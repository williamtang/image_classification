<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>image_classification_ZH-CN</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.6 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 20ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Image-Classification">Image Classification<a class="anchor-link" href="#Image-Classification">&#182;</a></h1><p>In this project, you'll classify images from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>.  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Run the following cell to download the <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#22270;&#20687;&#20998;&#31867;">&#22270;&#20687;&#20998;&#31867;<a class="anchor-link" href="#&#22270;&#20687;&#20998;&#31867;">&#182;</a></h1><p>在该项目中，你将会对来自 <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 数据集</a> 中的图像进行分类。数据集中图片的内容包括飞机（airplane）、狗（dogs）、猫（cats）及其他物体。你需要处理这些图像，接着对所有的样本训练一个卷积神经网络。</p>
<p>具体而言，在项目中你要对图像进行正规化处理（normalization)，同时还要对图像的标签进行 one-hot 编码。接着你将会应用到你所学的技能来搭建一个具有卷积层、最大池化（Max Pooling）层、Dropout  层及全连接（fully connected）层的神经网络。最后，你会训练你的神经网络，会得到你神经网络在样本图像上的预测结果。</p>
<h2 id="&#19979;&#36733;&#25968;&#25454;">&#19979;&#36733;&#25968;&#25454;<a class="anchor-link" href="#&#19979;&#36733;&#25968;&#25454;">&#182;</a></h2><p>运行如下代码下载 <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1">#from urllib.request import urlretrieve</span>
<span class="c1">#import urllib #python27</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span> <span class="c1">#py36</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">isdir</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="n">cifar10_dataset_folder_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-batches-py&#39;</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;CIFAR-10 Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="c1">#urllib.urlretrieve(</span>
        <span class="c1">#    &#39;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&#39;,</span>
        <span class="c1">#    &#39;cifar-10-python.tar.gz&#39;,</span>
        <span class="c1">#    pbar.hook)</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isdir</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="n">tests</span><span class="o">.</span><span class="n">test_folder_path</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>All files found!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named <code>data_batch_1</code>, <code>data_batch_2</code>, etc.. Each batch contains the labels and images that are one of the following:</p>
<ul>
<li>airplane</li>
<li>automobile</li>
<li>bird</li>
<li>cat</li>
<li>deer</li>
<li>dog</li>
<li>frog</li>
<li>horse</li>
<li>ship</li>
<li>truck</li>
</ul>
<p>Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the <code>batch_id</code> and <code>sample_id</code>. The <code>batch_id</code> is the id for a batch (1-5). The <code>sample_id</code> is the id for a image and label pair in the batch.</p>
<p>Ask yourself "What are all possible labels?", "What is the range of values for the image data?", "Are the labels in order or random?".  Answers to questions like these will help you preprocess the data and end up with better predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#25506;&#32034;&#25968;&#25454;&#38598;">&#25506;&#32034;&#25968;&#25454;&#38598;<a class="anchor-link" href="#&#25506;&#32034;&#25968;&#25454;&#38598;">&#182;</a></h2><p>为防止在运行过程中内存不足的问题，该数据集已经事先被分成了5批（batch），名为<code>data_batch_1</code>、<code>data_batch_2</code>等。每一批中都含有 <em>图像</em> 及对应的 <em>标签</em>，都是如下类别中的一种：</p>
<ul>
<li>飞机</li>
<li>汽车</li>
<li>鸟</li>
<li>鹿</li>
<li>狗</li>
<li>青蛙</li>
<li>马</li>
<li>船</li>
<li>卡车</li>
</ul>
<p>理解数据集也是对数据进行预测的一部分。修改如下代码中的 <code>batch_id</code> 和 <code>sample_id</code>，看看输出的图像是什么样子。其中，<code>batch_id</code> 代表着批次数（1-5），<code>sample_id</code> 代表着在该批内图像及标签的编号。</p>
<p>你可以尝试回答如下问题：</p>
<ul>
<li>可能出现的 <em>标签</em> 都包括哪些？</li>
<li>图像数据的取值范围是多少？</li>
<li><em>标签</em> 的排列顺序是随机的还是有序的？</li>
</ul>
<p>对这些问题的回答，会有助于更好地处理数据，并能更好地进行预测。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Explore the dataset</span>
<span class="n">batch_id</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sample_id</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">helper</span><span class="o">.</span><span class="n">display_stats</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
Stats of batch 2:
Samples: 10000
Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}
First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]

Example of Image 20:
Image - Min Value: 24 Max Value: 206
Image - Shape: (32, 32, 3)
Label - Label Id: 0 Name: airplane
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
width=253
height=250
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocess-Functions">Implement Preprocess Functions<a class="anchor-link" href="#Implement-Preprocess-Functions">&#182;</a></h2><h3 id="Normalize">Normalize<a class="anchor-link" href="#Normalize">&#182;</a></h3><p>In the cell below, implement the <code>normalize</code> function to take in image data, <code>x</code>, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as <code>x</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#22270;&#20687;&#39044;&#22788;&#29702;&#21151;&#33021;&#30340;&#23454;&#29616;">&#22270;&#20687;&#39044;&#22788;&#29702;&#21151;&#33021;&#30340;&#23454;&#29616;<a class="anchor-link" href="#&#22270;&#20687;&#39044;&#22788;&#29702;&#21151;&#33021;&#30340;&#23454;&#29616;">&#182;</a></h2><h3 id="&#27491;&#35268;&#21270;">&#27491;&#35268;&#21270;<a class="anchor-link" href="#&#27491;&#35268;&#21270;">&#182;</a></h3><p>在如下的代码中，修改 <code>normalize</code> 函数，使之能够对输入的图像数据 <code>x</code> 进行处理，输出一个经过正规化的、Numpy array 格式的图像数据。</p>
<p><strong>注意：</strong>
处理后的值应当在 $[0,1]$ 的范围之内。返回值应当和输入值具有相同的形状。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize a list of sample image data in the range of 0 to 1</span>
<span class="sd">    : x: List of image data.  The image shape is (32, 32, 3)</span>
<span class="sd">    : return: Numpy array of normalize data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">min_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">max_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,:,:]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">min_val</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">max_val</span> <span class="o">-</span> <span class="n">min_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_normalize</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-hot-encode">One-hot encode<a class="anchor-link" href="#One-hot-encode">&#182;</a></h3><p>Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the <code>one_hot_encode</code> function. The input, <code>x</code>, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to <code>one_hot_encode</code>.  Make sure to save the map of encodings outside the function.</p>
<p><strong>Hint:</strong></p>
<p>Look into LabelBinarizer in the preprocessing module of sklearn.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-hot-&#32534;&#30721;">One-hot &#32534;&#30721;<a class="anchor-link" href="#One-hot-&#32534;&#30721;">&#182;</a></h3><p>在如下代码中，你将继续实现预处理的功能，实现一个 <code>one_hot_encode</code> 函数。函数的输入 <code>x</code> 是 <em>标签</em> 构成的列表，返回值是经过 One_hot 处理过后的这列 <em>标签</em> 对应的 One_hot 编码，以 Numpy array 储存。其中，<em>标签</em> 的取值范围从0到9。每次调用该函数时，对相同的标签值，它输出的编码也是相同的。请确保在函数外保存编码的映射（map of encodings）。</p>
<p><strong>提示：</strong></p>
<p>你可以尝试使用 sklearn preprocessing 模块中的 <code>LabelBinarizer</code> 函数。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.</span>
<span class="sd">    : x: List of sample Labels</span>
<span class="sd">    : return: Numpy array of one-hot encoded labels</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>
    <span class="n">lb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">onehot_labels</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">onehot_labels</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_one_hot_encode</span><span class="p">(</span><span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Randomize-Data">Randomize Data<a class="anchor-link" href="#Randomize-Data">&#182;</a></h3><p>As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#38543;&#26426;&#25171;&#20081;&#25968;&#25454;">&#38543;&#26426;&#25171;&#20081;&#25968;&#25454;<a class="anchor-link" href="#&#38543;&#26426;&#25171;&#20081;&#25968;&#25454;">&#182;</a></h3><p>正如你在上方探索数据部分所看到的，样本的顺序已经被随机打乱了。尽管再随机处理一次也没问题，不过对于该数据我们没必要再进行一次相关操作了。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#23545;&#25152;&#26377;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#32467;&#26524;">&#23545;&#25152;&#26377;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#32467;&#26524;<a class="anchor-link" href="#&#23545;&#25152;&#26377;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#32467;&#26524;">&#182;</a></h2><p>运行如下代码，它将会预处理所有的 CIFAR-10 数据并将它另存为文件。此外，如下的代码还将会把 10% 的训练数据留出作为验证数据。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#26816;&#26597;&#28857;">&#26816;&#26597;&#28857;<a class="anchor-link" href="#&#26816;&#26597;&#28857;">&#182;</a></h1><p>这是你的首个检查点。因为预处理完的数据已经被保存到硬盘上了，所以如果你需要回顾或重启该 notebook，你可以在这里重新开始。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="c1"># Load the Preprocessed Validation data</span>
<span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_validation.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h2><p>For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.</p>
<blockquote><p><strong>Note:</strong> If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages to build each layer, except the layers you build in the "Convolutional and Max Pooling Layer" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.</p>
<p>However, if you would like to get the most out of this course, try to solve all the problems <em>without</em> using anything from the TF Layers packages. You <strong>can</strong> still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the <code>conv2d</code> class, <a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d">tf.layers.conv2d</a>, you would want to use the TF Neural Network version of <code>conv2d</code>, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">tf.nn.conv2d</a>.</p>
</blockquote>
<p>Let's begin!</p>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions</p>
<ul>
<li>Implement <code>neural_net_image_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>image_shape</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "x" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_label_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>n_classes</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "y" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_keep_prob_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> for dropout keep probability.</li>
<li>Name the TensorFlow placeholder "keep_prob" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
</ul>
<p>These names will be used at the end of the project to load your saved model.</p>
<p>Note: <code>None</code> for shapes in TensorFlow allow for a dynamic size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#25645;&#24314;&#31070;&#32463;&#32593;&#32476;">&#25645;&#24314;&#31070;&#32463;&#32593;&#32476;<a class="anchor-link" href="#&#25645;&#24314;&#31070;&#32463;&#32593;&#32476;">&#182;</a></h2><p>为搭建神经网络，你需要将搭建每一层的过程封装到一个函数中。大部分的代码你在函数外已经见过。为能够更透彻地测试你的代码，我们要求你把每一层都封装到一个函数中。这能够帮助我们给予你更好的回复，同时还能让我们使用 unittests 在你提交报告前检测出你项目中的小问题。</p>
<blockquote><p><strong>注意：</strong> 如果你时间紧迫，那么在该部分我们为你提供了一个便捷方法。在接下来的一些问题中，你可以使用来自 <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> 或 <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> 包中的函数来搭建各层，不过不可以用他们搭建卷积-最大池化层。TF Layers 和 Keras 及 TFLean 中对层的抽象比较相似，所以你应该很容易上手。</p>
</blockquote>
<p>&gt;</p>
<p>However, if you would like to get the most out of this course, try to solve all the problems <em>without</em> using anything from the TF Layers packages. You <strong>can</strong> still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the <code>conv2d</code> class, <a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d">tf.layers.conv2d</a>, you would want to use the TF Neural Network version of <code>conv2d</code>, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">tf.nn.conv2d</a>.</p>
<p>不过，如果你希望能够更多地实践，我们希望你能够在<strong>不</strong>使用 TF Layers 的情况下解决所有问题。你依然<strong>能</strong>使用来自其他包但和 layers 中重名的函数。例如，你可以使用 TF Neural Network 版本的 `conv_2d</p>
<p>让我们开始吧！</p>
<h3 id="&#36755;&#20837;">&#36755;&#20837;<a class="anchor-link" href="#&#36755;&#20837;">&#182;</a></h3><p>神经网络需要能够读取图像数据、经 one-hot 编码之后的标签及 dropout 中的保留概率。修改如下函数：</p>
<ul>
<li>修改 <code>neural_net_image_input</code> 函数：<ul>
<li>返回 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>。</li>
<li>使用 <code>image_shape</code> 设定形状，设定批大小（batch size)为 <code>None</code>。</li>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> 中的 <code>Name</code> 参数，命名该 TensorFlow placeholder 为 "x"。</li>
</ul>
</li>
<li>修改 <code>neural_net_label_input</code> 函数： <ul>
<li>返回 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>。</li>
<li>使用 <code>n_classes</code> 设定形状，设定批大小（batch size)为 <code>None</code>。</li>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> 中的 <code>Name</code> 参数，命名该 TensorFlow placeholder 为 "y"。</li>
</ul>
</li>
<li>修改 <code>neural_net_keep_prob_input</code> 函数：<ul>
<li>返回 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> 作为 dropout 的保留概率（keep probability）。</li>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> 中的 <code>Name</code> 参数，命名该 TensorFlow placeholder 为 "keep_prob"。</li>
</ul>
</li>
</ul>
<p>我们会在项目最后使用这些名字，来载入你储存的模型。</p>
<p><strong>注意：</strong>在 TensorFlow 中，对形状设定为 <code>None</code>，能帮助设定一个动态的大小。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">neural_net_image_input</span><span class="p">(</span><span class="n">image_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of image input</span>
<span class="sd">    : image_shape: Shape of the images</span>
<span class="sd">    : return: Tensor for image input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">neural_net_label_input</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of label input</span>
<span class="sd">    : n_classes: Number of classes</span>
<span class="sd">    : return: Tensor for label input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">neural_net_keep_prob_input</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for keep probability</span>
<span class="sd">    : return: Tensor for keep probability.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">keep_prob</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_image_inputs</span><span class="p">(</span><span class="n">neural_net_image_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_label_inputs</span><span class="p">(</span><span class="n">neural_net_label_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_keep_prob_inputs</span><span class="p">(</span><span class="n">neural_net_keep_prob_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Image Input Tests Passed.
Label Input Tests Passed.
Keep Prob Tests Passed.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolution-and-Max-Pooling-Layer">Convolution and Max Pooling Layer<a class="anchor-link" href="#Convolution-and-Max-Pooling-Layer">&#182;</a></h3><p>Convolution layers have a lot of success with images. For this code cell, you should implement the function <code>conv2d_maxpool</code> to apply convolution then max pooling:</p>
<ul>
<li>Create the weight and bias using <code>conv_ksize</code>, <code>conv_num_outputs</code> and the shape of <code>x_tensor</code>.</li>
<li>Apply a convolution to <code>x_tensor</code> using weight and <code>conv_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
<li>Add bias</li>
<li>Add a nonlinear activation to the convolution.</li>
<li>Apply Max Pooling using <code>pool_ksize</code> and <code>pool_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
</ul>
<p><strong>Note:</strong> You <strong>can't</strong> use <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> for <strong>this</strong> layer, but you can still use TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/nn">Neural Network</a> package. You may still use the shortcut option for all the <strong>other</strong> layers.</p>
<p><strong> Hint: </strong></p>
<p>When unpacking values as an argument in Python, look into the <a href="https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists">unpacking</a> operator.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#21367;&#31215;-&#26368;&#22823;&#27744;&#65288;Convolution-and-Max-Pooling&#65289;&#21270;&#23618;">&#21367;&#31215;-&#26368;&#22823;&#27744;&#65288;Convolution and Max Pooling&#65289;&#21270;&#23618;<a class="anchor-link" href="#&#21367;&#31215;-&#26368;&#22823;&#27744;&#65288;Convolution-and-Max-Pooling&#65289;&#21270;&#23618;">&#182;</a></h3><p>卷积层在图像处理中取得了不小的成功。在这部分的代码中，你需要修改 <code>conv2d_maxpool</code> 函数来先后实现卷积及最大池化的功能。</p>
<ul>
<li>使用 <code>conv_ksize</code>、<code>conv_num_outputs</code> 及 <code>x_tensor</code> 来创建权重（weight）及偏差（bias）变量。</li>
<li>对 <code>x_tensor</code> 进行卷积，使用 <code>conv_strides</code> 及<em>权重</em>。<ul>
<li>我们建议使用 SAME padding，不过你也可尝试其他 padding 模式。 </li>
</ul>
</li>
<li>加上<em>偏差</em>。</li>
<li>对卷积结果加上一个非线性函数作为激活层。</li>
<li>基于 <code>pool_kszie</code> 及 <code>pool_strides</code> 进行最大池化。<ul>
<li>我们建议使用 SAME padding，不过你也可尝试其他 padding 模式。</li>
</ul>
</li>
</ul>
<p><strong>注意：</strong>
你<strong>不</strong>可以使用来自 <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> 或 <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> 包中的函数来实现<strong>这一层</strong>的功能。但是你可以使用 TensorFlow 的<a href="https://www.tensorflow.org/api_docs/python/tf/nn">Neural Network</a>包。</p>
<p>对于如上的快捷方法，你在<strong>其他层</strong>中可以尝试使用。</p>
<p><strong>提示：</strong>
当你在 Python 中希望展开（unpacking）某个变量的值作为函数的参数，你可以参考 <a href="https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists">unpacking</a> 运算符。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv2d_maxpool</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">conv_num_outputs</span><span class="p">,</span> <span class="n">conv_ksize</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">,</span> <span class="n">pool_ksize</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply convolution then max pooling to x_tensor</span>
<span class="sd">    :param x_tensor: TensorFlow Tensor</span>
<span class="sd">    :param conv_num_outputs: Number of outputs for the convolutional layer</span>
<span class="sd">    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer</span>
<span class="sd">    :param conv_strides: Stride 2-D Tuple for convolution</span>
<span class="sd">    :param pool_ksize: kernal size 2-D Tuple for pool</span>
<span class="sd">    :param pool_strides: Stride 2-D Tuple for pool</span>
<span class="sd">    : return: A tensor that represents convolution and max pooling of x_tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">initial_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">conv_ksize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">conv_ksize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x_tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">conv_num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">initial_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">conv_num_outputs</span><span class="p">])</span>
    
    <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_w</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_b</span><span class="p">)</span>
    
    <span class="n">conv_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conv_strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="n">relu_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv_data</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">pool_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">relu_data</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">pool_ksize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pool_ksize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> 
                   <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pool_strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">pool_data</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_con_pool</span><span class="p">(</span><span class="n">conv2d_maxpool</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Flatten-Layer">Flatten Layer<a class="anchor-link" href="#Flatten-Layer">&#182;</a></h3><p>Implement the <code>flatten</code> function to change the dimension of <code>x_tensor</code> from a 4-D tensor to a 2-D tensor.  The output should be the shape (<em>Batch Size</em>, <em>Flattened Image Size</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#23637;&#24320;&#23618;">&#23637;&#24320;&#23618;<a class="anchor-link" href="#&#23637;&#24320;&#23618;">&#182;</a></h3><p>修改 <code>flatten</code> 函数，来将4维的输入张量 <code>x_tensor</code> 转换为一个二维的张量。输出的形状应当是 <code>(Batch Size, Flattened Image Size)</code>。
快捷方法：你可以使用来自 <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> 或 <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> 包中的函数来实现该功能。不过你也可以只使用 TensorFlow 包中的函数来挑战自己。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>
<span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flatten x_tensor to (Batch Size, Flattened Image Size)</span>
<span class="sd">    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.</span>
<span class="sd">    : return: A tensor of size (Batch Size, Flattened Image Size).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="n">flat_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:])])</span>
    <span class="k">return</span> <span class="n">flat_data</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_flatten</span><span class="p">(</span><span class="n">flatten</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Connected-Layer">Fully-Connected Layer<a class="anchor-link" href="#Fully-Connected-Layer">&#182;</a></h3><p>Implement the <code>fully_conn</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#20840;&#36830;&#25509;&#23618;">&#20840;&#36830;&#25509;&#23618;<a class="anchor-link" href="#&#20840;&#36830;&#25509;&#23618;">&#182;</a></h3><p>修改 <code>fully_conn</code> 函数，来对形如 <code>(batch Size, num_outputs)</code> 的输入 <code>x_tensor</code> 应用一个全连接层。快捷方法：你可以使用来自 <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> 或 <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> 包中的函数来实现该功能。不过你也可以只使用 TensorFlow 包中的函数来挑战自己。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a fully connected layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">num_weights</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">W_fc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">num_weights</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">b_fc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">num_outputs</span><span class="p">]))</span>
    <span class="n">fc_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W_fc</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_fc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fc_data</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_fully_conn</span><span class="p">(</span><span class="n">fully_conn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-Layer">Output Layer<a class="anchor-link" href="#Output-Layer">&#182;</a></h3><p>Implement the <code>output</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>
<p><strong>Note:</strong> Activation, softmax, or cross entropy should <strong>not</strong> be applied to this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#36755;&#20986;&#23618;">&#36755;&#20986;&#23618;<a class="anchor-link" href="#&#36755;&#20986;&#23618;">&#182;</a></h3><p>修改 <code>output</code> 函数，来对形如 <code>(batch Size, num_outputs)</code> 的输入 <code>x_tensor</code> 应用一个全连接层。快捷方法：你可以使用来自 <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> 或 <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> 包中的函数来实现该功能。不过你也可以只使用 TensorFlow 包中的函数来挑战自己。</p>
<p><strong>注意：</strong>
激活函数、softmax 或者交叉熵（corss entropy）<strong>不</strong>应被加入到该层。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a output layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">num_weights</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">W_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">num_weights</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">b_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">num_outputs</span><span class="p">]))</span>
    <span class="n">output_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W_output</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_data</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Convolutional-Model">Create Convolutional Model<a class="anchor-link" href="#Create-Convolutional-Model">&#182;</a></h3><p>Implement the function <code>conv_net</code> to create a convolutional neural network model. The function takes in a batch of images, <code>x</code>, and outputs logits.  Use the layers you created above to create this model:</p>
<ul>
<li>Apply 1, 2, or 3 Convolution and Max Pool layers</li>
<li>Apply a Flatten Layer</li>
<li>Apply 1, 2, or 3 Fully Connected Layers</li>
<li>Apply an Output Layer</li>
<li>Return the output</li>
<li>Apply <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout">TensorFlow's Dropout</a> to one or more layers in the model using <code>keep_prob</code>. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#21019;&#24314;&#21367;&#31215;&#27169;&#22411;">&#21019;&#24314;&#21367;&#31215;&#27169;&#22411;<a class="anchor-link" href="#&#21019;&#24314;&#21367;&#31215;&#27169;&#22411;">&#182;</a></h3><p>修改 <code>conv_net</code> 函数，使之能够生成一个卷积神经网络模型。该函数的输入为一批图像数据 <code>x</code>，输出为 logits。在函数中，使用上方你修改的创建各种层的函数来创建该模型：</p>
<ul>
<li>使用 1 到 3 个卷积-最大池化层</li>
<li>使用一个展开层</li>
<li>使用 1 到 3 个全连接层</li>
<li>使用一个输出层</li>
<li>返回呼出结果</li>
<li>在一个或多个层上使用 <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout">TensorFlow's Dropout</a>，对应的保留概率为 <code>keep_prob</code>. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a convolutional neural network model</span>
<span class="sd">    : x: Placeholder tensor that holds image data.</span>
<span class="sd">    : keep_prob: Placeholder tensor that hold dropout keep probability.</span>
<span class="sd">    : return: Tensor that represents logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Apply 1, 2, or 3 Convolution and Max Pool layers</span>
    <span class="c1">#    Play around with different number of outputs, kernel size and stride</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)</span>
    <span class="n">conv_maxpool1</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">conv_maxpool2</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">conv_maxpool1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    
    <span class="c1"># TODO: Apply a Flatten Layer</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   flatten(x_tensor)</span>
    <span class="n">flatten_data</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">=</span><span class="n">conv_maxpool2</span><span class="p">)</span>
    

    <span class="c1"># TODO: Apply 1, 2, or 3 Fully Connected Layers</span>
    <span class="c1">#    Play around with different number of outputs</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   fully_conn(x_tensor, num_outputs)</span>
    <span class="n">fc1</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">=</span><span class="n">flatten_data</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">fc2</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">=</span><span class="n">fc1</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1">#fc3 = fully_conn(x_tensor=fc2, num_outputs=10)</span>
    
    
    <span class="c1"># TODO: Apply an Output Layer</span>
    <span class="c1">#    Set this to the number of classes</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   output(x_tensor, num_outputs)</span>
    <span class="n">output_data</span> <span class="o">=</span> <span class="n">output</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">=</span><span class="n">fc2</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># TODO: return output</span>
    <span class="k">return</span> <span class="n">output_data</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">##############################</span>
<span class="c1">## Build the Neural Network ##</span>
<span class="c1">##############################</span>

<span class="c1"># Remove previous weights, bias, inputs, etc..</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># Inputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">neural_net_image_input</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">neural_net_label_input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">neural_net_keep_prob_input</span><span class="p">()</span>

<span class="c1"># Model</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

<span class="c1"># Name logits Tensor, so that is can be loaded from disk after training</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="c1"># Accuracy</span>
<span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_conv_net</span><span class="p">(</span><span class="n">conv_net</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Neural Network Built!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-the-Neural-Network">Train the Neural Network<a class="anchor-link" href="#Train-the-Neural-Network">&#182;</a></h2><h3 id="Single-Optimization">Single Optimization<a class="anchor-link" href="#Single-Optimization">&#182;</a></h3><p>Implement the function <code>train_neural_network</code> to do a single optimization.  The optimization should use <code>optimizer</code> to optimize in <code>session</code> with a <code>feed_dict</code> of the following:</p>
<ul>
<li><code>x</code> for image input</li>
<li><code>y</code> for labels</li>
<li><code>keep_prob</code> for keep probability for dropout</li>
</ul>
<p>This function will be called for each batch, so <code>tf.global_variables_initializer()</code> has already been called.</p>
<p>Note: Nothing needs to be returned. This function is only optimizing the neural network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#35757;&#32451;&#35813;&#31070;&#32463;&#32593;&#32476;">&#35757;&#32451;&#35813;&#31070;&#32463;&#32593;&#32476;<a class="anchor-link" href="#&#35757;&#32451;&#35813;&#31070;&#32463;&#32593;&#32476;">&#182;</a></h2><h3 id="&#26368;&#20248;&#21270;">&#26368;&#20248;&#21270;<a class="anchor-link" href="#&#26368;&#20248;&#21270;">&#182;</a></h3><p>修改 <code>train_neural_network</code> 函数以执行单次最优化。该最优化过程应在一个 <code>session</code> 中使用 <code>optimizer</code> 来进行该过程，它的 <code>feed_dict</code> 包括：</p>
<ul>
<li><code>x</code> 代表输入图像</li>
<li><code>y</code> 代表<em>标签</em></li>
<li><code>keep_prob</code> 为 Dropout 过程中的保留概率</li>
</ul>
<p>对每批数据该函数都会被调用，因而 <code>tf.global_variables_initializer()</code> 已经被调用过。</p>
<p>注意：该函数并不要返回某个值，它只对神经网络进行最优化。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Optimize the session on a batch of images and labels</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : optimizer: TensorFlow optimizer function</span>
<span class="sd">    : keep_probability: keep probability</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_train_nn</span><span class="p">(</span><span class="n">train_neural_network</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-Stats">Show Stats<a class="anchor-link" href="#Show-Stats">&#182;</a></h3><p>Implement the function <code>print_stats</code> to print loss and validation accuracy.  Use the global variables <code>valid_features</code> and <code>valid_labels</code> to calculate validation accuracy.  Use a keep probability of <code>1.0</code> to calculate the loss and validation accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#26174;&#31034;&#29366;&#24577;">&#26174;&#31034;&#29366;&#24577;<a class="anchor-link" href="#&#26174;&#31034;&#29366;&#24577;">&#182;</a></h3><p>修改 <code>print_stats</code> 函数来打印 loss 值及验证准确率。 使用全局的变量 <code>valid_features</code> 及 <code>valid_labels</code> 来计算验证准确率。 设定保留概率为 1.0 来计算 loss 值及验证准确率。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information about loss and validation accuracy</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    : cost: TensorFlow cost function</span>
<span class="sd">    : accuracy: TensorFlow accuracy function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span><span class="n">accuracy</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of iterations until the network stops learning or start overfitting</li>
<li>Set <code>batch_size</code> to the highest number that your machine has memory for.  Most people set them to common sizes of memory:<ul>
<li>64</li>
<li>128</li>
<li>256</li>
<li>...</li>
</ul>
</li>
<li>Set <code>keep_probability</code> to the probability of keeping a node using dropout</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#36229;&#21442;&#25968;&#35843;&#33410;">&#36229;&#21442;&#25968;&#35843;&#33410;<a class="anchor-link" href="#&#36229;&#21442;&#25968;&#35843;&#33410;">&#182;</a></h3><p>你需要调节如下的参数：</p>
<ul>
<li>设定 <code>epoches</code> 为模型停止学习或开始过拟合时模型的迭代次数。</li>
<li>设定 <code>batch_size</code> 为你内存能支持的最大值。一般我们设定该值为：<ul>
<li>64</li>
<li>128</li>
<li>256</li>
<li>...</li>
</ul>
</li>
<li>设定 <code>keep_probability</code> 为在 dropout 过程中保留一个节点的概率。</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: Tune Parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.85</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-on-a-Single-CIFAR-10-Batch">Train on a Single CIFAR-10 Batch<a class="anchor-link" href="#Train-on-a-Single-CIFAR-10-Batch">&#182;</a></h3><p>Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#23545;&#21333;&#25209;-CIFAR-10-&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;">&#23545;&#21333;&#25209; CIFAR-10 &#25968;&#25454;&#36827;&#34892;&#35757;&#32451;<a class="anchor-link" href="#&#23545;&#21333;&#25209;-CIFAR-10-&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;">&#182;</a></h3><p>相比于在所有 CIFAR-10 数据上训练神经网络，我们首先使用一批数据进行训练。这会帮助你在调节模型提高精度的过程中节省时间。当最终的验证精度超过 50% 之后，你就可以前往下一节在所有数据上运行该模型了。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking the Training on a Single Batch...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking the Training on a Single Batch...
Epoch  1, CIFAR-10 Batch 1:  loss: 2.323219
accuracy: 0.075000
Epoch  2, CIFAR-10 Batch 1:  loss: 2.325608
accuracy: 0.100000
Epoch  3, CIFAR-10 Batch 1:  loss: 2.307657
accuracy: 0.125000
Epoch  4, CIFAR-10 Batch 1:  loss: 2.292927
accuracy: 0.125000
Epoch  5, CIFAR-10 Batch 1:  loss: 2.262314
accuracy: 0.175000
Epoch  6, CIFAR-10 Batch 1:  loss: 2.213558
accuracy: 0.275000
Epoch  7, CIFAR-10 Batch 1:  loss: 2.179834
accuracy: 0.275000
Epoch  8, CIFAR-10 Batch 1:  loss: 2.133162
accuracy: 0.225000
Epoch  9, CIFAR-10 Batch 1:  loss: 2.089618
accuracy: 0.250000
Epoch 10, CIFAR-10 Batch 1:  loss: 2.050212
accuracy: 0.300000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Train-the-Model">Fully Train the Model<a class="anchor-link" href="#Fully-Train-the-Model">&#182;</a></h3><p>Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#23436;&#20840;&#35757;&#32451;&#35813;&#27169;&#22411;">&#23436;&#20840;&#35757;&#32451;&#35813;&#27169;&#22411;<a class="anchor-link" href="#&#23436;&#20840;&#35757;&#32451;&#35813;&#27169;&#22411;">&#182;</a></h3><p>因为你在单批 CIFAR-10 数据上已经得到了一个不错的准确率了，那你可以尝试在所有五批数据上进行训练。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Loop over all batches</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
            
    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Training...
Epoch  1, CIFAR-10 Batch 1:  loss: 2.311109
accuracy: 0.075000
Epoch  1, CIFAR-10 Batch 2:  loss: 2.302874
accuracy: 0.100000
Epoch  1, CIFAR-10 Batch 3:  loss: 2.198396
accuracy: 0.225000
Epoch  1, CIFAR-10 Batch 4:  loss: 2.273061
accuracy: 0.100000
Epoch  1, CIFAR-10 Batch 5:  loss: 2.295355
accuracy: 0.100000
Epoch  2, CIFAR-10 Batch 1:  loss: 2.247268
accuracy: 0.200000
Epoch  2, CIFAR-10 Batch 2:  loss: 2.282282
accuracy: 0.150000
Epoch  2, CIFAR-10 Batch 3:  loss: 2.144038
accuracy: 0.175000
Epoch  2, CIFAR-10 Batch 4:  loss: 2.248559
accuracy: 0.150000
Epoch  2, CIFAR-10 Batch 5:  loss: 2.272398
accuracy: 0.175000
Epoch  3, CIFAR-10 Batch 1:  loss: 2.198834
accuracy: 0.200000
Epoch  3, CIFAR-10 Batch 2:  loss: 2.272129
accuracy: 0.200000
Epoch  3, CIFAR-10 Batch 3:  loss: 2.104615
accuracy: 0.225000
Epoch  3, CIFAR-10 Batch 4:  loss: 2.228700
accuracy: 0.175000
Epoch  3, CIFAR-10 Batch 5:  loss: 2.255332
accuracy: 0.150000
Epoch  4, CIFAR-10 Batch 1:  loss: 2.190986
accuracy: 0.200000
Epoch  4, CIFAR-10 Batch 2:  loss: 2.250761
accuracy: 0.225000
Epoch  4, CIFAR-10 Batch 3:  loss: 2.093730
accuracy: 0.225000
Epoch  4, CIFAR-10 Batch 4:  loss: 2.205502
accuracy: 0.125000
Epoch  4, CIFAR-10 Batch 5:  loss: 2.244753
accuracy: 0.150000
Epoch  5, CIFAR-10 Batch 1:  loss: 2.182720
accuracy: 0.225000
Epoch  5, CIFAR-10 Batch 2:  loss: 2.234088
accuracy: 0.225000
Epoch  5, CIFAR-10 Batch 3:  loss: 2.079081
accuracy: 0.275000
Epoch  5, CIFAR-10 Batch 4:  loss: 2.199689
accuracy: 0.150000
Epoch  5, CIFAR-10 Batch 5:  loss: 2.215868
accuracy: 0.150000
Epoch  6, CIFAR-10 Batch 1:  loss: 2.153807
accuracy: 0.225000
Epoch  6, CIFAR-10 Batch 2:  loss: 2.206803
accuracy: 0.225000
Epoch  6, CIFAR-10 Batch 3:  loss: 2.084309
accuracy: 0.175000
Epoch  6, CIFAR-10 Batch 4:  loss: 2.181384
accuracy: 0.150000
Epoch  6, CIFAR-10 Batch 5:  loss: 2.214654
accuracy: 0.125000
Epoch  7, CIFAR-10 Batch 1:  loss: 2.128479
accuracy: 0.225000
Epoch  7, CIFAR-10 Batch 2:  loss: 2.128058
accuracy: 0.275000
Epoch  7, CIFAR-10 Batch 3:  loss: 2.058027
accuracy: 0.250000
Epoch  7, CIFAR-10 Batch 4:  loss: 2.169923
accuracy: 0.175000
Epoch  7, CIFAR-10 Batch 5:  loss: 2.193798
accuracy: 0.150000
Epoch  8, CIFAR-10 Batch 1:  loss: 2.096152
accuracy: 0.225000
Epoch  8, CIFAR-10 Batch 2:  loss: 2.111368
accuracy: 0.300000
Epoch  8, CIFAR-10 Batch 3:  loss: 2.046938
accuracy: 0.225000
Epoch  8, CIFAR-10 Batch 4:  loss: 2.142800
accuracy: 0.250000
Epoch  8, CIFAR-10 Batch 5:  loss: 2.168020
accuracy: 0.125000
Epoch  9, CIFAR-10 Batch 1:  loss: 2.054710
accuracy: 0.250000
Epoch  9, CIFAR-10 Batch 2:  loss: 2.071850
accuracy: 0.325000
Epoch  9, CIFAR-10 Batch 3:  loss: 2.013138
accuracy: 0.225000
Epoch  9, CIFAR-10 Batch 4:  loss: 2.109556
accuracy: 0.300000
Epoch  9, CIFAR-10 Batch 5:  loss: 2.151948
accuracy: 0.125000
Epoch 10, CIFAR-10 Batch 1:  loss: 2.037143
accuracy: 0.250000
Epoch 10, CIFAR-10 Batch 2:  loss: 2.062499
accuracy: 0.325000
Epoch 10, CIFAR-10 Batch 3:  loss: 1.992631
accuracy: 0.275000
Epoch 10, CIFAR-10 Batch 4:  loss: 2.092449
accuracy: 0.250000
Epoch 10, CIFAR-10 Batch 5:  loss: 2.126212
accuracy: 0.150000
Epoch 11, CIFAR-10 Batch 1:  loss: 2.011142
accuracy: 0.250000
Epoch 11, CIFAR-10 Batch 2:  loss: 2.029597
accuracy: 0.375000
Epoch 11, CIFAR-10 Batch 3:  loss: 1.969368
accuracy: 0.300000
Epoch 11, CIFAR-10 Batch 4:  loss: 2.078585
accuracy: 0.300000
Epoch 11, CIFAR-10 Batch 5:  loss: 2.096579
accuracy: 0.150000
Epoch 12, CIFAR-10 Batch 1:  loss: 1.980952
accuracy: 0.275000
Epoch 12, CIFAR-10 Batch 2:  loss: 2.020665
accuracy: 0.300000
Epoch 12, CIFAR-10 Batch 3:  loss: 1.956455
accuracy: 0.275000
Epoch 12, CIFAR-10 Batch 4:  loss: 2.045511
accuracy: 0.300000
Epoch 12, CIFAR-10 Batch 5:  loss: 2.074875
accuracy: 0.200000
Epoch 13, CIFAR-10 Batch 1:  loss: 1.934237
accuracy: 0.300000
Epoch 13, CIFAR-10 Batch 2:  loss: 1.968185
accuracy: 0.375000
Epoch 13, CIFAR-10 Batch 3:  loss: 1.927748
accuracy: 0.300000
Epoch 13, CIFAR-10 Batch 4:  loss: 2.025476
accuracy: 0.300000
Epoch 13, CIFAR-10 Batch 5:  loss: 2.061116
accuracy: 0.175000
Epoch 14, CIFAR-10 Batch 1:  loss: 1.887222
accuracy: 0.350000
Epoch 14, CIFAR-10 Batch 2:  loss: 1.954738
accuracy: 0.350000
Epoch 14, CIFAR-10 Batch 3:  loss: 1.904782
accuracy: 0.275000
Epoch 14, CIFAR-10 Batch 4:  loss: 1.993054
accuracy: 0.300000
Epoch 14, CIFAR-10 Batch 5:  loss: 2.023324
accuracy: 0.200000
Epoch 15, CIFAR-10 Batch 1:  loss: 1.836904
accuracy: 0.400000
Epoch 15, CIFAR-10 Batch 2:  loss: 1.903205
accuracy: 0.375000
Epoch 15, CIFAR-10 Batch 3:  loss: 1.868883
accuracy: 0.350000
Epoch 15, CIFAR-10 Batch 4:  loss: 1.961128
accuracy: 0.275000
Epoch 15, CIFAR-10 Batch 5:  loss: 2.004756
accuracy: 0.200000
Epoch 16, CIFAR-10 Batch 1:  loss: 1.805535
accuracy: 0.375000
Epoch 16, CIFAR-10 Batch 2:  loss: 1.860266
accuracy: 0.425000
Epoch 16, CIFAR-10 Batch 3:  loss: 1.855685
accuracy: 0.350000
Epoch 16, CIFAR-10 Batch 4:  loss: 1.926319
accuracy: 0.325000
Epoch 16, CIFAR-10 Batch 5:  loss: 1.979509
accuracy: 0.250000
Epoch 17, CIFAR-10 Batch 1:  loss: 1.772054
accuracy: 0.425000
Epoch 17, CIFAR-10 Batch 2:  loss: 1.838536
accuracy: 0.450000
Epoch 17, CIFAR-10 Batch 3:  loss: 1.851423
accuracy: 0.400000
Epoch 17, CIFAR-10 Batch 4:  loss: 1.906106
accuracy: 0.350000
Epoch 17, CIFAR-10 Batch 5:  loss: 1.962886
accuracy: 0.275000
Epoch 18, CIFAR-10 Batch 1:  loss: 1.747270
accuracy: 0.400000
Epoch 18, CIFAR-10 Batch 2:  loss: 1.781859
accuracy: 0.450000
Epoch 18, CIFAR-10 Batch 3:  loss: 1.841798
accuracy: 0.325000
Epoch 18, CIFAR-10 Batch 4:  loss: 1.889230
accuracy: 0.375000
Epoch 18, CIFAR-10 Batch 5:  loss: 1.923831
accuracy: 0.300000
Epoch 19, CIFAR-10 Batch 1:  loss: 1.725706
accuracy: 0.400000
Epoch 19, CIFAR-10 Batch 2:  loss: 1.747808
accuracy: 0.425000
Epoch 19, CIFAR-10 Batch 3:  loss: 1.815964
accuracy: 0.325000
Epoch 19, CIFAR-10 Batch 4:  loss: 1.852320
accuracy: 0.375000
Epoch 19, CIFAR-10 Batch 5:  loss: 1.908249
accuracy: 0.275000
Epoch 20, CIFAR-10 Batch 1:  loss: 1.707844
accuracy: 0.400000
Epoch 20, CIFAR-10 Batch 2:  loss: 1.716548
accuracy: 0.450000
Epoch 20, CIFAR-10 Batch 3:  loss: 1.787616
accuracy: 0.375000
Epoch 20, CIFAR-10 Batch 4:  loss: 1.835966
accuracy: 0.400000
Epoch 20, CIFAR-10 Batch 5:  loss: 1.888066
accuracy: 0.250000
Epoch 21, CIFAR-10 Batch 1:  loss: 1.710489
accuracy: 0.400000
Epoch 21, CIFAR-10 Batch 2:  loss: 1.705576
accuracy: 0.425000
Epoch 21, CIFAR-10 Batch 3:  loss: 1.756608
accuracy: 0.475000
Epoch 21, CIFAR-10 Batch 4:  loss: 1.843393
accuracy: 0.375000
Epoch 21, CIFAR-10 Batch 5:  loss: 1.886508
accuracy: 0.225000
Epoch 22, CIFAR-10 Batch 1:  loss: 1.704239
accuracy: 0.500000
Epoch 22, CIFAR-10 Batch 2:  loss: 1.666913
accuracy: 0.450000
Epoch 22, CIFAR-10 Batch 3:  loss: 1.735923
accuracy: 0.475000
Epoch 22, CIFAR-10 Batch 4:  loss: 1.835046
accuracy: 0.375000
Epoch 22, CIFAR-10 Batch 5:  loss: 1.886181
accuracy: 0.275000
Epoch 23, CIFAR-10 Batch 1:  loss: 1.692289
accuracy: 0.450000
Epoch 23, CIFAR-10 Batch 2:  loss: 1.626926
accuracy: 0.500000
Epoch 23, CIFAR-10 Batch 3:  loss: 1.740161
accuracy: 0.400000
Epoch 23, CIFAR-10 Batch 4:  loss: 1.818518
accuracy: 0.375000
Epoch 23, CIFAR-10 Batch 5:  loss: 1.864196
accuracy: 0.250000
Epoch 24, CIFAR-10 Batch 1:  loss: 1.700378
accuracy: 0.425000
Epoch 24, CIFAR-10 Batch 2:  loss: 1.611739
accuracy: 0.525000
Epoch 24, CIFAR-10 Batch 3:  loss: 1.741612
accuracy: 0.425000
Epoch 24, CIFAR-10 Batch 4:  loss: 1.804080
accuracy: 0.375000
Epoch 24, CIFAR-10 Batch 5:  loss: 1.840531
accuracy: 0.300000
Epoch 25, CIFAR-10 Batch 1:  loss: 1.751875
accuracy: 0.375000
Epoch 25, CIFAR-10 Batch 2:  loss: 1.562883
accuracy: 0.500000
Epoch 25, CIFAR-10 Batch 3:  loss: 1.729070
accuracy: 0.425000
Epoch 25, CIFAR-10 Batch 4:  loss: 1.792387
accuracy: 0.325000
Epoch 25, CIFAR-10 Batch 5:  loss: 1.830368
accuracy: 0.325000
Epoch 26, CIFAR-10 Batch 1:  loss: 1.655558
accuracy: 0.425000
Epoch 26, CIFAR-10 Batch 2:  loss: 1.603300
accuracy: 0.525000
Epoch 26, CIFAR-10 Batch 3:  loss: 1.732863
accuracy: 0.450000
Epoch 26, CIFAR-10 Batch 4:  loss: 1.769861
accuracy: 0.375000
Epoch 26, CIFAR-10 Batch 5:  loss: 1.815569
accuracy: 0.325000
Epoch 27, CIFAR-10 Batch 1:  loss: 1.595149
accuracy: 0.450000
Epoch 27, CIFAR-10 Batch 2:  loss: 1.532913
accuracy: 0.550000
Epoch 27, CIFAR-10 Batch 3:  loss: 1.713523
accuracy: 0.475000
Epoch 27, CIFAR-10 Batch 4:  loss: 1.784986
accuracy: 0.350000
Epoch 27, CIFAR-10 Batch 5:  loss: 1.806850
accuracy: 0.300000
Epoch 28, CIFAR-10 Batch 1:  loss: 1.584651
accuracy: 0.450000
Epoch 28, CIFAR-10 Batch 2:  loss: 1.507725
accuracy: 0.525000
Epoch 28, CIFAR-10 Batch 3:  loss: 1.689813
accuracy: 0.425000
Epoch 28, CIFAR-10 Batch 4:  loss: 1.747775
accuracy: 0.350000
Epoch 28, CIFAR-10 Batch 5:  loss: 1.787672
accuracy: 0.300000
Epoch 29, CIFAR-10 Batch 1:  loss: 1.585510
accuracy: 0.450000
Epoch 29, CIFAR-10 Batch 2:  loss: 1.499992
accuracy: 0.525000
Epoch 29, CIFAR-10 Batch 3:  loss: 1.657761
accuracy: 0.475000
Epoch 29, CIFAR-10 Batch 4:  loss: 1.739312
accuracy: 0.375000
Epoch 29, CIFAR-10 Batch 5:  loss: 1.777749
accuracy: 0.325000
Epoch 30, CIFAR-10 Batch 1:  loss: 1.565619
accuracy: 0.500000
Epoch 30, CIFAR-10 Batch 2:  loss: 1.495676
accuracy: 0.500000
Epoch 30, CIFAR-10 Batch 3:  loss: 1.629975
accuracy: 0.450000
Epoch 30, CIFAR-10 Batch 4:  loss: 1.746385
accuracy: 0.350000
Epoch 30, CIFAR-10 Batch 5:  loss: 1.758334
accuracy: 0.325000
Epoch 31, CIFAR-10 Batch 1:  loss: 1.643847
accuracy: 0.475000
Epoch 31, CIFAR-10 Batch 2:  loss: 1.487465
accuracy: 0.525000
Epoch 31, CIFAR-10 Batch 3:  loss: 1.617539
accuracy: 0.500000
Epoch 31, CIFAR-10 Batch 4:  loss: 1.726573
accuracy: 0.375000
Epoch 31, CIFAR-10 Batch 5:  loss: 1.746148
accuracy: 0.350000
Epoch 32, CIFAR-10 Batch 1:  loss: 1.634328
accuracy: 0.525000
Epoch 32, CIFAR-10 Batch 2:  loss: 1.485802
accuracy: 0.475000
Epoch 32, CIFAR-10 Batch 3:  loss: 1.584754
accuracy: 0.550000
Epoch 32, CIFAR-10 Batch 4:  loss: 1.741869
accuracy: 0.375000
Epoch 32, CIFAR-10 Batch 5:  loss: 1.755439
accuracy: 0.300000
Epoch 33, CIFAR-10 Batch 1:  loss: 1.612009
accuracy: 0.525000
Epoch 33, CIFAR-10 Batch 2:  loss: 1.477913
accuracy: 0.525000
Epoch 33, CIFAR-10 Batch 3:  loss: 1.583279
accuracy: 0.525000
Epoch 33, CIFAR-10 Batch 4:  loss: 1.759452
accuracy: 0.350000
Epoch 33, CIFAR-10 Batch 5:  loss: 1.745776
accuracy: 0.275000
Epoch 34, CIFAR-10 Batch 1:  loss: 1.582136
accuracy: 0.525000
Epoch 34, CIFAR-10 Batch 2:  loss: 1.452721
accuracy: 0.500000
Epoch 34, CIFAR-10 Batch 3:  loss: 1.565878
accuracy: 0.550000
Epoch 34, CIFAR-10 Batch 4:  loss: 1.734754
accuracy: 0.350000
Epoch 34, CIFAR-10 Batch 5:  loss: 1.745516
accuracy: 0.325000
Epoch 35, CIFAR-10 Batch 1:  loss: 1.564914
accuracy: 0.550000
Epoch 35, CIFAR-10 Batch 2:  loss: 1.424789
accuracy: 0.500000
Epoch 35, CIFAR-10 Batch 3:  loss: 1.554109
accuracy: 0.525000
Epoch 35, CIFAR-10 Batch 4:  loss: 1.728853
accuracy: 0.400000
Epoch 35, CIFAR-10 Batch 5:  loss: 1.730853
accuracy: 0.325000
Epoch 36, CIFAR-10 Batch 1:  loss: 1.561547
accuracy: 0.525000
Epoch 36, CIFAR-10 Batch 2:  loss: 1.405198
accuracy: 0.550000
Epoch 36, CIFAR-10 Batch 3:  loss: 1.544751
accuracy: 0.575000
Epoch 36, CIFAR-10 Batch 4:  loss: 1.722466
accuracy: 0.400000
Epoch 36, CIFAR-10 Batch 5:  loss: 1.725775
accuracy: 0.275000
Epoch 37, CIFAR-10 Batch 1:  loss: 1.575014
accuracy: 0.500000
Epoch 37, CIFAR-10 Batch 2:  loss: 1.412748
accuracy: 0.600000
Epoch 37, CIFAR-10 Batch 3:  loss: 1.531466
accuracy: 0.500000
Epoch 37, CIFAR-10 Batch 4:  loss: 1.703300
accuracy: 0.450000
Epoch 37, CIFAR-10 Batch 5:  loss: 1.704749
accuracy: 0.400000
Epoch 38, CIFAR-10 Batch 1:  loss: 1.536638
accuracy: 0.500000
Epoch 38, CIFAR-10 Batch 2:  loss: 1.393996
accuracy: 0.600000
Epoch 38, CIFAR-10 Batch 3:  loss: 1.521527
accuracy: 0.500000
Epoch 38, CIFAR-10 Batch 4:  loss: 1.692981
accuracy: 0.450000
Epoch 38, CIFAR-10 Batch 5:  loss: 1.697298
accuracy: 0.350000
Epoch 39, CIFAR-10 Batch 1:  loss: 1.518515
accuracy: 0.475000
Epoch 39, CIFAR-10 Batch 2:  loss: 1.370083
accuracy: 0.550000
Epoch 39, CIFAR-10 Batch 3:  loss: 1.460436
accuracy: 0.500000
Epoch 39, CIFAR-10 Batch 4:  loss: 1.673555
accuracy: 0.475000
Epoch 39, CIFAR-10 Batch 5:  loss: 1.655230
accuracy: 0.350000
Epoch 40, CIFAR-10 Batch 1:  loss: 1.507781
accuracy: 0.525000
Epoch 40, CIFAR-10 Batch 2:  loss: 1.331576
accuracy: 0.575000
Epoch 40, CIFAR-10 Batch 3:  loss: 1.452727
accuracy: 0.525000
Epoch 40, CIFAR-10 Batch 4:  loss: 1.660849
accuracy: 0.425000
Epoch 40, CIFAR-10 Batch 5:  loss: 1.670977
accuracy: 0.350000
Epoch 41, CIFAR-10 Batch 1:  loss: 1.483196
accuracy: 0.525000
Epoch 41, CIFAR-10 Batch 2:  loss: 1.334844
accuracy: 0.625000
Epoch 41, CIFAR-10 Batch 3:  loss: 1.414156
accuracy: 0.550000
Epoch 41, CIFAR-10 Batch 4:  loss: 1.625534
accuracy: 0.400000
Epoch 41, CIFAR-10 Batch 5:  loss: 1.630850
accuracy: 0.425000
Epoch 42, CIFAR-10 Batch 1:  loss: 1.444670
accuracy: 0.575000
Epoch 42, CIFAR-10 Batch 2:  loss: 1.313173
accuracy: 0.600000
Epoch 42, CIFAR-10 Batch 3:  loss: 1.430580
accuracy: 0.525000
Epoch 42, CIFAR-10 Batch 4:  loss: 1.654161
accuracy: 0.375000
Epoch 42, CIFAR-10 Batch 5:  loss: 1.620833
accuracy: 0.375000
Epoch 43, CIFAR-10 Batch 1:  loss: 1.429777
accuracy: 0.600000
Epoch 43, CIFAR-10 Batch 2:  loss: 1.313577
accuracy: 0.575000
Epoch 43, CIFAR-10 Batch 3:  loss: 1.426070
accuracy: 0.550000
Epoch 43, CIFAR-10 Batch 4:  loss: 1.625327
accuracy: 0.425000
Epoch 43, CIFAR-10 Batch 5:  loss: 1.635258
accuracy: 0.400000
Epoch 44, CIFAR-10 Batch 1:  loss: 1.393411
accuracy: 0.625000
Epoch 44, CIFAR-10 Batch 2:  loss: 1.258915
accuracy: 0.650000
Epoch 44, CIFAR-10 Batch 3:  loss: 1.425585
accuracy: 0.525000
Epoch 44, CIFAR-10 Batch 4:  loss: 1.605718
accuracy: 0.425000
Epoch 44, CIFAR-10 Batch 5:  loss: 1.612432
accuracy: 0.425000
Epoch 45, CIFAR-10 Batch 1:  loss: 1.310414
accuracy: 0.575000
Epoch 45, CIFAR-10 Batch 2:  loss: 1.270778
accuracy: 0.600000
Epoch 45, CIFAR-10 Batch 3:  loss: 1.452316
accuracy: 0.550000
Epoch 45, CIFAR-10 Batch 4:  loss: 1.592666
accuracy: 0.450000
Epoch 45, CIFAR-10 Batch 5:  loss: 1.630079
accuracy: 0.375000
Epoch 46, CIFAR-10 Batch 1:  loss: 1.394176
accuracy: 0.550000
Epoch 46, CIFAR-10 Batch 2:  loss: 1.244660
accuracy: 0.650000
Epoch 46, CIFAR-10 Batch 3:  loss: 1.423540
accuracy: 0.575000
Epoch 46, CIFAR-10 Batch 4:  loss: 1.596610
accuracy: 0.425000
Epoch 46, CIFAR-10 Batch 5:  loss: 1.581972
accuracy: 0.400000
Epoch 47, CIFAR-10 Batch 1:  loss: 1.385303
accuracy: 0.550000
Epoch 47, CIFAR-10 Batch 2:  loss: 1.242341
accuracy: 0.625000
Epoch 47, CIFAR-10 Batch 3:  loss: 1.420499
accuracy: 0.575000
Epoch 47, CIFAR-10 Batch 4:  loss: 1.624605
accuracy: 0.375000
Epoch 47, CIFAR-10 Batch 5:  loss: 1.560950
accuracy: 0.400000
Epoch 48, CIFAR-10 Batch 1:  loss: 1.359199
accuracy: 0.550000
Epoch 48, CIFAR-10 Batch 2:  loss: 1.225677
accuracy: 0.600000
Epoch 48, CIFAR-10 Batch 3:  loss: 1.402879
accuracy: 0.575000
Epoch 48, CIFAR-10 Batch 4:  loss: 1.608744
accuracy: 0.475000
Epoch 48, CIFAR-10 Batch 5:  loss: 1.588224
accuracy: 0.400000
Epoch 49, CIFAR-10 Batch 1:  loss: 1.342980
accuracy: 0.575000
Epoch 49, CIFAR-10 Batch 2:  loss: 1.221720
accuracy: 0.625000
Epoch 49, CIFAR-10 Batch 3:  loss: 1.380318
accuracy: 0.600000
Epoch 49, CIFAR-10 Batch 4:  loss: 1.600017
accuracy: 0.475000
Epoch 49, CIFAR-10 Batch 5:  loss: 1.552408
accuracy: 0.475000
Epoch 50, CIFAR-10 Batch 1:  loss: 1.296413
accuracy: 0.575000
Epoch 50, CIFAR-10 Batch 2:  loss: 1.214234
accuracy: 0.600000
Epoch 50, CIFAR-10 Batch 3:  loss: 1.415256
accuracy: 0.525000
Epoch 50, CIFAR-10 Batch 4:  loss: 1.611652
accuracy: 0.425000
Epoch 50, CIFAR-10 Batch 5:  loss: 1.544683
accuracy: 0.450000
Epoch 51, CIFAR-10 Batch 1:  loss: 1.244788
accuracy: 0.600000
Epoch 51, CIFAR-10 Batch 2:  loss: 1.203761
accuracy: 0.650000
Epoch 51, CIFAR-10 Batch 3:  loss: 1.426482
accuracy: 0.550000
Epoch 51, CIFAR-10 Batch 4:  loss: 1.628001
accuracy: 0.400000
Epoch 51, CIFAR-10 Batch 5:  loss: 1.543362
accuracy: 0.425000
Epoch 52, CIFAR-10 Batch 1:  loss: 1.291509
accuracy: 0.600000
Epoch 52, CIFAR-10 Batch 2:  loss: 1.225145
accuracy: 0.600000
Epoch 52, CIFAR-10 Batch 3:  loss: 1.408215
accuracy: 0.575000
Epoch 52, CIFAR-10 Batch 4:  loss: 1.600119
accuracy: 0.325000
Epoch 52, CIFAR-10 Batch 5:  loss: 1.538165
accuracy: 0.450000
Epoch 53, CIFAR-10 Batch 1:  loss: 1.266075
accuracy: 0.600000
Epoch 53, CIFAR-10 Batch 2:  loss: 1.217520
accuracy: 0.650000
Epoch 53, CIFAR-10 Batch 3:  loss: 1.406933
accuracy: 0.575000
Epoch 53, CIFAR-10 Batch 4:  loss: 1.601449
accuracy: 0.400000
Epoch 53, CIFAR-10 Batch 5:  loss: 1.540599
accuracy: 0.450000
Epoch 54, CIFAR-10 Batch 1:  loss: 1.194541
accuracy: 0.650000
Epoch 54, CIFAR-10 Batch 2:  loss: 1.190429
accuracy: 0.625000
Epoch 54, CIFAR-10 Batch 3:  loss: 1.413211
accuracy: 0.600000
Epoch 54, CIFAR-10 Batch 4:  loss: 1.610981
accuracy: 0.350000
Epoch 54, CIFAR-10 Batch 5:  loss: 1.523883
accuracy: 0.475000
Epoch 55, CIFAR-10 Batch 1:  loss: 1.173360
accuracy: 0.650000
Epoch 55, CIFAR-10 Batch 2:  loss: 1.195305
accuracy: 0.600000
Epoch 55, CIFAR-10 Batch 3:  loss: 1.409773
accuracy: 0.600000
Epoch 55, CIFAR-10 Batch 4:  loss: 1.598159
accuracy: 0.450000
Epoch 55, CIFAR-10 Batch 5:  loss: 1.514984
accuracy: 0.500000
Epoch 56, CIFAR-10 Batch 1:  loss: 1.163777
accuracy: 0.675000
Epoch 56, CIFAR-10 Batch 2:  loss: 1.203829
accuracy: 0.650000
Epoch 56, CIFAR-10 Batch 3:  loss: 1.418854
accuracy: 0.550000
Epoch 56, CIFAR-10 Batch 4:  loss: 1.605948
accuracy: 0.400000
Epoch 56, CIFAR-10 Batch 5:  loss: 1.501730
accuracy: 0.475000
Epoch 57, CIFAR-10 Batch 1:  loss: 1.171252
accuracy: 0.650000
Epoch 57, CIFAR-10 Batch 2:  loss: 1.226066
accuracy: 0.650000
Epoch 57, CIFAR-10 Batch 3:  loss: 1.431549
accuracy: 0.600000
Epoch 57, CIFAR-10 Batch 4:  loss: 1.570312
accuracy: 0.425000
Epoch 57, CIFAR-10 Batch 5:  loss: 1.516255
accuracy: 0.475000
Epoch 58, CIFAR-10 Batch 1:  loss: 1.179098
accuracy: 0.550000
Epoch 58, CIFAR-10 Batch 2:  loss: 1.211766
accuracy: 0.625000
Epoch 58, CIFAR-10 Batch 3:  loss: 1.397726
accuracy: 0.600000
Epoch 58, CIFAR-10 Batch 4:  loss: 1.591537
accuracy: 0.400000
Epoch 58, CIFAR-10 Batch 5:  loss: 1.501495
accuracy: 0.450000
Epoch 59, CIFAR-10 Batch 1:  loss: 1.160094
accuracy: 0.575000
Epoch 59, CIFAR-10 Batch 2:  loss: 1.189481
accuracy: 0.600000
Epoch 59, CIFAR-10 Batch 3:  loss: 1.393981
accuracy: 0.600000
Epoch 59, CIFAR-10 Batch 4:  loss: 1.567123
accuracy: 0.450000
Epoch 59, CIFAR-10 Batch 5:  loss: 1.476236
accuracy: 0.475000
Epoch 60, CIFAR-10 Batch 1:  loss: 1.131955
accuracy: 0.600000
Epoch 60, CIFAR-10 Batch 2:  loss: 1.172773
accuracy: 0.625000
Epoch 60, CIFAR-10 Batch 3:  loss: 1.398744
accuracy: 0.575000
Epoch 60, CIFAR-10 Batch 4:  loss: 1.548442
accuracy: 0.425000
Epoch 60, CIFAR-10 Batch 5:  loss: 1.499647
accuracy: 0.475000
Epoch 61, CIFAR-10 Batch 1:  loss: 1.124869
accuracy: 0.575000
Epoch 61, CIFAR-10 Batch 2:  loss: 1.204721
accuracy: 0.650000
Epoch 61, CIFAR-10 Batch 3:  loss: 1.380762
accuracy: 0.625000
Epoch 61, CIFAR-10 Batch 4:  loss: 1.534739
accuracy: 0.375000
Epoch 61, CIFAR-10 Batch 5:  loss: 1.518853
accuracy: 0.450000
Epoch 62, CIFAR-10 Batch 1:  loss: 1.142664
accuracy: 0.625000
Epoch 62, CIFAR-10 Batch 2:  loss: 1.228167
accuracy: 0.700000
Epoch 62, CIFAR-10 Batch 3:  loss: 1.378769
accuracy: 0.625000
Epoch 62, CIFAR-10 Batch 4:  loss: 1.533587
accuracy: 0.400000
Epoch 62, CIFAR-10 Batch 5:  loss: 1.483340
accuracy: 0.500000
Epoch 63, CIFAR-10 Batch 1:  loss: 1.103313
accuracy: 0.600000
Epoch 63, CIFAR-10 Batch 2:  loss: 1.223774
accuracy: 0.650000
Epoch 63, CIFAR-10 Batch 3:  loss: 1.366656
accuracy: 0.650000
Epoch 63, CIFAR-10 Batch 4:  loss: 1.491096
accuracy: 0.425000
Epoch 63, CIFAR-10 Batch 5:  loss: 1.508358
accuracy: 0.450000
Epoch 64, CIFAR-10 Batch 1:  loss: 1.114636
accuracy: 0.650000
Epoch 64, CIFAR-10 Batch 2:  loss: 1.169229
accuracy: 0.600000
Epoch 64, CIFAR-10 Batch 3:  loss: 1.383330
accuracy: 0.600000
Epoch 64, CIFAR-10 Batch 4:  loss: 1.525921
accuracy: 0.425000
Epoch 64, CIFAR-10 Batch 5:  loss: 1.485300
accuracy: 0.500000
Epoch 65, CIFAR-10 Batch 1:  loss: 1.116554
accuracy: 0.600000
Epoch 65, CIFAR-10 Batch 2:  loss: 1.192780
accuracy: 0.600000
Epoch 65, CIFAR-10 Batch 3:  loss: 1.378777
accuracy: 0.625000
Epoch 65, CIFAR-10 Batch 4:  loss: 1.492205
accuracy: 0.400000
Epoch 65, CIFAR-10 Batch 5:  loss: 1.460225
accuracy: 0.525000
Epoch 66, CIFAR-10 Batch 1:  loss: 1.101542
accuracy: 0.600000
Epoch 66, CIFAR-10 Batch 2:  loss: 1.182437
accuracy: 0.625000
Epoch 66, CIFAR-10 Batch 3:  loss: 1.364096
accuracy: 0.625000
Epoch 66, CIFAR-10 Batch 4:  loss: 1.507047
accuracy: 0.425000
Epoch 66, CIFAR-10 Batch 5:  loss: 1.501618
accuracy: 0.475000
Epoch 67, CIFAR-10 Batch 1:  loss: 1.104219
accuracy: 0.575000
Epoch 67, CIFAR-10 Batch 2:  loss: 1.209327
accuracy: 0.650000
Epoch 67, CIFAR-10 Batch 3:  loss: 1.362295
accuracy: 0.650000
Epoch 67, CIFAR-10 Batch 4:  loss: 1.493330
accuracy: 0.425000
Epoch 67, CIFAR-10 Batch 5:  loss: 1.452484
accuracy: 0.500000
Epoch 68, CIFAR-10 Batch 1:  loss: 1.089342
accuracy: 0.625000
Epoch 68, CIFAR-10 Batch 2:  loss: 1.178849
accuracy: 0.625000
Epoch 68, CIFAR-10 Batch 3:  loss: 1.371048
accuracy: 0.525000
Epoch 68, CIFAR-10 Batch 4:  loss: 1.503947
accuracy: 0.425000
Epoch 68, CIFAR-10 Batch 5:  loss: 1.429780
accuracy: 0.550000
Epoch 69, CIFAR-10 Batch 1:  loss: 1.114093
accuracy: 0.600000
Epoch 69, CIFAR-10 Batch 2:  loss: 1.192650
accuracy: 0.650000
Epoch 69, CIFAR-10 Batch 3:  loss: 1.380996
accuracy: 0.550000
Epoch 69, CIFAR-10 Batch 4:  loss: 1.467174
accuracy: 0.450000
Epoch 69, CIFAR-10 Batch 5:  loss: 1.438088
accuracy: 0.500000
Epoch 70, CIFAR-10 Batch 1:  loss: 1.103845
accuracy: 0.600000
Epoch 70, CIFAR-10 Batch 2:  loss: 1.141314
accuracy: 0.725000
Epoch 70, CIFAR-10 Batch 3:  loss: 1.330021
accuracy: 0.650000
Epoch 70, CIFAR-10 Batch 4:  loss: 1.458110
accuracy: 0.400000
Epoch 70, CIFAR-10 Batch 5:  loss: 1.437784
accuracy: 0.500000
Epoch 71, CIFAR-10 Batch 1:  loss: 1.128549
accuracy: 0.600000
Epoch 71, CIFAR-10 Batch 2:  loss: 1.151840
accuracy: 0.650000
Epoch 71, CIFAR-10 Batch 3:  loss: 1.356115
accuracy: 0.625000
Epoch 71, CIFAR-10 Batch 4:  loss: 1.411978
accuracy: 0.450000
Epoch 71, CIFAR-10 Batch 5:  loss: 1.436535
accuracy: 0.525000
Epoch 72, CIFAR-10 Batch 1:  loss: 1.122621
accuracy: 0.600000
Epoch 72, CIFAR-10 Batch 2:  loss: 1.154822
accuracy: 0.625000
Epoch 72, CIFAR-10 Batch 3:  loss: 1.348826
accuracy: 0.700000
Epoch 72, CIFAR-10 Batch 4:  loss: 1.448378
accuracy: 0.450000
Epoch 72, CIFAR-10 Batch 5:  loss: 1.434138
accuracy: 0.525000
Epoch 73, CIFAR-10 Batch 1:  loss: 1.124826
accuracy: 0.525000
Epoch 73, CIFAR-10 Batch 2:  loss: 1.144924
accuracy: 0.700000
Epoch 73, CIFAR-10 Batch 3:  loss: 1.384650
accuracy: 0.575000
Epoch 73, CIFAR-10 Batch 4:  loss: 1.406163
accuracy: 0.500000
Epoch 73, CIFAR-10 Batch 5:  loss: 1.424831
accuracy: 0.525000
Epoch 74, CIFAR-10 Batch 1:  loss: 1.133997
accuracy: 0.600000
Epoch 74, CIFAR-10 Batch 2:  loss: 1.176921
accuracy: 0.625000
Epoch 74, CIFAR-10 Batch 3:  loss: 1.305720
accuracy: 0.650000
Epoch 74, CIFAR-10 Batch 4:  loss: 1.418005
accuracy: 0.500000
Epoch 74, CIFAR-10 Batch 5:  loss: 1.399087
accuracy: 0.550000
Epoch 75, CIFAR-10 Batch 1:  loss: 1.135964
accuracy: 0.625000
Epoch 75, CIFAR-10 Batch 2:  loss: 1.161272
accuracy: 0.675000
Epoch 75, CIFAR-10 Batch 3:  loss: 1.299290
accuracy: 0.675000
Epoch 75, CIFAR-10 Batch 4:  loss: 1.393170
accuracy: 0.525000
Epoch 75, CIFAR-10 Batch 5:  loss: 1.395740
accuracy: 0.575000
Epoch 76, CIFAR-10 Batch 1:  loss: 1.134162
accuracy: 0.625000
Epoch 76, CIFAR-10 Batch 2:  loss: 1.128832
accuracy: 0.625000
Epoch 76, CIFAR-10 Batch 3:  loss: 1.314473
accuracy: 0.650000
Epoch 76, CIFAR-10 Batch 4:  loss: 1.373200
accuracy: 0.500000
Epoch 76, CIFAR-10 Batch 5:  loss: 1.392773
accuracy: 0.550000
Epoch 77, CIFAR-10 Batch 1:  loss: 1.110668
accuracy: 0.650000
Epoch 77, CIFAR-10 Batch 2:  loss: 1.068703
accuracy: 0.725000
Epoch 77, CIFAR-10 Batch 3:  loss: 1.284986
accuracy: 0.675000
Epoch 77, CIFAR-10 Batch 4:  loss: 1.388695
accuracy: 0.450000
Epoch 77, CIFAR-10 Batch 5:  loss: 1.367994
accuracy: 0.575000
Epoch 78, CIFAR-10 Batch 1:  loss: 1.093288
accuracy: 0.650000
Epoch 78, CIFAR-10 Batch 2:  loss: 1.115082
accuracy: 0.650000
Epoch 78, CIFAR-10 Batch 3:  loss: 1.312313
accuracy: 0.600000
Epoch 78, CIFAR-10 Batch 4:  loss: 1.387827
accuracy: 0.500000
Epoch 78, CIFAR-10 Batch 5:  loss: 1.382812
accuracy: 0.550000
Epoch 79, CIFAR-10 Batch 1:  loss: 1.111894
accuracy: 0.600000
Epoch 79, CIFAR-10 Batch 2:  loss: 1.060101
accuracy: 0.725000
Epoch 79, CIFAR-10 Batch 3:  loss: 1.341583
accuracy: 0.600000
Epoch 79, CIFAR-10 Batch 4:  loss: 1.372068
accuracy: 0.450000
Epoch 79, CIFAR-10 Batch 5:  loss: 1.399670
accuracy: 0.575000
Epoch 80, CIFAR-10 Batch 1:  loss: 1.095380
accuracy: 0.675000
Epoch 80, CIFAR-10 Batch 2:  loss: 1.040625
accuracy: 0.700000
Epoch 80, CIFAR-10 Batch 3:  loss: 1.322842
accuracy: 0.575000
Epoch 80, CIFAR-10 Batch 4:  loss: 1.359256
accuracy: 0.475000
Epoch 80, CIFAR-10 Batch 5:  loss: 1.394027
accuracy: 0.550000
Epoch 81, CIFAR-10 Batch 1:  loss: 1.080541
accuracy: 0.675000
Epoch 81, CIFAR-10 Batch 2:  loss: 1.064542
accuracy: 0.675000
Epoch 81, CIFAR-10 Batch 3:  loss: 1.271997
accuracy: 0.650000
Epoch 81, CIFAR-10 Batch 4:  loss: 1.368574
accuracy: 0.500000
Epoch 81, CIFAR-10 Batch 5:  loss: 1.397174
accuracy: 0.550000
Epoch 82, CIFAR-10 Batch 1:  loss: 1.098637
accuracy: 0.675000
Epoch 82, CIFAR-10 Batch 2:  loss: 1.032552
accuracy: 0.675000
Epoch 82, CIFAR-10 Batch 3:  loss: 1.267284
accuracy: 0.650000
Epoch 82, CIFAR-10 Batch 4:  loss: 1.389216
accuracy: 0.500000
Epoch 82, CIFAR-10 Batch 5:  loss: 1.371336
accuracy: 0.550000
Epoch 83, CIFAR-10 Batch 1:  loss: 1.092820
accuracy: 0.625000
Epoch 83, CIFAR-10 Batch 2:  loss: 1.016051
accuracy: 0.675000
Epoch 83, CIFAR-10 Batch 3:  loss: 1.263782
accuracy: 0.625000
Epoch 83, CIFAR-10 Batch 4:  loss: 1.374207
accuracy: 0.575000
Epoch 83, CIFAR-10 Batch 5:  loss: 1.394159
accuracy: 0.525000
Epoch 84, CIFAR-10 Batch 1:  loss: 1.082803
accuracy: 0.650000
Epoch 84, CIFAR-10 Batch 2:  loss: 1.075130
accuracy: 0.675000
Epoch 84, CIFAR-10 Batch 3:  loss: 1.297772
accuracy: 0.625000
Epoch 84, CIFAR-10 Batch 4:  loss: 1.336219
accuracy: 0.550000
Epoch 84, CIFAR-10 Batch 5:  loss: 1.377227
accuracy: 0.550000
Epoch 85, CIFAR-10 Batch 1:  loss: 1.083215
accuracy: 0.675000
Epoch 85, CIFAR-10 Batch 2:  loss: 0.997356
accuracy: 0.675000
Epoch 85, CIFAR-10 Batch 3:  loss: 1.329500
accuracy: 0.575000
Epoch 85, CIFAR-10 Batch 4:  loss: 1.360029
accuracy: 0.550000
Epoch 85, CIFAR-10 Batch 5:  loss: 1.349801
accuracy: 0.550000
Epoch 86, CIFAR-10 Batch 1:  loss: 1.089012
accuracy: 0.650000
Epoch 86, CIFAR-10 Batch 2:  loss: 1.016777
accuracy: 0.700000
Epoch 86, CIFAR-10 Batch 3:  loss: 1.276314
accuracy: 0.625000
Epoch 86, CIFAR-10 Batch 4:  loss: 1.356540
accuracy: 0.550000
Epoch 86, CIFAR-10 Batch 5:  loss: 1.346792
accuracy: 0.550000
Epoch 87, CIFAR-10 Batch 1:  loss: 1.091980
accuracy: 0.675000
Epoch 87, CIFAR-10 Batch 2:  loss: 1.004242
accuracy: 0.675000
Epoch 87, CIFAR-10 Batch 3:  loss: 1.268553
accuracy: 0.650000
Epoch 87, CIFAR-10 Batch 4:  loss: 1.396216
accuracy: 0.525000
Epoch 87, CIFAR-10 Batch 5:  loss: 1.366414
accuracy: 0.600000
Epoch 88, CIFAR-10 Batch 1:  loss: 1.264697
accuracy: 0.650000
Epoch 88, CIFAR-10 Batch 2:  loss: 0.978381
accuracy: 0.675000
Epoch 88, CIFAR-10 Batch 3:  loss: 1.268774
accuracy: 0.700000
Epoch 88, CIFAR-10 Batch 4:  loss: 1.347910
accuracy: 0.575000
Epoch 88, CIFAR-10 Batch 5:  loss: 1.375397
accuracy: 0.500000
Epoch 89, CIFAR-10 Batch 1:  loss: 1.051114
accuracy: 0.675000
Epoch 89, CIFAR-10 Batch 2:  loss: 0.992069
accuracy: 0.725000
Epoch 89, CIFAR-10 Batch 3:  loss: 1.274111
accuracy: 0.625000
Epoch 89, CIFAR-10 Batch 4:  loss: 1.351204
accuracy: 0.525000
Epoch 89, CIFAR-10 Batch 5:  loss: 1.357713
accuracy: 0.575000
Epoch 90, CIFAR-10 Batch 1:  loss: 1.055651
accuracy: 0.725000
Epoch 90, CIFAR-10 Batch 2:  loss: 0.957199
accuracy: 0.700000
Epoch 90, CIFAR-10 Batch 3:  loss: 1.253330
accuracy: 0.650000
Epoch 90, CIFAR-10 Batch 4:  loss: 1.312437
accuracy: 0.575000
Epoch 90, CIFAR-10 Batch 5:  loss: 1.333103
accuracy: 0.600000
Epoch 91, CIFAR-10 Batch 1:  loss: 1.054454
accuracy: 0.675000
Epoch 91, CIFAR-10 Batch 2:  loss: 0.964288
accuracy: 0.725000
Epoch 91, CIFAR-10 Batch 3:  loss: 1.241484
accuracy: 0.650000
Epoch 91, CIFAR-10 Batch 4:  loss: 1.287147
accuracy: 0.550000
Epoch 91, CIFAR-10 Batch 5:  loss: 1.361680
accuracy: 0.525000
Epoch 92, CIFAR-10 Batch 1:  loss: 1.062131
accuracy: 0.625000
Epoch 92, CIFAR-10 Batch 2:  loss: 0.961622
accuracy: 0.725000
Epoch 92, CIFAR-10 Batch 3:  loss: 1.229854
accuracy: 0.600000
Epoch 92, CIFAR-10 Batch 4:  loss: 1.327223
accuracy: 0.575000
Epoch 92, CIFAR-10 Batch 5:  loss: 1.315608
accuracy: 0.600000
Epoch 93, CIFAR-10 Batch 1:  loss: 1.045519
accuracy: 0.675000
Epoch 93, CIFAR-10 Batch 2:  loss: 0.978147
accuracy: 0.675000
Epoch 93, CIFAR-10 Batch 3:  loss: 1.235258
accuracy: 0.675000
Epoch 93, CIFAR-10 Batch 4:  loss: 1.406186
accuracy: 0.500000
Epoch 93, CIFAR-10 Batch 5:  loss: 1.340538
accuracy: 0.525000
Epoch 94, CIFAR-10 Batch 1:  loss: 1.052716
accuracy: 0.675000
Epoch 94, CIFAR-10 Batch 2:  loss: 1.012308
accuracy: 0.700000
Epoch 94, CIFAR-10 Batch 3:  loss: 1.289811
accuracy: 0.550000
Epoch 94, CIFAR-10 Batch 4:  loss: 1.330139
accuracy: 0.550000
Epoch 94, CIFAR-10 Batch 5:  loss: 1.366597
accuracy: 0.575000
Epoch 95, CIFAR-10 Batch 1:  loss: 1.055218
accuracy: 0.675000
Epoch 95, CIFAR-10 Batch 2:  loss: 0.985720
accuracy: 0.675000
Epoch 95, CIFAR-10 Batch 3:  loss: 1.231925
accuracy: 0.600000
Epoch 95, CIFAR-10 Batch 4:  loss: 1.333819
accuracy: 0.550000
Epoch 95, CIFAR-10 Batch 5:  loss: 1.381933
accuracy: 0.575000
Epoch 96, CIFAR-10 Batch 1:  loss: 1.059627
accuracy: 0.675000
Epoch 96, CIFAR-10 Batch 2:  loss: 0.990926
accuracy: 0.675000
Epoch 96, CIFAR-10 Batch 3:  loss: 1.247950
accuracy: 0.600000
Epoch 96, CIFAR-10 Batch 4:  loss: 1.314539
accuracy: 0.600000
Epoch 96, CIFAR-10 Batch 5:  loss: 1.373740
accuracy: 0.575000
Epoch 97, CIFAR-10 Batch 1:  loss: 1.034202
accuracy: 0.650000
Epoch 97, CIFAR-10 Batch 2:  loss: 0.979612
accuracy: 0.700000
Epoch 97, CIFAR-10 Batch 3:  loss: 1.212974
accuracy: 0.650000
Epoch 97, CIFAR-10 Batch 4:  loss: 1.357584
accuracy: 0.475000
Epoch 97, CIFAR-10 Batch 5:  loss: 1.368068
accuracy: 0.550000
Epoch 98, CIFAR-10 Batch 1:  loss: 1.017130
accuracy: 0.675000
Epoch 98, CIFAR-10 Batch 2:  loss: 0.979363
accuracy: 0.700000
Epoch 98, CIFAR-10 Batch 3:  loss: 1.224327
accuracy: 0.675000
Epoch 98, CIFAR-10 Batch 4:  loss: 1.309314
accuracy: 0.600000
Epoch 98, CIFAR-10 Batch 5:  loss: 1.350406
accuracy: 0.550000
Epoch 99, CIFAR-10 Batch 1:  loss: 1.027116
accuracy: 0.650000
Epoch 99, CIFAR-10 Batch 2:  loss: 0.923211
accuracy: 0.725000
Epoch 99, CIFAR-10 Batch 3:  loss: 1.272626
accuracy: 0.625000
Epoch 99, CIFAR-10 Batch 4:  loss: 1.284670
accuracy: 0.600000
Epoch 99, CIFAR-10 Batch 5:  loss: 1.355216
accuracy: 0.550000
Epoch 100, CIFAR-10 Batch 1:  loss: 1.020145
accuracy: 0.650000
Epoch 100, CIFAR-10 Batch 2:  loss: 0.926124
accuracy: 0.700000
Epoch 100, CIFAR-10 Batch 3:  loss: 1.220857
accuracy: 0.650000
Epoch 100, CIFAR-10 Batch 4:  loss: 1.309131
accuracy: 0.600000
Epoch 100, CIFAR-10 Batch 5:  loss: 1.359278
accuracy: 0.600000
Epoch 101, CIFAR-10 Batch 1:  loss: 1.018456
accuracy: 0.700000
Epoch 101, CIFAR-10 Batch 2:  loss: 0.904025
accuracy: 0.700000
Epoch 101, CIFAR-10 Batch 3:  loss: 1.221939
accuracy: 0.625000
Epoch 101, CIFAR-10 Batch 4:  loss: 1.320784
accuracy: 0.600000
Epoch 101, CIFAR-10 Batch 5:  loss: 1.370673
accuracy: 0.550000
Epoch 102, CIFAR-10 Batch 1:  loss: 1.009405
accuracy: 0.675000
Epoch 102, CIFAR-10 Batch 2:  loss: 0.882689
accuracy: 0.725000
Epoch 102, CIFAR-10 Batch 3:  loss: 1.199756
accuracy: 0.650000
Epoch 102, CIFAR-10 Batch 4:  loss: 1.327007
accuracy: 0.575000
Epoch 102, CIFAR-10 Batch 5:  loss: 1.331036
accuracy: 0.550000
Epoch 103, CIFAR-10 Batch 1:  loss: 1.033934
accuracy: 0.625000
Epoch 103, CIFAR-10 Batch 2:  loss: 0.934518
accuracy: 0.725000
Epoch 103, CIFAR-10 Batch 3:  loss: 1.234013
accuracy: 0.625000
Epoch 103, CIFAR-10 Batch 4:  loss: 1.364754
accuracy: 0.525000
Epoch 103, CIFAR-10 Batch 5:  loss: 1.418766
accuracy: 0.500000
Epoch 104, CIFAR-10 Batch 1:  loss: 1.005009
accuracy: 0.675000
Epoch 104, CIFAR-10 Batch 2:  loss: 0.925429
accuracy: 0.675000
Epoch 104, CIFAR-10 Batch 3:  loss: 1.201309
accuracy: 0.675000
Epoch 104, CIFAR-10 Batch 4:  loss: 1.305334
accuracy: 0.575000
Epoch 104, CIFAR-10 Batch 5:  loss: 1.434525
accuracy: 0.450000
Epoch 105, CIFAR-10 Batch 1:  loss: 0.982437
accuracy: 0.725000
Epoch 105, CIFAR-10 Batch 2:  loss: 0.901319
accuracy: 0.700000
Epoch 105, CIFAR-10 Batch 3:  loss: 1.226502
accuracy: 0.700000
Epoch 105, CIFAR-10 Batch 4:  loss: 1.323297
accuracy: 0.500000
Epoch 105, CIFAR-10 Batch 5:  loss: 1.366786
accuracy: 0.550000
Epoch 106, CIFAR-10 Batch 1:  loss: 0.974641
accuracy: 0.675000
Epoch 106, CIFAR-10 Batch 2:  loss: 0.972229
accuracy: 0.675000
Epoch 106, CIFAR-10 Batch 3:  loss: 1.188279
accuracy: 0.625000
Epoch 106, CIFAR-10 Batch 4:  loss: 1.302347
accuracy: 0.575000
Epoch 106, CIFAR-10 Batch 5:  loss: 1.386477
accuracy: 0.550000
Epoch 107, CIFAR-10 Batch 1:  loss: 0.991080
accuracy: 0.750000
Epoch 107, CIFAR-10 Batch 2:  loss: 0.915550
accuracy: 0.700000
Epoch 107, CIFAR-10 Batch 3:  loss: 1.201829
accuracy: 0.675000
Epoch 107, CIFAR-10 Batch 4:  loss: 1.315365
accuracy: 0.550000
Epoch 107, CIFAR-10 Batch 5:  loss: 1.382728
accuracy: 0.575000
Epoch 108, CIFAR-10 Batch 1:  loss: 0.974493
accuracy: 0.675000
Epoch 108, CIFAR-10 Batch 2:  loss: 0.922264
accuracy: 0.700000
Epoch 108, CIFAR-10 Batch 3:  loss: 1.220829
accuracy: 0.625000
Epoch 108, CIFAR-10 Batch 4:  loss: 1.324353
accuracy: 0.550000
Epoch 108, CIFAR-10 Batch 5:  loss: 1.357363
accuracy: 0.550000
Epoch 109, CIFAR-10 Batch 1:  loss: 0.964987
accuracy: 0.700000
Epoch 109, CIFAR-10 Batch 2:  loss: 0.891168
accuracy: 0.675000
Epoch 109, CIFAR-10 Batch 3:  loss: 1.207991
accuracy: 0.675000
Epoch 109, CIFAR-10 Batch 4:  loss: 1.329572
accuracy: 0.600000
Epoch 109, CIFAR-10 Batch 5:  loss: 1.347429
accuracy: 0.575000
Epoch 110, CIFAR-10 Batch 1:  loss: 0.984362
accuracy: 0.675000
Epoch 110, CIFAR-10 Batch 2:  loss: 0.902909
accuracy: 0.725000
Epoch 110, CIFAR-10 Batch 3:  loss: 1.200863
accuracy: 0.675000
Epoch 110, CIFAR-10 Batch 4:  loss: 1.310743
accuracy: 0.550000
Epoch 110, CIFAR-10 Batch 5:  loss: 1.364783
accuracy: 0.550000
Epoch 111, CIFAR-10 Batch 1:  loss: 0.978653
accuracy: 0.650000
Epoch 111, CIFAR-10 Batch 2:  loss: 0.919696
accuracy: 0.675000
Epoch 111, CIFAR-10 Batch 3:  loss: 1.145015
accuracy: 0.725000
Epoch 111, CIFAR-10 Batch 4:  loss: 1.305554
accuracy: 0.625000
Epoch 111, CIFAR-10 Batch 5:  loss: 1.374534
accuracy: 0.575000
Epoch 112, CIFAR-10 Batch 1:  loss: 0.981277
accuracy: 0.675000
Epoch 112, CIFAR-10 Batch 2:  loss: 0.898935
accuracy: 0.725000
Epoch 112, CIFAR-10 Batch 3:  loss: 1.219787
accuracy: 0.650000
Epoch 112, CIFAR-10 Batch 4:  loss: 1.290729
accuracy: 0.575000
Epoch 112, CIFAR-10 Batch 5:  loss: 1.336862
accuracy: 0.550000
Epoch 113, CIFAR-10 Batch 1:  loss: 0.969298
accuracy: 0.700000
Epoch 113, CIFAR-10 Batch 2:  loss: 0.937805
accuracy: 0.675000
Epoch 113, CIFAR-10 Batch 3:  loss: 1.213221
accuracy: 0.650000
Epoch 113, CIFAR-10 Batch 4:  loss: 1.292124
accuracy: 0.575000
Epoch 113, CIFAR-10 Batch 5:  loss: 1.404763
accuracy: 0.550000
Epoch 114, CIFAR-10 Batch 1:  loss: 0.980952
accuracy: 0.675000
Epoch 114, CIFAR-10 Batch 2:  loss: 0.924431
accuracy: 0.675000
Epoch 114, CIFAR-10 Batch 3:  loss: 1.253773
accuracy: 0.600000
Epoch 114, CIFAR-10 Batch 4:  loss: 1.330517
accuracy: 0.575000
Epoch 114, CIFAR-10 Batch 5:  loss: 1.341956
accuracy: 0.575000
Epoch 115, CIFAR-10 Batch 1:  loss: 0.983506
accuracy: 0.700000
Epoch 115, CIFAR-10 Batch 2:  loss: 0.912110
accuracy: 0.725000
Epoch 115, CIFAR-10 Batch 3:  loss: 1.361426
accuracy: 0.650000
Epoch 115, CIFAR-10 Batch 4:  loss: 1.296988
accuracy: 0.575000
Epoch 115, CIFAR-10 Batch 5:  loss: 1.306363
accuracy: 0.575000
Epoch 116, CIFAR-10 Batch 1:  loss: 0.988863
accuracy: 0.625000
Epoch 116, CIFAR-10 Batch 2:  loss: 0.878984
accuracy: 0.700000
Epoch 116, CIFAR-10 Batch 3:  loss: 1.303740
accuracy: 0.625000
Epoch 116, CIFAR-10 Batch 4:  loss: 1.301721
accuracy: 0.600000
Epoch 116, CIFAR-10 Batch 5:  loss: 1.358175
accuracy: 0.525000
Epoch 117, CIFAR-10 Batch 1:  loss: 0.966762
accuracy: 0.700000
Epoch 117, CIFAR-10 Batch 2:  loss: 0.892868
accuracy: 0.700000
Epoch 117, CIFAR-10 Batch 3:  loss: 1.194550
accuracy: 0.700000
Epoch 117, CIFAR-10 Batch 4:  loss: 1.299574
accuracy: 0.625000
Epoch 117, CIFAR-10 Batch 5:  loss: 1.313145
accuracy: 0.575000
Epoch 118, CIFAR-10 Batch 1:  loss: 0.955109
accuracy: 0.700000
Epoch 118, CIFAR-10 Batch 2:  loss: 0.913209
accuracy: 0.700000
Epoch 118, CIFAR-10 Batch 3:  loss: 1.214077
accuracy: 0.675000
Epoch 118, CIFAR-10 Batch 4:  loss: 1.281070
accuracy: 0.625000
Epoch 118, CIFAR-10 Batch 5:  loss: 1.303673
accuracy: 0.550000
Epoch 119, CIFAR-10 Batch 1:  loss: 0.964585
accuracy: 0.675000
Epoch 119, CIFAR-10 Batch 2:  loss: 0.880486
accuracy: 0.700000
Epoch 119, CIFAR-10 Batch 3:  loss: 1.173402
accuracy: 0.700000
Epoch 119, CIFAR-10 Batch 4:  loss: 1.292169
accuracy: 0.625000
Epoch 119, CIFAR-10 Batch 5:  loss: 1.311576
accuracy: 0.550000
Epoch 120, CIFAR-10 Batch 1:  loss: 0.950913
accuracy: 0.675000
Epoch 120, CIFAR-10 Batch 2:  loss: 0.876208
accuracy: 0.675000
Epoch 120, CIFAR-10 Batch 3:  loss: 1.146846
accuracy: 0.700000
Epoch 120, CIFAR-10 Batch 4:  loss: 1.288689
accuracy: 0.600000
Epoch 120, CIFAR-10 Batch 5:  loss: 1.288275
accuracy: 0.575000
Epoch 121, CIFAR-10 Batch 1:  loss: 0.976303
accuracy: 0.700000
Epoch 121, CIFAR-10 Batch 2:  loss: 0.932432
accuracy: 0.675000
Epoch 121, CIFAR-10 Batch 3:  loss: 1.151838
accuracy: 0.700000
Epoch 121, CIFAR-10 Batch 4:  loss: 1.319188
accuracy: 0.625000
Epoch 121, CIFAR-10 Batch 5:  loss: 1.340616
accuracy: 0.550000
Epoch 122, CIFAR-10 Batch 1:  loss: 0.937878
accuracy: 0.700000
Epoch 122, CIFAR-10 Batch 2:  loss: 0.887631
accuracy: 0.725000
Epoch 122, CIFAR-10 Batch 3:  loss: 1.165544
accuracy: 0.650000
Epoch 122, CIFAR-10 Batch 4:  loss: 1.319520
accuracy: 0.600000
Epoch 122, CIFAR-10 Batch 5:  loss: 1.342446
accuracy: 0.500000
Epoch 123, CIFAR-10 Batch 1:  loss: 0.963515
accuracy: 0.700000
Epoch 123, CIFAR-10 Batch 2:  loss: 0.908768
accuracy: 0.675000
Epoch 123, CIFAR-10 Batch 3:  loss: 1.188128
accuracy: 0.675000
Epoch 123, CIFAR-10 Batch 4:  loss: 1.308683
accuracy: 0.600000
Epoch 123, CIFAR-10 Batch 5:  loss: 1.292093
accuracy: 0.550000
Epoch 124, CIFAR-10 Batch 1:  loss: 0.966423
accuracy: 0.675000
Epoch 124, CIFAR-10 Batch 2:  loss: 0.887242
accuracy: 0.700000
Epoch 124, CIFAR-10 Batch 3:  loss: 1.183667
accuracy: 0.675000
Epoch 124, CIFAR-10 Batch 4:  loss: 1.255535
accuracy: 0.600000
Epoch 124, CIFAR-10 Batch 5:  loss: 1.390260
accuracy: 0.500000
Epoch 125, CIFAR-10 Batch 1:  loss: 0.955376
accuracy: 0.675000
Epoch 125, CIFAR-10 Batch 2:  loss: 0.880619
accuracy: 0.725000
Epoch 125, CIFAR-10 Batch 3:  loss: 1.226899
accuracy: 0.675000
Epoch 125, CIFAR-10 Batch 4:  loss: 1.269396
accuracy: 0.600000
Epoch 125, CIFAR-10 Batch 5:  loss: 1.360108
accuracy: 0.525000
Epoch 126, CIFAR-10 Batch 1:  loss: 1.002127
accuracy: 0.675000
Epoch 126, CIFAR-10 Batch 2:  loss: 0.901433
accuracy: 0.675000
Epoch 126, CIFAR-10 Batch 3:  loss: 1.150764
accuracy: 0.700000
Epoch 126, CIFAR-10 Batch 4:  loss: 1.284455
accuracy: 0.550000
Epoch 126, CIFAR-10 Batch 5:  loss: 1.312343
accuracy: 0.550000
Epoch 127, CIFAR-10 Batch 1:  loss: 0.954470
accuracy: 0.700000
Epoch 127, CIFAR-10 Batch 2:  loss: 0.870534
accuracy: 0.700000
Epoch 127, CIFAR-10 Batch 3:  loss: 1.184616
accuracy: 0.675000
Epoch 127, CIFAR-10 Batch 4:  loss: 1.263053
accuracy: 0.600000
Epoch 127, CIFAR-10 Batch 5:  loss: 1.342447
accuracy: 0.550000
Epoch 128, CIFAR-10 Batch 1:  loss: 0.961867
accuracy: 0.700000
Epoch 128, CIFAR-10 Batch 2:  loss: 0.867179
accuracy: 0.700000
Epoch 128, CIFAR-10 Batch 3:  loss: 1.127077
accuracy: 0.725000
Epoch 128, CIFAR-10 Batch 4:  loss: 1.277833
accuracy: 0.575000
Epoch 128, CIFAR-10 Batch 5:  loss: 1.354299
accuracy: 0.550000
Epoch 129, CIFAR-10 Batch 1:  loss: 0.943683
accuracy: 0.700000
Epoch 129, CIFAR-10 Batch 2:  loss: 0.828937
accuracy: 0.725000
Epoch 129, CIFAR-10 Batch 3:  loss: 1.152917
accuracy: 0.675000
Epoch 129, CIFAR-10 Batch 4:  loss: 1.280028
accuracy: 0.625000
Epoch 129, CIFAR-10 Batch 5:  loss: 1.370150
accuracy: 0.525000
Epoch 130, CIFAR-10 Batch 1:  loss: 0.954978
accuracy: 0.625000
Epoch 130, CIFAR-10 Batch 2:  loss: 0.854088
accuracy: 0.725000
Epoch 130, CIFAR-10 Batch 3:  loss: 1.113759
accuracy: 0.675000
Epoch 130, CIFAR-10 Batch 4:  loss: 1.241350
accuracy: 0.625000
Epoch 130, CIFAR-10 Batch 5:  loss: 1.304179
accuracy: 0.525000
Epoch 131, CIFAR-10 Batch 1:  loss: 0.954886
accuracy: 0.675000
Epoch 131, CIFAR-10 Batch 2:  loss: 0.838258
accuracy: 0.700000
Epoch 131, CIFAR-10 Batch 3:  loss: 1.094628
accuracy: 0.750000
Epoch 131, CIFAR-10 Batch 4:  loss: 1.290500
accuracy: 0.550000
Epoch 131, CIFAR-10 Batch 5:  loss: 1.307900
accuracy: 0.500000
Epoch 132, CIFAR-10 Batch 1:  loss: 1.054895
accuracy: 0.625000
Epoch 132, CIFAR-10 Batch 2:  loss: 0.846455
accuracy: 0.725000
Epoch 132, CIFAR-10 Batch 3:  loss: 1.147724
accuracy: 0.750000
Epoch 132, CIFAR-10 Batch 4:  loss: 1.286137
accuracy: 0.625000
Epoch 132, CIFAR-10 Batch 5:  loss: 1.346483
accuracy: 0.550000
Epoch 133, CIFAR-10 Batch 1:  loss: 0.978230
accuracy: 0.700000
Epoch 133, CIFAR-10 Batch 2:  loss: 0.910298
accuracy: 0.650000
Epoch 133, CIFAR-10 Batch 3:  loss: 1.140249
accuracy: 0.675000
Epoch 133, CIFAR-10 Batch 4:  loss: 1.271067
accuracy: 0.625000
Epoch 133, CIFAR-10 Batch 5:  loss: 1.341282
accuracy: 0.550000
Epoch 134, CIFAR-10 Batch 1:  loss: 0.947816
accuracy: 0.700000
Epoch 134, CIFAR-10 Batch 2:  loss: 0.915221
accuracy: 0.700000
Epoch 134, CIFAR-10 Batch 3:  loss: 1.143310
accuracy: 0.700000
Epoch 134, CIFAR-10 Batch 4:  loss: 1.259085
accuracy: 0.625000
Epoch 134, CIFAR-10 Batch 5:  loss: 1.310318
accuracy: 0.550000
Epoch 135, CIFAR-10 Batch 1:  loss: 0.961966
accuracy: 0.650000
Epoch 135, CIFAR-10 Batch 2:  loss: 0.888104
accuracy: 0.725000
Epoch 135, CIFAR-10 Batch 3:  loss: 1.121676
accuracy: 0.700000
Epoch 135, CIFAR-10 Batch 4:  loss: 1.299148
accuracy: 0.550000
Epoch 135, CIFAR-10 Batch 5:  loss: 1.333575
accuracy: 0.500000
Epoch 136, CIFAR-10 Batch 1:  loss: 0.933403
accuracy: 0.675000
Epoch 136, CIFAR-10 Batch 2:  loss: 0.868632
accuracy: 0.675000
Epoch 136, CIFAR-10 Batch 3:  loss: 1.106746
accuracy: 0.725000
Epoch 136, CIFAR-10 Batch 4:  loss: 1.281904
accuracy: 0.650000
Epoch 136, CIFAR-10 Batch 5:  loss: 1.320570
accuracy: 0.550000
Epoch 137, CIFAR-10 Batch 1:  loss: 0.969117
accuracy: 0.725000
Epoch 137, CIFAR-10 Batch 2:  loss: 0.839272
accuracy: 0.700000
Epoch 137, CIFAR-10 Batch 3:  loss: 1.148104
accuracy: 0.700000
Epoch 137, CIFAR-10 Batch 4:  loss: 1.269962
accuracy: 0.625000
Epoch 137, CIFAR-10 Batch 5:  loss: 1.380138
accuracy: 0.450000
Epoch 138, CIFAR-10 Batch 1:  loss: 0.943819
accuracy: 0.675000
Epoch 138, CIFAR-10 Batch 2:  loss: 0.829443
accuracy: 0.725000
Epoch 138, CIFAR-10 Batch 3:  loss: 1.074998
accuracy: 0.725000
Epoch 138, CIFAR-10 Batch 4:  loss: 1.269547
accuracy: 0.600000
Epoch 138, CIFAR-10 Batch 5:  loss: 1.322335
accuracy: 0.525000
Epoch 139, CIFAR-10 Batch 1:  loss: 0.926172
accuracy: 0.675000
Epoch 139, CIFAR-10 Batch 2:  loss: 0.847665
accuracy: 0.725000
Epoch 139, CIFAR-10 Batch 3:  loss: 1.141584
accuracy: 0.725000
Epoch 139, CIFAR-10 Batch 4:  loss: 1.306832
accuracy: 0.600000
Epoch 139, CIFAR-10 Batch 5:  loss: 1.326521
accuracy: 0.500000
Epoch 140, CIFAR-10 Batch 1:  loss: 0.956871
accuracy: 0.625000
Epoch 140, CIFAR-10 Batch 2:  loss: 0.864245
accuracy: 0.675000
Epoch 140, CIFAR-10 Batch 3:  loss: 1.092775
accuracy: 0.725000
Epoch 140, CIFAR-10 Batch 4:  loss: 1.288913
accuracy: 0.650000
Epoch 140, CIFAR-10 Batch 5:  loss: 1.305987
accuracy: 0.550000
Epoch 141, CIFAR-10 Batch 1:  loss: 0.919822
accuracy: 0.675000
Epoch 141, CIFAR-10 Batch 2:  loss: 0.863632
accuracy: 0.675000
Epoch 141, CIFAR-10 Batch 3:  loss: 1.086243
accuracy: 0.700000
Epoch 141, CIFAR-10 Batch 4:  loss: 1.273363
accuracy: 0.650000
Epoch 141, CIFAR-10 Batch 5:  loss: 1.334374
accuracy: 0.525000
Epoch 142, CIFAR-10 Batch 1:  loss: 0.945546
accuracy: 0.650000
Epoch 142, CIFAR-10 Batch 2:  loss: 0.878729
accuracy: 0.725000
Epoch 142, CIFAR-10 Batch 3:  loss: 1.065852
accuracy: 0.700000
Epoch 142, CIFAR-10 Batch 4:  loss: 1.283751
accuracy: 0.575000
Epoch 142, CIFAR-10 Batch 5:  loss: 1.321301
accuracy: 0.550000
Epoch 143, CIFAR-10 Batch 1:  loss: 0.931101
accuracy: 0.750000
Epoch 143, CIFAR-10 Batch 2:  loss: 0.862212
accuracy: 0.725000
Epoch 143, CIFAR-10 Batch 3:  loss: 1.077126
accuracy: 0.725000
Epoch 143, CIFAR-10 Batch 4:  loss: 1.277200
accuracy: 0.600000
Epoch 143, CIFAR-10 Batch 5:  loss: 1.331170
accuracy: 0.500000
Epoch 144, CIFAR-10 Batch 1:  loss: 0.924617
accuracy: 0.675000
Epoch 144, CIFAR-10 Batch 2:  loss: 0.863444
accuracy: 0.700000
Epoch 144, CIFAR-10 Batch 3:  loss: 1.106483
accuracy: 0.700000
Epoch 144, CIFAR-10 Batch 4:  loss: 1.238870
accuracy: 0.650000
Epoch 144, CIFAR-10 Batch 5:  loss: 1.350628
accuracy: 0.525000
Epoch 145, CIFAR-10 Batch 1:  loss: 0.932981
accuracy: 0.650000
Epoch 145, CIFAR-10 Batch 2:  loss: 0.851724
accuracy: 0.700000
Epoch 145, CIFAR-10 Batch 3:  loss: 1.093140
accuracy: 0.675000
Epoch 145, CIFAR-10 Batch 4:  loss: 1.296790
accuracy: 0.550000
Epoch 145, CIFAR-10 Batch 5:  loss: 1.380391
accuracy: 0.500000
Epoch 146, CIFAR-10 Batch 1:  loss: 0.920428
accuracy: 0.675000
Epoch 146, CIFAR-10 Batch 2:  loss: 0.886993
accuracy: 0.650000
Epoch 146, CIFAR-10 Batch 3:  loss: 1.120129
accuracy: 0.700000
Epoch 146, CIFAR-10 Batch 4:  loss: 1.262773
accuracy: 0.625000
Epoch 146, CIFAR-10 Batch 5:  loss: 1.291721
accuracy: 0.550000
Epoch 147, CIFAR-10 Batch 1:  loss: 0.921269
accuracy: 0.700000
Epoch 147, CIFAR-10 Batch 2:  loss: 0.859359
accuracy: 0.700000
Epoch 147, CIFAR-10 Batch 3:  loss: 1.097927
accuracy: 0.700000
Epoch 147, CIFAR-10 Batch 4:  loss: 1.235535
accuracy: 0.600000
Epoch 147, CIFAR-10 Batch 5:  loss: 1.276447
accuracy: 0.550000
Epoch 148, CIFAR-10 Batch 1:  loss: 0.910459
accuracy: 0.650000
Epoch 148, CIFAR-10 Batch 2:  loss: 0.836887
accuracy: 0.700000
Epoch 148, CIFAR-10 Batch 3:  loss: 1.077296
accuracy: 0.675000
Epoch 148, CIFAR-10 Batch 4:  loss: 1.248938
accuracy: 0.600000
Epoch 148, CIFAR-10 Batch 5:  loss: 1.328181
accuracy: 0.550000
Epoch 149, CIFAR-10 Batch 1:  loss: 0.911392
accuracy: 0.650000
Epoch 149, CIFAR-10 Batch 2:  loss: 0.872872
accuracy: 0.700000
Epoch 149, CIFAR-10 Batch 3:  loss: 1.070963
accuracy: 0.700000
Epoch 149, CIFAR-10 Batch 4:  loss: 1.243811
accuracy: 0.650000
Epoch 149, CIFAR-10 Batch 5:  loss: 1.291536
accuracy: 0.525000
Epoch 150, CIFAR-10 Batch 1:  loss: 0.929300
accuracy: 0.650000
Epoch 150, CIFAR-10 Batch 2:  loss: 0.914642
accuracy: 0.700000
Epoch 150, CIFAR-10 Batch 3:  loss: 1.116100
accuracy: 0.625000
Epoch 150, CIFAR-10 Batch 4:  loss: 1.236254
accuracy: 0.650000
Epoch 150, CIFAR-10 Batch 5:  loss: 1.300535
accuracy: 0.575000
Epoch 151, CIFAR-10 Batch 1:  loss: 0.892224
accuracy: 0.700000
Epoch 151, CIFAR-10 Batch 2:  loss: 0.909944
accuracy: 0.675000
Epoch 151, CIFAR-10 Batch 3:  loss: 1.096229
accuracy: 0.675000
Epoch 151, CIFAR-10 Batch 4:  loss: 1.251191
accuracy: 0.600000
Epoch 151, CIFAR-10 Batch 5:  loss: 1.294796
accuracy: 0.550000
Epoch 152, CIFAR-10 Batch 1:  loss: 0.908498
accuracy: 0.725000
Epoch 152, CIFAR-10 Batch 2:  loss: 0.873798
accuracy: 0.700000
Epoch 152, CIFAR-10 Batch 3:  loss: 1.108191
accuracy: 0.625000
Epoch 152, CIFAR-10 Batch 4:  loss: 1.247403
accuracy: 0.525000
Epoch 152, CIFAR-10 Batch 5:  loss: 1.299056
accuracy: 0.550000
Epoch 153, CIFAR-10 Batch 1:  loss: 0.906559
accuracy: 0.750000
Epoch 153, CIFAR-10 Batch 2:  loss: 0.873369
accuracy: 0.675000
Epoch 153, CIFAR-10 Batch 3:  loss: 1.118442
accuracy: 0.700000
Epoch 153, CIFAR-10 Batch 4:  loss: 1.237345
accuracy: 0.600000
Epoch 153, CIFAR-10 Batch 5:  loss: 1.289122
accuracy: 0.500000
Epoch 154, CIFAR-10 Batch 1:  loss: 0.894387
accuracy: 0.725000
Epoch 154, CIFAR-10 Batch 2:  loss: 0.893231
accuracy: 0.675000
Epoch 154, CIFAR-10 Batch 3:  loss: 1.129342
accuracy: 0.625000
Epoch 154, CIFAR-10 Batch 4:  loss: 1.237261
accuracy: 0.625000
Epoch 154, CIFAR-10 Batch 5:  loss: 1.296144
accuracy: 0.525000
Epoch 155, CIFAR-10 Batch 1:  loss: 0.896443
accuracy: 0.750000
Epoch 155, CIFAR-10 Batch 2:  loss: 0.854123
accuracy: 0.700000
Epoch 155, CIFAR-10 Batch 3:  loss: 1.105919
accuracy: 0.650000
Epoch 155, CIFAR-10 Batch 4:  loss: 1.290368
accuracy: 0.575000
Epoch 155, CIFAR-10 Batch 5:  loss: 1.266887
accuracy: 0.575000
Epoch 156, CIFAR-10 Batch 1:  loss: 0.905817
accuracy: 0.675000
Epoch 156, CIFAR-10 Batch 2:  loss: 0.847407
accuracy: 0.725000
Epoch 156, CIFAR-10 Batch 3:  loss: 1.104896
accuracy: 0.675000
Epoch 156, CIFAR-10 Batch 4:  loss: 1.261590
accuracy: 0.600000
Epoch 156, CIFAR-10 Batch 5:  loss: 1.266510
accuracy: 0.550000
Epoch 157, CIFAR-10 Batch 1:  loss: 0.920324
accuracy: 0.675000
Epoch 157, CIFAR-10 Batch 2:  loss: 0.821972
accuracy: 0.675000
Epoch 157, CIFAR-10 Batch 3:  loss: 1.040710
accuracy: 0.700000
Epoch 157, CIFAR-10 Batch 4:  loss: 1.220917
accuracy: 0.625000
Epoch 157, CIFAR-10 Batch 5:  loss: 1.282029
accuracy: 0.550000
Epoch 158, CIFAR-10 Batch 1:  loss: 0.866601
accuracy: 0.750000
Epoch 158, CIFAR-10 Batch 2:  loss: 0.872001
accuracy: 0.700000
Epoch 158, CIFAR-10 Batch 3:  loss: 1.082691
accuracy: 0.700000
Epoch 158, CIFAR-10 Batch 4:  loss: 1.263685
accuracy: 0.575000
Epoch 158, CIFAR-10 Batch 5:  loss: 1.250819
accuracy: 0.575000
Epoch 159, CIFAR-10 Batch 1:  loss: 0.883487
accuracy: 0.725000
Epoch 159, CIFAR-10 Batch 2:  loss: 0.877501
accuracy: 0.700000
Epoch 159, CIFAR-10 Batch 3:  loss: 1.136714
accuracy: 0.625000
Epoch 159, CIFAR-10 Batch 4:  loss: 1.279408
accuracy: 0.575000
Epoch 159, CIFAR-10 Batch 5:  loss: 1.267910
accuracy: 0.550000
Epoch 160, CIFAR-10 Batch 1:  loss: 0.903180
accuracy: 0.725000
Epoch 160, CIFAR-10 Batch 2:  loss: 0.858107
accuracy: 0.750000
Epoch 160, CIFAR-10 Batch 3:  loss: 1.124234
accuracy: 0.625000
Epoch 160, CIFAR-10 Batch 4:  loss: 1.261578
accuracy: 0.625000
Epoch 160, CIFAR-10 Batch 5:  loss: 1.269416
accuracy: 0.575000
Epoch 161, CIFAR-10 Batch 1:  loss: 0.883857
accuracy: 0.750000
Epoch 161, CIFAR-10 Batch 2:  loss: 0.811102
accuracy: 0.725000
Epoch 161, CIFAR-10 Batch 3:  loss: 1.050299
accuracy: 0.750000
Epoch 161, CIFAR-10 Batch 4:  loss: 1.236189
accuracy: 0.575000
Epoch 161, CIFAR-10 Batch 5:  loss: 1.270636
accuracy: 0.575000
Epoch 162, CIFAR-10 Batch 1:  loss: 0.869008
accuracy: 0.725000
Epoch 162, CIFAR-10 Batch 2:  loss: 0.885503
accuracy: 0.725000
Epoch 162, CIFAR-10 Batch 3:  loss: 1.338802
accuracy: 0.650000
Epoch 162, CIFAR-10 Batch 4:  loss: 1.251168
accuracy: 0.650000
Epoch 162, CIFAR-10 Batch 5:  loss: 1.249005
accuracy: 0.575000
Epoch 163, CIFAR-10 Batch 1:  loss: 0.899110
accuracy: 0.725000
Epoch 163, CIFAR-10 Batch 2:  loss: 0.813547
accuracy: 0.725000
Epoch 163, CIFAR-10 Batch 3:  loss: 1.013633
accuracy: 0.725000
Epoch 163, CIFAR-10 Batch 4:  loss: 1.254337
accuracy: 0.575000
Epoch 163, CIFAR-10 Batch 5:  loss: 1.259831
accuracy: 0.525000
Epoch 164, CIFAR-10 Batch 1:  loss: 0.901989
accuracy: 0.650000
Epoch 164, CIFAR-10 Batch 2:  loss: 0.859349
accuracy: 0.700000
Epoch 164, CIFAR-10 Batch 3:  loss: 1.061054
accuracy: 0.675000
Epoch 164, CIFAR-10 Batch 4:  loss: 1.286542
accuracy: 0.575000
Epoch 164, CIFAR-10 Batch 5:  loss: 1.246175
accuracy: 0.575000
Epoch 165, CIFAR-10 Batch 1:  loss: 0.889495
accuracy: 0.750000
Epoch 165, CIFAR-10 Batch 2:  loss: 0.843598
accuracy: 0.725000
Epoch 165, CIFAR-10 Batch 3:  loss: 1.144984
accuracy: 0.675000
Epoch 165, CIFAR-10 Batch 4:  loss: 1.264510
accuracy: 0.600000
Epoch 165, CIFAR-10 Batch 5:  loss: 1.253876
accuracy: 0.550000
Epoch 166, CIFAR-10 Batch 1:  loss: 0.890095
accuracy: 0.725000
Epoch 166, CIFAR-10 Batch 2:  loss: 0.886760
accuracy: 0.725000
Epoch 166, CIFAR-10 Batch 3:  loss: 1.115023
accuracy: 0.625000
Epoch 166, CIFAR-10 Batch 4:  loss: 1.226756
accuracy: 0.625000
Epoch 166, CIFAR-10 Batch 5:  loss: 1.281811
accuracy: 0.600000
Epoch 167, CIFAR-10 Batch 1:  loss: 1.710527
accuracy: 0.675000
Epoch 167, CIFAR-10 Batch 2:  loss: 0.818228
accuracy: 0.725000
Epoch 167, CIFAR-10 Batch 3:  loss: 1.055078
accuracy: 0.675000
Epoch 167, CIFAR-10 Batch 4:  loss: 1.259832
accuracy: 0.575000
Epoch 167, CIFAR-10 Batch 5:  loss: 1.266481
accuracy: 0.525000
Epoch 168, CIFAR-10 Batch 1:  loss: 1.471967
accuracy: 0.700000
Epoch 168, CIFAR-10 Batch 2:  loss: 0.845950
accuracy: 0.725000
Epoch 168, CIFAR-10 Batch 3:  loss: 1.097722
accuracy: 0.625000
Epoch 168, CIFAR-10 Batch 4:  loss: 1.224013
accuracy: 0.625000
Epoch 168, CIFAR-10 Batch 5:  loss: 1.258649
accuracy: 0.575000
Epoch 169, CIFAR-10 Batch 1:  loss: 1.337000
accuracy: 0.675000
Epoch 169, CIFAR-10 Batch 2:  loss: 0.875882
accuracy: 0.750000
Epoch 169, CIFAR-10 Batch 3:  loss: 1.052798
accuracy: 0.675000
Epoch 169, CIFAR-10 Batch 4:  loss: 1.266487
accuracy: 0.550000
Epoch 169, CIFAR-10 Batch 5:  loss: 1.239728
accuracy: 0.575000
Epoch 170, CIFAR-10 Batch 1:  loss: 1.282325
accuracy: 0.675000
Epoch 170, CIFAR-10 Batch 2:  loss: 0.843412
accuracy: 0.725000
Epoch 170, CIFAR-10 Batch 3:  loss: 1.084213
accuracy: 0.625000
Epoch 170, CIFAR-10 Batch 4:  loss: 1.250965
accuracy: 0.600000
Epoch 170, CIFAR-10 Batch 5:  loss: 1.241715
accuracy: 0.575000
Epoch 171, CIFAR-10 Batch 1:  loss: 1.213796
accuracy: 0.675000
Epoch 171, CIFAR-10 Batch 2:  loss: 0.819614
accuracy: 0.725000
Epoch 171, CIFAR-10 Batch 3:  loss: 1.050170
accuracy: 0.675000
Epoch 171, CIFAR-10 Batch 4:  loss: 1.277412
accuracy: 0.575000
Epoch 171, CIFAR-10 Batch 5:  loss: 1.228494
accuracy: 0.550000
Epoch 172, CIFAR-10 Batch 1:  loss: 0.940428
accuracy: 0.675000
Epoch 172, CIFAR-10 Batch 2:  loss: 0.848962
accuracy: 0.700000
Epoch 172, CIFAR-10 Batch 3:  loss: 1.083139
accuracy: 0.650000
Epoch 172, CIFAR-10 Batch 4:  loss: 1.256614
accuracy: 0.575000
Epoch 172, CIFAR-10 Batch 5:  loss: 1.253786
accuracy: 0.600000
Epoch 173, CIFAR-10 Batch 1:  loss: 0.885315
accuracy: 0.700000
Epoch 173, CIFAR-10 Batch 2:  loss: 0.825063
accuracy: 0.700000
Epoch 173, CIFAR-10 Batch 3:  loss: 1.065594
accuracy: 0.700000
Epoch 173, CIFAR-10 Batch 4:  loss: 1.274882
accuracy: 0.550000
Epoch 173, CIFAR-10 Batch 5:  loss: 1.229817
accuracy: 0.575000
Epoch 174, CIFAR-10 Batch 1:  loss: 0.884454
accuracy: 0.750000
Epoch 174, CIFAR-10 Batch 2:  loss: 0.846141
accuracy: 0.725000
Epoch 174, CIFAR-10 Batch 3:  loss: 1.063250
accuracy: 0.625000
Epoch 174, CIFAR-10 Batch 4:  loss: 1.285331
accuracy: 0.500000
Epoch 174, CIFAR-10 Batch 5:  loss: 1.281144
accuracy: 0.550000
Epoch 175, CIFAR-10 Batch 1:  loss: 0.899254
accuracy: 0.700000
Epoch 175, CIFAR-10 Batch 2:  loss: 0.857350
accuracy: 0.750000
Epoch 175, CIFAR-10 Batch 3:  loss: 1.087475
accuracy: 0.650000
Epoch 175, CIFAR-10 Batch 4:  loss: 1.247504
accuracy: 0.575000
Epoch 175, CIFAR-10 Batch 5:  loss: 1.213016
accuracy: 0.575000
Epoch 176, CIFAR-10 Batch 1:  loss: 0.879508
accuracy: 0.725000
Epoch 176, CIFAR-10 Batch 2:  loss: 0.861250
accuracy: 0.700000
Epoch 176, CIFAR-10 Batch 3:  loss: 1.072362
accuracy: 0.700000
Epoch 176, CIFAR-10 Batch 4:  loss: 1.270247
accuracy: 0.525000
Epoch 176, CIFAR-10 Batch 5:  loss: 1.215844
accuracy: 0.600000
Epoch 177, CIFAR-10 Batch 1:  loss: 0.878007
accuracy: 0.750000
Epoch 177, CIFAR-10 Batch 2:  loss: 0.840947
accuracy: 0.750000
Epoch 177, CIFAR-10 Batch 3:  loss: 1.026129
accuracy: 0.675000
Epoch 177, CIFAR-10 Batch 4:  loss: 1.300638
accuracy: 0.625000
Epoch 177, CIFAR-10 Batch 5:  loss: 1.233016
accuracy: 0.600000
Epoch 178, CIFAR-10 Batch 1:  loss: 0.904282
accuracy: 0.725000
Epoch 178, CIFAR-10 Batch 2:  loss: 0.832197
accuracy: 0.725000
Epoch 178, CIFAR-10 Batch 3:  loss: 1.034520
accuracy: 0.675000
Epoch 178, CIFAR-10 Batch 4:  loss: 1.577769
accuracy: 0.575000
Epoch 178, CIFAR-10 Batch 5:  loss: 1.233925
accuracy: 0.575000
Epoch 179, CIFAR-10 Batch 1:  loss: 0.891956
accuracy: 0.700000
Epoch 179, CIFAR-10 Batch 2:  loss: 0.880556
accuracy: 0.700000
Epoch 179, CIFAR-10 Batch 3:  loss: 1.021808
accuracy: 0.700000
Epoch 179, CIFAR-10 Batch 4:  loss: 1.250642
accuracy: 0.600000
Epoch 179, CIFAR-10 Batch 5:  loss: 1.185639
accuracy: 0.625000
Epoch 180, CIFAR-10 Batch 1:  loss: 0.882903
accuracy: 0.725000
Epoch 180, CIFAR-10 Batch 2:  loss: 0.834104
accuracy: 0.725000
Epoch 180, CIFAR-10 Batch 3:  loss: 1.056995
accuracy: 0.650000
Epoch 180, CIFAR-10 Batch 4:  loss: 1.268673
accuracy: 0.550000
Epoch 180, CIFAR-10 Batch 5:  loss: 1.180646
accuracy: 0.625000
Epoch 181, CIFAR-10 Batch 1:  loss: 0.878363
accuracy: 0.750000
Epoch 181, CIFAR-10 Batch 2:  loss: 0.818079
accuracy: 0.725000
Epoch 181, CIFAR-10 Batch 3:  loss: 1.059156
accuracy: 0.625000
Epoch 181, CIFAR-10 Batch 4:  loss: 1.276446
accuracy: 0.550000
Epoch 181, CIFAR-10 Batch 5:  loss: 1.178333
accuracy: 0.625000
Epoch 182, CIFAR-10 Batch 1:  loss: 0.890176
accuracy: 0.725000
Epoch 182, CIFAR-10 Batch 2:  loss: 0.830266
accuracy: 0.750000
Epoch 182, CIFAR-10 Batch 3:  loss: 0.997143
accuracy: 0.700000
Epoch 182, CIFAR-10 Batch 4:  loss: 1.278313
accuracy: 0.575000
Epoch 182, CIFAR-10 Batch 5:  loss: 1.204851
accuracy: 0.650000
Epoch 183, CIFAR-10 Batch 1:  loss: 1.086813
accuracy: 0.700000
Epoch 183, CIFAR-10 Batch 2:  loss: 0.807953
accuracy: 0.725000
Epoch 183, CIFAR-10 Batch 3:  loss: 1.021420
accuracy: 0.700000
Epoch 183, CIFAR-10 Batch 4:  loss: 1.330169
accuracy: 0.550000
Epoch 183, CIFAR-10 Batch 5:  loss: 1.207120
accuracy: 0.575000
Epoch 184, CIFAR-10 Batch 1:  loss: 1.383919
accuracy: 0.675000
Epoch 184, CIFAR-10 Batch 2:  loss: 0.822122
accuracy: 0.750000
Epoch 184, CIFAR-10 Batch 3:  loss: 1.002454
accuracy: 0.675000
Epoch 184, CIFAR-10 Batch 4:  loss: 1.301173
accuracy: 0.500000
Epoch 184, CIFAR-10 Batch 5:  loss: 1.198707
accuracy: 0.650000
Epoch 185, CIFAR-10 Batch 1:  loss: 2.234494
accuracy: 0.725000
Epoch 185, CIFAR-10 Batch 2:  loss: 0.815967
accuracy: 0.700000
Epoch 185, CIFAR-10 Batch 3:  loss: 0.998967
accuracy: 0.650000
Epoch 185, CIFAR-10 Batch 4:  loss: 1.271385
accuracy: 0.550000
Epoch 185, CIFAR-10 Batch 5:  loss: 1.152813
accuracy: 0.650000
Epoch 186, CIFAR-10 Batch 1:  loss: 1.844962
accuracy: 0.675000
Epoch 186, CIFAR-10 Batch 2:  loss: 0.800174
accuracy: 0.725000
Epoch 186, CIFAR-10 Batch 3:  loss: 0.967446
accuracy: 0.675000
Epoch 186, CIFAR-10 Batch 4:  loss: 1.254518
accuracy: 0.550000
Epoch 186, CIFAR-10 Batch 5:  loss: 1.166268
accuracy: 0.600000
Epoch 187, CIFAR-10 Batch 1:  loss: 1.658396
accuracy: 0.675000
Epoch 187, CIFAR-10 Batch 2:  loss: 0.760473
accuracy: 0.725000
Epoch 187, CIFAR-10 Batch 3:  loss: 0.995640
accuracy: 0.750000
Epoch 187, CIFAR-10 Batch 4:  loss: 1.288364
accuracy: 0.500000
Epoch 187, CIFAR-10 Batch 5:  loss: 1.157393
accuracy: 0.625000
Epoch 188, CIFAR-10 Batch 1:  loss: 1.699891
accuracy: 0.725000
Epoch 188, CIFAR-10 Batch 2:  loss: 0.768026
accuracy: 0.725000
Epoch 188, CIFAR-10 Batch 3:  loss: 1.005909
accuracy: 0.650000
Epoch 188, CIFAR-10 Batch 4:  loss: 1.276863
accuracy: 0.575000
Epoch 188, CIFAR-10 Batch 5:  loss: 1.138428
accuracy: 0.625000
Epoch 189, CIFAR-10 Batch 1:  loss: 1.679247
accuracy: 0.675000
Epoch 189, CIFAR-10 Batch 2:  loss: 0.859455
accuracy: 0.725000
Epoch 189, CIFAR-10 Batch 3:  loss: 0.955423
accuracy: 0.750000
Epoch 189, CIFAR-10 Batch 4:  loss: 1.285335
accuracy: 0.575000
Epoch 189, CIFAR-10 Batch 5:  loss: 1.125567
accuracy: 0.650000
Epoch 190, CIFAR-10 Batch 1:  loss: 1.124084
accuracy: 0.750000
Epoch 190, CIFAR-10 Batch 2:  loss: 0.798811
accuracy: 0.750000
Epoch 190, CIFAR-10 Batch 3:  loss: 1.021641
accuracy: 0.725000
Epoch 190, CIFAR-10 Batch 4:  loss: 1.236215
accuracy: 0.575000
Epoch 190, CIFAR-10 Batch 5:  loss: 1.122621
accuracy: 0.625000
Epoch 191, CIFAR-10 Batch 1:  loss: 0.876173
accuracy: 0.725000
Epoch 191, CIFAR-10 Batch 2:  loss: 0.831207
accuracy: 0.725000
Epoch 191, CIFAR-10 Batch 3:  loss: 1.022743
accuracy: 0.700000
Epoch 191, CIFAR-10 Batch 4:  loss: 1.258234
accuracy: 0.575000
Epoch 191, CIFAR-10 Batch 5:  loss: 1.142731
accuracy: 0.650000
Epoch 192, CIFAR-10 Batch 1:  loss: 0.873679
accuracy: 0.700000
Epoch 192, CIFAR-10 Batch 2:  loss: 0.796612
accuracy: 0.750000
Epoch 192, CIFAR-10 Batch 3:  loss: 1.054378
accuracy: 0.675000
Epoch 192, CIFAR-10 Batch 4:  loss: 1.266749
accuracy: 0.525000
Epoch 192, CIFAR-10 Batch 5:  loss: 1.144794
accuracy: 0.625000
Epoch 193, CIFAR-10 Batch 1:  loss: 0.882134
accuracy: 0.700000
Epoch 193, CIFAR-10 Batch 2:  loss: 0.802129
accuracy: 0.725000
Epoch 193, CIFAR-10 Batch 3:  loss: 1.019010
accuracy: 0.650000
Epoch 193, CIFAR-10 Batch 4:  loss: 1.282690
accuracy: 0.550000
Epoch 193, CIFAR-10 Batch 5:  loss: 1.138273
accuracy: 0.675000
Epoch 194, CIFAR-10 Batch 1:  loss: 0.861525
accuracy: 0.725000
Epoch 194, CIFAR-10 Batch 2:  loss: 0.806479
accuracy: 0.725000
Epoch 194, CIFAR-10 Batch 3:  loss: 0.967307
accuracy: 0.750000
Epoch 194, CIFAR-10 Batch 4:  loss: 1.270561
accuracy: 0.575000
Epoch 194, CIFAR-10 Batch 5:  loss: 1.122570
accuracy: 0.675000
Epoch 195, CIFAR-10 Batch 1:  loss: 0.867357
accuracy: 0.775000
Epoch 195, CIFAR-10 Batch 2:  loss: 0.801018
accuracy: 0.700000
Epoch 195, CIFAR-10 Batch 3:  loss: 0.966476
accuracy: 0.700000
Epoch 195, CIFAR-10 Batch 4:  loss: 1.318279
accuracy: 0.500000
Epoch 195, CIFAR-10 Batch 5:  loss: 1.160016
accuracy: 0.600000
Epoch 196, CIFAR-10 Batch 1:  loss: 0.852775
accuracy: 0.725000
Epoch 196, CIFAR-10 Batch 2:  loss: 0.814809
accuracy: 0.700000
Epoch 196, CIFAR-10 Batch 3:  loss: 0.971841
accuracy: 0.700000
Epoch 196, CIFAR-10 Batch 4:  loss: 1.282096
accuracy: 0.550000
Epoch 196, CIFAR-10 Batch 5:  loss: 1.166381
accuracy: 0.650000
Epoch 197, CIFAR-10 Batch 1:  loss: 0.921780
accuracy: 0.725000
Epoch 197, CIFAR-10 Batch 2:  loss: 0.816857
accuracy: 0.750000
Epoch 197, CIFAR-10 Batch 3:  loss: 1.003882
accuracy: 0.700000
Epoch 197, CIFAR-10 Batch 4:  loss: 1.335421
accuracy: 0.525000
Epoch 197, CIFAR-10 Batch 5:  loss: 1.161411
accuracy: 0.575000
Epoch 198, CIFAR-10 Batch 1:  loss: 0.859209
accuracy: 0.800000
Epoch 198, CIFAR-10 Batch 2:  loss: 0.781055
accuracy: 0.725000
Epoch 198, CIFAR-10 Batch 3:  loss: 0.956370
accuracy: 0.700000
Epoch 198, CIFAR-10 Batch 4:  loss: 1.290997
accuracy: 0.575000
Epoch 198, CIFAR-10 Batch 5:  loss: 1.089105
accuracy: 0.700000
Epoch 199, CIFAR-10 Batch 1:  loss: 0.872254
accuracy: 0.725000
Epoch 199, CIFAR-10 Batch 2:  loss: 0.805514
accuracy: 0.725000
Epoch 199, CIFAR-10 Batch 3:  loss: 0.957200
accuracy: 0.750000
Epoch 199, CIFAR-10 Batch 4:  loss: 1.264500
accuracy: 0.600000
Epoch 199, CIFAR-10 Batch 5:  loss: 1.138762
accuracy: 0.675000
Epoch 200, CIFAR-10 Batch 1:  loss: 0.856695
accuracy: 0.725000
Epoch 200, CIFAR-10 Batch 2:  loss: 0.798558
accuracy: 0.725000
Epoch 200, CIFAR-10 Batch 3:  loss: 0.981300
accuracy: 0.675000
Epoch 200, CIFAR-10 Batch 4:  loss: 1.293483
accuracy: 0.525000
Epoch 200, CIFAR-10 Batch 5:  loss: 1.106884
accuracy: 0.725000
Epoch 201, CIFAR-10 Batch 1:  loss: 0.857201
accuracy: 0.725000
Epoch 201, CIFAR-10 Batch 2:  loss: 0.797280
accuracy: 0.725000
Epoch 201, CIFAR-10 Batch 3:  loss: 0.988524
accuracy: 0.725000
Epoch 201, CIFAR-10 Batch 4:  loss: 1.274109
accuracy: 0.525000
Epoch 201, CIFAR-10 Batch 5:  loss: 1.098667
accuracy: 0.700000
Epoch 202, CIFAR-10 Batch 1:  loss: 0.862386
accuracy: 0.700000
Epoch 202, CIFAR-10 Batch 2:  loss: 0.779753
accuracy: 0.725000
Epoch 202, CIFAR-10 Batch 3:  loss: 0.984191
accuracy: 0.700000
Epoch 202, CIFAR-10 Batch 4:  loss: 1.356472
accuracy: 0.500000
Epoch 202, CIFAR-10 Batch 5:  loss: 1.124419
accuracy: 0.650000
Epoch 203, CIFAR-10 Batch 1:  loss: 0.864143
accuracy: 0.750000
Epoch 203, CIFAR-10 Batch 2:  loss: 0.805227
accuracy: 0.700000
Epoch 203, CIFAR-10 Batch 3:  loss: 0.974837
accuracy: 0.700000
Epoch 203, CIFAR-10 Batch 4:  loss: 1.286588
accuracy: 0.525000
Epoch 203, CIFAR-10 Batch 5:  loss: 1.090551
accuracy: 0.700000
Epoch 204, CIFAR-10 Batch 1:  loss: 0.844359
accuracy: 0.750000
Epoch 204, CIFAR-10 Batch 2:  loss: 0.795575
accuracy: 0.725000
Epoch 204, CIFAR-10 Batch 3:  loss: 1.002624
accuracy: 0.725000
Epoch 204, CIFAR-10 Batch 4:  loss: 1.323147
accuracy: 0.525000
Epoch 204, CIFAR-10 Batch 5:  loss: 1.086143
accuracy: 0.675000
Epoch 205, CIFAR-10 Batch 1:  loss: 0.848327
accuracy: 0.800000
Epoch 205, CIFAR-10 Batch 2:  loss: 0.808800
accuracy: 0.750000
Epoch 205, CIFAR-10 Batch 3:  loss: 0.963604
accuracy: 0.700000
Epoch 205, CIFAR-10 Batch 4:  loss: 1.317685
accuracy: 0.550000
Epoch 205, CIFAR-10 Batch 5:  loss: 1.113707
accuracy: 0.625000
Epoch 206, CIFAR-10 Batch 1:  loss: 0.867680
accuracy: 0.725000
Epoch 206, CIFAR-10 Batch 2:  loss: 0.770110
accuracy: 0.725000
Epoch 206, CIFAR-10 Batch 3:  loss: 0.999471
accuracy: 0.700000
Epoch 206, CIFAR-10 Batch 4:  loss: 1.299373
accuracy: 0.475000
Epoch 206, CIFAR-10 Batch 5:  loss: 1.893395
accuracy: 0.650000
Epoch 207, CIFAR-10 Batch 1:  loss: 0.853907
accuracy: 0.750000
Epoch 207, CIFAR-10 Batch 2:  loss: 0.779567
accuracy: 0.700000
Epoch 207, CIFAR-10 Batch 3:  loss: 0.944072
accuracy: 0.750000
Epoch 207, CIFAR-10 Batch 4:  loss: 1.276887
accuracy: 0.600000
Epoch 207, CIFAR-10 Batch 5:  loss: 1.834423
accuracy: 0.675000
Epoch 208, CIFAR-10 Batch 1:  loss: 0.895637
accuracy: 0.750000
Epoch 208, CIFAR-10 Batch 2:  loss: 0.828695
accuracy: 0.700000
Epoch 208, CIFAR-10 Batch 3:  loss: 0.976828
accuracy: 0.725000
Epoch 208, CIFAR-10 Batch 4:  loss: 1.305241
accuracy: 0.500000
Epoch 208, CIFAR-10 Batch 5:  loss: 1.435101
accuracy: 0.650000
Epoch 209, CIFAR-10 Batch 1:  loss: 0.867375
accuracy: 0.675000
Epoch 209, CIFAR-10 Batch 2:  loss: 0.810193
accuracy: 0.725000
Epoch 209, CIFAR-10 Batch 3:  loss: 0.952766
accuracy: 0.700000
Epoch 209, CIFAR-10 Batch 4:  loss: 1.311634
accuracy: 0.500000
Epoch 209, CIFAR-10 Batch 5:  loss: 1.073129
accuracy: 0.650000
Epoch 210, CIFAR-10 Batch 1:  loss: 0.867272
accuracy: 0.750000
Epoch 210, CIFAR-10 Batch 2:  loss: 0.776839
accuracy: 0.750000
Epoch 210, CIFAR-10 Batch 3:  loss: 0.957676
accuracy: 0.725000
Epoch 210, CIFAR-10 Batch 4:  loss: 1.373994
accuracy: 0.550000
Epoch 210, CIFAR-10 Batch 5:  loss: 1.053468
accuracy: 0.700000
Epoch 211, CIFAR-10 Batch 1:  loss: 0.842994
accuracy: 0.775000
Epoch 211, CIFAR-10 Batch 2:  loss: 0.774221
accuracy: 0.750000
Epoch 211, CIFAR-10 Batch 3:  loss: 0.963202
accuracy: 0.725000
Epoch 211, CIFAR-10 Batch 4:  loss: 1.373382
accuracy: 0.475000
Epoch 211, CIFAR-10 Batch 5:  loss: 1.085973
accuracy: 0.725000
Epoch 212, CIFAR-10 Batch 1:  loss: 0.841415
accuracy: 0.775000
Epoch 212, CIFAR-10 Batch 2:  loss: 0.789209
accuracy: 0.750000
Epoch 212, CIFAR-10 Batch 3:  loss: 0.970957
accuracy: 0.700000
Epoch 212, CIFAR-10 Batch 4:  loss: 1.362512
accuracy: 0.450000
Epoch 212, CIFAR-10 Batch 5:  loss: 1.070913
accuracy: 0.650000
Epoch 213, CIFAR-10 Batch 1:  loss: 0.825145
accuracy: 0.750000
Epoch 213, CIFAR-10 Batch 2:  loss: 0.796881
accuracy: 0.725000
Epoch 213, CIFAR-10 Batch 3:  loss: 0.952307
accuracy: 0.650000
Epoch 213, CIFAR-10 Batch 4:  loss: 1.341001
accuracy: 0.525000
Epoch 213, CIFAR-10 Batch 5:  loss: 1.085838
accuracy: 0.725000
Epoch 214, CIFAR-10 Batch 1:  loss: 0.861423
accuracy: 0.750000
Epoch 214, CIFAR-10 Batch 2:  loss: 0.769443
accuracy: 0.725000
Epoch 214, CIFAR-10 Batch 3:  loss: 1.004699
accuracy: 0.650000
Epoch 214, CIFAR-10 Batch 4:  loss: 1.324718
accuracy: 0.525000
Epoch 214, CIFAR-10 Batch 5:  loss: 1.074829
accuracy: 0.675000
Epoch 215, CIFAR-10 Batch 1:  loss: 0.847320
accuracy: 0.775000
Epoch 215, CIFAR-10 Batch 2:  loss: 0.793391
accuracy: 0.725000
Epoch 215, CIFAR-10 Batch 3:  loss: 1.104440
accuracy: 0.725000
Epoch 215, CIFAR-10 Batch 4:  loss: 1.360464
accuracy: 0.450000
Epoch 215, CIFAR-10 Batch 5:  loss: 1.080719
accuracy: 0.700000
Epoch 216, CIFAR-10 Batch 1:  loss: 0.837969
accuracy: 0.750000
Epoch 216, CIFAR-10 Batch 2:  loss: 0.778601
accuracy: 0.725000
Epoch 216, CIFAR-10 Batch 3:  loss: 0.934585
accuracy: 0.700000
Epoch 216, CIFAR-10 Batch 4:  loss: 1.324952
accuracy: 0.500000
Epoch 216, CIFAR-10 Batch 5:  loss: 1.101577
accuracy: 0.650000
Epoch 217, CIFAR-10 Batch 1:  loss: 0.850223
accuracy: 0.750000
Epoch 217, CIFAR-10 Batch 2:  loss: 0.803034
accuracy: 0.750000
Epoch 217, CIFAR-10 Batch 3:  loss: 0.938359
accuracy: 0.725000
Epoch 217, CIFAR-10 Batch 4:  loss: 1.309517
accuracy: 0.525000
Epoch 217, CIFAR-10 Batch 5:  loss: 1.105021
accuracy: 0.675000
Epoch 218, CIFAR-10 Batch 1:  loss: 0.840774
accuracy: 0.800000
Epoch 218, CIFAR-10 Batch 2:  loss: 0.794145
accuracy: 0.725000
Epoch 218, CIFAR-10 Batch 3:  loss: 0.947574
accuracy: 0.700000
Epoch 218, CIFAR-10 Batch 4:  loss: 1.349301
accuracy: 0.475000
Epoch 218, CIFAR-10 Batch 5:  loss: 1.074476
accuracy: 0.675000
Epoch 219, CIFAR-10 Batch 1:  loss: 0.856704
accuracy: 0.775000
Epoch 219, CIFAR-10 Batch 2:  loss: 0.795481
accuracy: 0.725000
Epoch 219, CIFAR-10 Batch 3:  loss: 0.942101
accuracy: 0.725000
Epoch 219, CIFAR-10 Batch 4:  loss: 1.292433
accuracy: 0.525000
Epoch 219, CIFAR-10 Batch 5:  loss: 1.088538
accuracy: 0.675000
Epoch 220, CIFAR-10 Batch 1:  loss: 0.850846
accuracy: 0.750000
Epoch 220, CIFAR-10 Batch 2:  loss: 0.767815
accuracy: 0.700000
Epoch 220, CIFAR-10 Batch 3:  loss: 0.974720
accuracy: 0.725000
Epoch 220, CIFAR-10 Batch 4:  loss: 1.322883
accuracy: 0.525000
Epoch 220, CIFAR-10 Batch 5:  loss: 1.088315
accuracy: 0.675000
Epoch 221, CIFAR-10 Batch 1:  loss: 0.851638
accuracy: 0.750000
Epoch 221, CIFAR-10 Batch 2:  loss: 0.790786
accuracy: 0.700000
Epoch 221, CIFAR-10 Batch 3:  loss: 0.912091
accuracy: 0.750000
Epoch 221, CIFAR-10 Batch 4:  loss: 1.345335
accuracy: 0.475000
Epoch 221, CIFAR-10 Batch 5:  loss: 1.119376
accuracy: 0.625000
Epoch 222, CIFAR-10 Batch 1:  loss: 0.877546
accuracy: 0.700000
Epoch 222, CIFAR-10 Batch 2:  loss: 0.807030
accuracy: 0.725000
Epoch 222, CIFAR-10 Batch 3:  loss: 0.915275
accuracy: 0.700000
Epoch 222, CIFAR-10 Batch 4:  loss: 1.352720
accuracy: 0.450000
Epoch 222, CIFAR-10 Batch 5:  loss: 1.085853
accuracy: 0.650000
Epoch 223, CIFAR-10 Batch 1:  loss: 0.856049
accuracy: 0.750000
Epoch 223, CIFAR-10 Batch 2:  loss: 0.790679
accuracy: 0.750000
Epoch 223, CIFAR-10 Batch 3:  loss: 0.944429
accuracy: 0.750000
Epoch 223, CIFAR-10 Batch 4:  loss: 1.332702
accuracy: 0.475000
Epoch 223, CIFAR-10 Batch 5:  loss: 1.108732
accuracy: 0.650000
Epoch 224, CIFAR-10 Batch 1:  loss: 0.844604
accuracy: 0.800000
Epoch 224, CIFAR-10 Batch 2:  loss: 0.794624
accuracy: 0.725000
Epoch 224, CIFAR-10 Batch 3:  loss: 0.953499
accuracy: 0.700000
Epoch 224, CIFAR-10 Batch 4:  loss: 1.309220
accuracy: 0.550000
Epoch 224, CIFAR-10 Batch 5:  loss: 1.079259
accuracy: 0.625000
Epoch 225, CIFAR-10 Batch 1:  loss: 0.859079
accuracy: 0.775000
Epoch 225, CIFAR-10 Batch 2:  loss: 0.772429
accuracy: 0.725000
Epoch 225, CIFAR-10 Batch 3:  loss: 0.892660
accuracy: 0.700000
Epoch 225, CIFAR-10 Batch 4:  loss: 1.296576
accuracy: 0.525000
Epoch 225, CIFAR-10 Batch 5:  loss: 1.072617
accuracy: 0.675000
Epoch 226, CIFAR-10 Batch 1:  loss: 0.844307
accuracy: 0.750000
Epoch 226, CIFAR-10 Batch 2:  loss: 0.787148
accuracy: 0.700000
Epoch 226, CIFAR-10 Batch 3:  loss: 0.910227
accuracy: 0.725000
Epoch 226, CIFAR-10 Batch 4:  loss: 1.297982
accuracy: 0.475000
Epoch 226, CIFAR-10 Batch 5:  loss: 1.090852
accuracy: 0.675000
Epoch 227, CIFAR-10 Batch 1:  loss: 0.853144
accuracy: 0.725000
Epoch 227, CIFAR-10 Batch 2:  loss: 0.755612
accuracy: 0.750000
Epoch 227, CIFAR-10 Batch 3:  loss: 0.959112
accuracy: 0.650000
Epoch 227, CIFAR-10 Batch 4:  loss: 1.379519
accuracy: 0.500000
Epoch 227, CIFAR-10 Batch 5:  loss: 1.083506
accuracy: 0.700000
Epoch 228, CIFAR-10 Batch 1:  loss: 0.861031
accuracy: 0.725000
Epoch 228, CIFAR-10 Batch 2:  loss: 0.749817
accuracy: 0.725000
Epoch 228, CIFAR-10 Batch 3:  loss: 0.963803
accuracy: 0.700000
Epoch 228, CIFAR-10 Batch 4:  loss: 1.341642
accuracy: 0.475000
Epoch 228, CIFAR-10 Batch 5:  loss: 1.104010
accuracy: 0.675000
Epoch 229, CIFAR-10 Batch 1:  loss: 0.833953
accuracy: 0.800000
Epoch 229, CIFAR-10 Batch 2:  loss: 0.785669
accuracy: 0.750000
Epoch 229, CIFAR-10 Batch 3:  loss: 0.934736
accuracy: 0.700000
Epoch 229, CIFAR-10 Batch 4:  loss: 1.344882
accuracy: 0.500000
Epoch 229, CIFAR-10 Batch 5:  loss: 1.080359
accuracy: 0.650000
Epoch 230, CIFAR-10 Batch 1:  loss: 0.820776
accuracy: 0.800000
Epoch 230, CIFAR-10 Batch 2:  loss: 0.793063
accuracy: 0.725000
Epoch 230, CIFAR-10 Batch 3:  loss: 0.908789
accuracy: 0.650000
Epoch 230, CIFAR-10 Batch 4:  loss: 1.377095
accuracy: 0.475000
Epoch 230, CIFAR-10 Batch 5:  loss: 1.112886
accuracy: 0.600000
Epoch 231, CIFAR-10 Batch 1:  loss: 0.862036
accuracy: 0.725000
Epoch 231, CIFAR-10 Batch 2:  loss: 0.809304
accuracy: 0.700000
Epoch 231, CIFAR-10 Batch 3:  loss: 0.879214
accuracy: 0.725000
Epoch 231, CIFAR-10 Batch 4:  loss: 1.333967
accuracy: 0.525000
Epoch 231, CIFAR-10 Batch 5:  loss: 1.071221
accuracy: 0.650000
Epoch 232, CIFAR-10 Batch 1:  loss: 0.841553
accuracy: 0.750000
Epoch 232, CIFAR-10 Batch 2:  loss: 0.797076
accuracy: 0.700000
Epoch 232, CIFAR-10 Batch 3:  loss: 0.900783
accuracy: 0.775000
Epoch 232, CIFAR-10 Batch 4:  loss: 1.303454
accuracy: 0.500000
Epoch 232, CIFAR-10 Batch 5:  loss: 1.098646
accuracy: 0.625000
Epoch 233, CIFAR-10 Batch 1:  loss: 0.890248
accuracy: 0.700000
Epoch 233, CIFAR-10 Batch 2:  loss: 0.815550
accuracy: 0.725000
Epoch 233, CIFAR-10 Batch 3:  loss: 0.889506
accuracy: 0.700000
Epoch 233, CIFAR-10 Batch 4:  loss: 1.297532
accuracy: 0.525000
Epoch 233, CIFAR-10 Batch 5:  loss: 1.087769
accuracy: 0.675000
Epoch 234, CIFAR-10 Batch 1:  loss: 0.854778
accuracy: 0.750000
Epoch 234, CIFAR-10 Batch 2:  loss: 0.837590
accuracy: 0.725000
Epoch 234, CIFAR-10 Batch 3:  loss: 0.934508
accuracy: 0.725000
Epoch 234, CIFAR-10 Batch 4:  loss: 1.369037
accuracy: 0.500000
Epoch 234, CIFAR-10 Batch 5:  loss: 1.082306
accuracy: 0.675000
Epoch 235, CIFAR-10 Batch 1:  loss: 0.840538
accuracy: 0.775000
Epoch 235, CIFAR-10 Batch 2:  loss: 0.800554
accuracy: 0.750000
Epoch 235, CIFAR-10 Batch 3:  loss: 0.880349
accuracy: 0.750000
Epoch 235, CIFAR-10 Batch 4:  loss: 1.334606
accuracy: 0.475000
Epoch 235, CIFAR-10 Batch 5:  loss: 1.117915
accuracy: 0.625000
Epoch 236, CIFAR-10 Batch 1:  loss: 0.843158
accuracy: 0.750000
Epoch 236, CIFAR-10 Batch 2:  loss: 0.812301
accuracy: 0.750000
Epoch 236, CIFAR-10 Batch 3:  loss: 0.929577
accuracy: 0.700000
Epoch 236, CIFAR-10 Batch 4:  loss: 1.304184
accuracy: 0.525000
Epoch 236, CIFAR-10 Batch 5:  loss: 1.130014
accuracy: 0.650000
Epoch 237, CIFAR-10 Batch 1:  loss: 0.859743
accuracy: 0.725000
Epoch 237, CIFAR-10 Batch 2:  loss: 0.810553
accuracy: 0.725000
Epoch 237, CIFAR-10 Batch 3:  loss: 0.912103
accuracy: 0.700000
Epoch 237, CIFAR-10 Batch 4:  loss: 1.330622
accuracy: 0.500000
Epoch 237, CIFAR-10 Batch 5:  loss: 1.117137
accuracy: 0.650000
Epoch 238, CIFAR-10 Batch 1:  loss: 0.871593
accuracy: 0.725000
Epoch 238, CIFAR-10 Batch 2:  loss: 0.788523
accuracy: 0.750000
Epoch 238, CIFAR-10 Batch 3:  loss: 0.834874
accuracy: 0.725000
Epoch 238, CIFAR-10 Batch 4:  loss: 1.312237
accuracy: 0.525000
Epoch 238, CIFAR-10 Batch 5:  loss: 1.091747
accuracy: 0.700000
Epoch 239, CIFAR-10 Batch 1:  loss: 0.858689
accuracy: 0.800000
Epoch 239, CIFAR-10 Batch 2:  loss: 0.797693
accuracy: 0.775000
Epoch 239, CIFAR-10 Batch 3:  loss: 0.840770
accuracy: 0.725000
Epoch 239, CIFAR-10 Batch 4:  loss: 1.319152
accuracy: 0.500000
Epoch 239, CIFAR-10 Batch 5:  loss: 1.087262
accuracy: 0.650000
Epoch 240, CIFAR-10 Batch 1:  loss: 0.846704
accuracy: 0.775000
Epoch 240, CIFAR-10 Batch 2:  loss: 0.790501
accuracy: 0.725000
Epoch 240, CIFAR-10 Batch 3:  loss: 0.846577
accuracy: 0.775000
Epoch 240, CIFAR-10 Batch 4:  loss: 1.331302
accuracy: 0.475000
Epoch 240, CIFAR-10 Batch 5:  loss: 1.120613
accuracy: 0.675000
Epoch 241, CIFAR-10 Batch 1:  loss: 0.840243
accuracy: 0.750000
Epoch 241, CIFAR-10 Batch 2:  loss: 0.796251
accuracy: 0.750000
Epoch 241, CIFAR-10 Batch 3:  loss: 0.873923
accuracy: 0.750000
Epoch 241, CIFAR-10 Batch 4:  loss: 1.286539
accuracy: 0.500000
Epoch 241, CIFAR-10 Batch 5:  loss: 1.120731
accuracy: 0.650000
Epoch 242, CIFAR-10 Batch 1:  loss: 0.858240
accuracy: 0.750000
Epoch 242, CIFAR-10 Batch 2:  loss: 0.746136
accuracy: 0.725000
Epoch 242, CIFAR-10 Batch 3:  loss: 0.868731
accuracy: 0.725000
Epoch 242, CIFAR-10 Batch 4:  loss: 1.303602
accuracy: 0.500000
Epoch 242, CIFAR-10 Batch 5:  loss: 1.138732
accuracy: 0.650000
Epoch 243, CIFAR-10 Batch 1:  loss: 0.847630
accuracy: 0.750000
Epoch 243, CIFAR-10 Batch 2:  loss: 0.787797
accuracy: 0.775000
Epoch 243, CIFAR-10 Batch 3:  loss: 0.836830
accuracy: 0.775000
Epoch 243, CIFAR-10 Batch 4:  loss: 1.336219
accuracy: 0.500000
Epoch 243, CIFAR-10 Batch 5:  loss: 1.118875
accuracy: 0.650000
Epoch 244, CIFAR-10 Batch 1:  loss: 0.870929
accuracy: 0.750000
Epoch 244, CIFAR-10 Batch 2:  loss: 0.790035
accuracy: 0.750000
Epoch 244, CIFAR-10 Batch 3:  loss: 0.834223
accuracy: 0.700000
Epoch 244, CIFAR-10 Batch 4:  loss: 1.335494
accuracy: 0.500000
Epoch 244, CIFAR-10 Batch 5:  loss: 1.118607
accuracy: 0.650000
Epoch 245, CIFAR-10 Batch 1:  loss: 0.855745
accuracy: 0.725000
Epoch 245, CIFAR-10 Batch 2:  loss: 0.796396
accuracy: 0.700000
Epoch 245, CIFAR-10 Batch 3:  loss: 0.892633
accuracy: 0.725000
Epoch 245, CIFAR-10 Batch 4:  loss: 1.307689
accuracy: 0.500000
Epoch 245, CIFAR-10 Batch 5:  loss: 1.122426
accuracy: 0.650000
Epoch 246, CIFAR-10 Batch 1:  loss: 0.871741
accuracy: 0.750000
Epoch 246, CIFAR-10 Batch 2:  loss: 0.809598
accuracy: 0.775000
Epoch 246, CIFAR-10 Batch 3:  loss: 0.835848
accuracy: 0.750000
Epoch 246, CIFAR-10 Batch 4:  loss: 1.295426
accuracy: 0.550000
Epoch 246, CIFAR-10 Batch 5:  loss: 1.091583
accuracy: 0.675000
Epoch 247, CIFAR-10 Batch 1:  loss: 0.900739
accuracy: 0.725000
Epoch 247, CIFAR-10 Batch 2:  loss: 0.773477
accuracy: 0.750000
Epoch 247, CIFAR-10 Batch 3:  loss: 0.865955
accuracy: 0.750000
Epoch 247, CIFAR-10 Batch 4:  loss: 1.270158
accuracy: 0.525000
Epoch 247, CIFAR-10 Batch 5:  loss: 1.119916
accuracy: 0.625000
Epoch 248, CIFAR-10 Batch 1:  loss: 0.846906
accuracy: 0.750000
Epoch 248, CIFAR-10 Batch 2:  loss: 0.786427
accuracy: 0.750000
Epoch 248, CIFAR-10 Batch 3:  loss: 0.791664
accuracy: 0.775000
Epoch 248, CIFAR-10 Batch 4:  loss: 1.399544
accuracy: 0.425000
Epoch 248, CIFAR-10 Batch 5:  loss: 1.137316
accuracy: 0.625000
Epoch 249, CIFAR-10 Batch 1:  loss: 0.870068
accuracy: 0.750000
Epoch 249, CIFAR-10 Batch 2:  loss: 0.773174
accuracy: 0.775000
Epoch 249, CIFAR-10 Batch 3:  loss: 0.816694
accuracy: 0.800000
Epoch 249, CIFAR-10 Batch 4:  loss: 1.303491
accuracy: 0.475000
Epoch 249, CIFAR-10 Batch 5:  loss: 1.096799
accuracy: 0.625000
Epoch 250, CIFAR-10 Batch 1:  loss: 0.862110
accuracy: 0.725000
Epoch 250, CIFAR-10 Batch 2:  loss: 0.789280
accuracy: 0.750000
Epoch 250, CIFAR-10 Batch 3:  loss: 0.801573
accuracy: 0.750000
Epoch 250, CIFAR-10 Batch 4:  loss: 1.668304
accuracy: 0.425000
Epoch 250, CIFAR-10 Batch 5:  loss: 1.077578
accuracy: 0.650000
Epoch 251, CIFAR-10 Batch 1:  loss: 0.844227
accuracy: 0.750000
Epoch 251, CIFAR-10 Batch 2:  loss: 0.775801
accuracy: 0.775000
Epoch 251, CIFAR-10 Batch 3:  loss: 0.823805
accuracy: 0.750000
Epoch 251, CIFAR-10 Batch 4:  loss: 1.331018
accuracy: 0.475000
Epoch 251, CIFAR-10 Batch 5:  loss: 1.106396
accuracy: 0.600000
Epoch 252, CIFAR-10 Batch 1:  loss: 0.845693
accuracy: 0.750000
Epoch 252, CIFAR-10 Batch 2:  loss: 0.777231
accuracy: 0.775000
Epoch 252, CIFAR-10 Batch 3:  loss: 0.842709
accuracy: 0.775000
Epoch 252, CIFAR-10 Batch 4:  loss: 1.310182
accuracy: 0.450000
Epoch 252, CIFAR-10 Batch 5:  loss: 1.135035
accuracy: 0.625000
Epoch 253, CIFAR-10 Batch 1:  loss: 0.848537
accuracy: 0.725000
Epoch 253, CIFAR-10 Batch 2:  loss: 0.810771
accuracy: 0.750000
Epoch 253, CIFAR-10 Batch 3:  loss: 0.829009
accuracy: 0.750000
Epoch 253, CIFAR-10 Batch 4:  loss: 1.273968
accuracy: 0.550000
Epoch 253, CIFAR-10 Batch 5:  loss: 1.116061
accuracy: 0.675000
Epoch 254, CIFAR-10 Batch 1:  loss: 0.867334
accuracy: 0.750000
Epoch 254, CIFAR-10 Batch 2:  loss: 0.772927
accuracy: 0.775000
Epoch 254, CIFAR-10 Batch 3:  loss: 0.816175
accuracy: 0.825000
Epoch 254, CIFAR-10 Batch 4:  loss: 1.350023
accuracy: 0.500000
Epoch 254, CIFAR-10 Batch 5:  loss: 1.087417
accuracy: 0.675000
Epoch 255, CIFAR-10 Batch 1:  loss: 0.821094
accuracy: 0.775000
Epoch 255, CIFAR-10 Batch 2:  loss: 0.794710
accuracy: 0.750000
Epoch 255, CIFAR-10 Batch 3:  loss: 0.854919
accuracy: 0.750000
Epoch 255, CIFAR-10 Batch 4:  loss: 1.359769
accuracy: 0.475000
Epoch 255, CIFAR-10 Batch 5:  loss: 1.080416
accuracy: 0.625000
Epoch 256, CIFAR-10 Batch 1:  loss: 0.841924
accuracy: 0.800000
Epoch 256, CIFAR-10 Batch 2:  loss: 0.796142
accuracy: 0.725000
Epoch 256, CIFAR-10 Batch 3:  loss: 0.796358
accuracy: 0.775000
Epoch 256, CIFAR-10 Batch 4:  loss: 1.315820
accuracy: 0.500000
Epoch 256, CIFAR-10 Batch 5:  loss: 1.070274
accuracy: 0.675000
Epoch 257, CIFAR-10 Batch 1:  loss: 0.839236
accuracy: 0.800000
Epoch 257, CIFAR-10 Batch 2:  loss: 0.724457
accuracy: 0.775000
Epoch 257, CIFAR-10 Batch 3:  loss: 0.809666
accuracy: 0.750000
Epoch 257, CIFAR-10 Batch 4:  loss: 1.293552
accuracy: 0.500000
Epoch 257, CIFAR-10 Batch 5:  loss: 1.137981
accuracy: 0.625000
Epoch 258, CIFAR-10 Batch 1:  loss: 0.866500
accuracy: 0.725000
Epoch 258, CIFAR-10 Batch 2:  loss: 0.776074
accuracy: 0.750000
Epoch 258, CIFAR-10 Batch 3:  loss: 0.807011
accuracy: 0.750000
Epoch 258, CIFAR-10 Batch 4:  loss: 1.344051
accuracy: 0.450000
Epoch 258, CIFAR-10 Batch 5:  loss: 1.093780
accuracy: 0.650000
Epoch 259, CIFAR-10 Batch 1:  loss: 0.837556
accuracy: 0.775000
Epoch 259, CIFAR-10 Batch 2:  loss: 0.787034
accuracy: 0.750000
Epoch 259, CIFAR-10 Batch 3:  loss: 0.788521
accuracy: 0.800000
Epoch 259, CIFAR-10 Batch 4:  loss: 1.318514
accuracy: 0.500000
Epoch 259, CIFAR-10 Batch 5:  loss: 1.120280
accuracy: 0.675000
Epoch 260, CIFAR-10 Batch 1:  loss: 0.840201
accuracy: 0.775000
Epoch 260, CIFAR-10 Batch 2:  loss: 0.855577
accuracy: 0.725000
Epoch 260, CIFAR-10 Batch 3:  loss: 0.822916
accuracy: 0.725000
Epoch 260, CIFAR-10 Batch 4:  loss: 1.316131
accuracy: 0.525000
Epoch 260, CIFAR-10 Batch 5:  loss: 1.117090
accuracy: 0.625000
Epoch 261, CIFAR-10 Batch 1:  loss: 0.857241
accuracy: 0.700000
Epoch 261, CIFAR-10 Batch 2:  loss: 0.799644
accuracy: 0.775000
Epoch 261, CIFAR-10 Batch 3:  loss: 0.818938
accuracy: 0.800000
Epoch 261, CIFAR-10 Batch 4:  loss: 1.292452
accuracy: 0.500000
Epoch 261, CIFAR-10 Batch 5:  loss: 1.088969
accuracy: 0.650000
Epoch 262, CIFAR-10 Batch 1:  loss: 0.867099
accuracy: 0.725000
Epoch 262, CIFAR-10 Batch 2:  loss: 0.776331
accuracy: 0.775000
Epoch 262, CIFAR-10 Batch 3:  loss: 0.824368
accuracy: 0.750000
Epoch 262, CIFAR-10 Batch 4:  loss: 1.329039
accuracy: 0.500000
Epoch 262, CIFAR-10 Batch 5:  loss: 1.129358
accuracy: 0.625000
Epoch 263, CIFAR-10 Batch 1:  loss: 0.853228
accuracy: 0.725000
Epoch 263, CIFAR-10 Batch 2:  loss: 0.797902
accuracy: 0.750000
Epoch 263, CIFAR-10 Batch 3:  loss: 0.809418
accuracy: 0.775000
Epoch 263, CIFAR-10 Batch 4:  loss: 1.351630
accuracy: 0.450000
Epoch 263, CIFAR-10 Batch 5:  loss: 1.099273
accuracy: 0.675000
Epoch 264, CIFAR-10 Batch 1:  loss: 0.839932
accuracy: 0.725000
Epoch 264, CIFAR-10 Batch 2:  loss: 0.793492
accuracy: 0.750000
Epoch 264, CIFAR-10 Batch 3:  loss: 0.841055
accuracy: 0.675000
Epoch 264, CIFAR-10 Batch 4:  loss: 1.286222
accuracy: 0.500000
Epoch 264, CIFAR-10 Batch 5:  loss: 1.102675
accuracy: 0.600000
Epoch 265, CIFAR-10 Batch 1:  loss: 0.850366
accuracy: 0.775000
Epoch 265, CIFAR-10 Batch 2:  loss: 0.779309
accuracy: 0.700000
Epoch 265, CIFAR-10 Batch 3:  loss: 0.798672
accuracy: 0.775000
Epoch 265, CIFAR-10 Batch 4:  loss: 1.325965
accuracy: 0.475000
Epoch 265, CIFAR-10 Batch 5:  loss: 1.168220
accuracy: 0.575000
Epoch 266, CIFAR-10 Batch 1:  loss: 0.834394
accuracy: 0.775000
Epoch 266, CIFAR-10 Batch 2:  loss: 0.763189
accuracy: 0.800000
Epoch 266, CIFAR-10 Batch 3:  loss: 0.806276
accuracy: 0.775000
Epoch 266, CIFAR-10 Batch 4:  loss: 1.299541
accuracy: 0.500000
Epoch 266, CIFAR-10 Batch 5:  loss: 1.110967
accuracy: 0.625000
Epoch 267, CIFAR-10 Batch 1:  loss: 0.860279
accuracy: 0.775000
Epoch 267, CIFAR-10 Batch 2:  loss: 0.790125
accuracy: 0.775000
Epoch 267, CIFAR-10 Batch 3:  loss: 0.822487
accuracy: 0.725000
Epoch 267, CIFAR-10 Batch 4:  loss: 1.295774
accuracy: 0.525000
Epoch 267, CIFAR-10 Batch 5:  loss: 1.130398
accuracy: 0.600000
Epoch 268, CIFAR-10 Batch 1:  loss: 0.827799
accuracy: 0.775000
Epoch 268, CIFAR-10 Batch 2:  loss: 0.805549
accuracy: 0.800000
Epoch 268, CIFAR-10 Batch 3:  loss: 0.797608
accuracy: 0.725000
Epoch 268, CIFAR-10 Batch 4:  loss: 1.308124
accuracy: 0.475000
Epoch 268, CIFAR-10 Batch 5:  loss: 1.138170
accuracy: 0.600000
Epoch 269, CIFAR-10 Batch 1:  loss: 0.855492
accuracy: 0.775000
Epoch 269, CIFAR-10 Batch 2:  loss: 0.772317
accuracy: 0.775000
Epoch 269, CIFAR-10 Batch 3:  loss: 0.824071
accuracy: 0.825000
Epoch 269, CIFAR-10 Batch 4:  loss: 1.313758
accuracy: 0.475000
Epoch 269, CIFAR-10 Batch 5:  loss: 1.124272
accuracy: 0.650000
Epoch 270, CIFAR-10 Batch 1:  loss: 0.844231
accuracy: 0.750000
Epoch 270, CIFAR-10 Batch 2:  loss: 0.824108
accuracy: 0.700000
Epoch 270, CIFAR-10 Batch 3:  loss: 0.841112
accuracy: 0.800000
Epoch 270, CIFAR-10 Batch 4:  loss: 1.352370
accuracy: 0.450000
Epoch 270, CIFAR-10 Batch 5:  loss: 1.117558
accuracy: 0.575000
Epoch 271, CIFAR-10 Batch 1:  loss: 0.844548
accuracy: 0.775000
Epoch 271, CIFAR-10 Batch 2:  loss: 0.788111
accuracy: 0.725000
Epoch 271, CIFAR-10 Batch 3:  loss: 0.842793
accuracy: 0.725000
Epoch 271, CIFAR-10 Batch 4:  loss: 1.302419
accuracy: 0.500000
Epoch 271, CIFAR-10 Batch 5:  loss: 1.114870
accuracy: 0.625000
Epoch 272, CIFAR-10 Batch 1:  loss: 0.850710
accuracy: 0.750000
Epoch 272, CIFAR-10 Batch 2:  loss: 0.822843
accuracy: 0.750000
Epoch 272, CIFAR-10 Batch 3:  loss: 0.843405
accuracy: 0.750000
Epoch 272, CIFAR-10 Batch 4:  loss: 1.332203
accuracy: 0.475000
Epoch 272, CIFAR-10 Batch 5:  loss: 1.100403
accuracy: 0.650000
Epoch 273, CIFAR-10 Batch 1:  loss: 0.855784
accuracy: 0.725000
Epoch 273, CIFAR-10 Batch 2:  loss: 0.792668
accuracy: 0.750000
Epoch 273, CIFAR-10 Batch 3:  loss: 0.857997
accuracy: 0.775000
Epoch 273, CIFAR-10 Batch 4:  loss: 1.291584
accuracy: 0.475000
Epoch 273, CIFAR-10 Batch 5:  loss: 1.122373
accuracy: 0.575000
Epoch 274, CIFAR-10 Batch 1:  loss: 0.841651
accuracy: 0.725000
Epoch 274, CIFAR-10 Batch 2:  loss: 0.806885
accuracy: 0.750000
Epoch 274, CIFAR-10 Batch 3:  loss: 0.816558
accuracy: 0.775000
Epoch 274, CIFAR-10 Batch 4:  loss: 1.292528
accuracy: 0.500000
Epoch 274, CIFAR-10 Batch 5:  loss: 1.062228
accuracy: 0.625000
Epoch 275, CIFAR-10 Batch 1:  loss: 0.862064
accuracy: 0.700000
Epoch 275, CIFAR-10 Batch 2:  loss: 0.769645
accuracy: 0.775000
Epoch 275, CIFAR-10 Batch 3:  loss: 0.789958
accuracy: 0.800000
Epoch 275, CIFAR-10 Batch 4:  loss: 1.255864
accuracy: 0.525000
Epoch 275, CIFAR-10 Batch 5:  loss: 1.110906
accuracy: 0.575000
Epoch 276, CIFAR-10 Batch 1:  loss: 0.837608
accuracy: 0.775000
Epoch 276, CIFAR-10 Batch 2:  loss: 0.755540
accuracy: 0.800000
Epoch 276, CIFAR-10 Batch 3:  loss: 0.818128
accuracy: 0.825000
Epoch 276, CIFAR-10 Batch 4:  loss: 1.289450
accuracy: 0.500000
Epoch 276, CIFAR-10 Batch 5:  loss: 1.096141
accuracy: 0.625000
Epoch 277, CIFAR-10 Batch 1:  loss: 0.835498
accuracy: 0.725000
Epoch 277, CIFAR-10 Batch 2:  loss: 0.815014
accuracy: 0.750000
Epoch 277, CIFAR-10 Batch 3:  loss: 0.800393
accuracy: 0.800000
Epoch 277, CIFAR-10 Batch 4:  loss: 1.256958
accuracy: 0.525000
Epoch 277, CIFAR-10 Batch 5:  loss: 1.166943
accuracy: 0.575000
Epoch 278, CIFAR-10 Batch 1:  loss: 0.795890
accuracy: 0.775000
Epoch 278, CIFAR-10 Batch 2:  loss: 0.776749
accuracy: 0.750000
Epoch 278, CIFAR-10 Batch 3:  loss: 0.824257
accuracy: 0.800000
Epoch 278, CIFAR-10 Batch 4:  loss: 1.290095
accuracy: 0.525000
Epoch 278, CIFAR-10 Batch 5:  loss: 1.092566
accuracy: 0.600000
Epoch 279, CIFAR-10 Batch 1:  loss: 0.824293
accuracy: 0.775000
Epoch 279, CIFAR-10 Batch 2:  loss: 0.721491
accuracy: 0.775000
Epoch 279, CIFAR-10 Batch 3:  loss: 0.809141
accuracy: 0.800000
Epoch 279, CIFAR-10 Batch 4:  loss: 1.329902
accuracy: 0.450000
Epoch 279, CIFAR-10 Batch 5:  loss: 1.136882
accuracy: 0.600000
Epoch 280, CIFAR-10 Batch 1:  loss: 0.841611
accuracy: 0.775000
Epoch 280, CIFAR-10 Batch 2:  loss: 0.751644
accuracy: 0.775000
Epoch 280, CIFAR-10 Batch 3:  loss: 0.878099
accuracy: 0.725000
Epoch 280, CIFAR-10 Batch 4:  loss: 1.330099
accuracy: 0.475000
Epoch 280, CIFAR-10 Batch 5:  loss: 1.098922
accuracy: 0.650000
Epoch 281, CIFAR-10 Batch 1:  loss: 0.850410
accuracy: 0.700000
Epoch 281, CIFAR-10 Batch 2:  loss: 0.723382
accuracy: 0.800000
Epoch 281, CIFAR-10 Batch 3:  loss: 0.883522
accuracy: 0.775000
Epoch 281, CIFAR-10 Batch 4:  loss: 1.283946
accuracy: 0.550000
Epoch 281, CIFAR-10 Batch 5:  loss: 1.109157
accuracy: 0.600000
Epoch 282, CIFAR-10 Batch 1:  loss: 0.831019
accuracy: 0.775000
Epoch 282, CIFAR-10 Batch 2:  loss: 0.749832
accuracy: 0.800000
Epoch 282, CIFAR-10 Batch 3:  loss: 0.801611
accuracy: 0.825000
Epoch 282, CIFAR-10 Batch 4:  loss: 1.274890
accuracy: 0.525000
Epoch 282, CIFAR-10 Batch 5:  loss: 1.102417
accuracy: 0.600000
Epoch 283, CIFAR-10 Batch 1:  loss: 0.823336
accuracy: 0.775000
Epoch 283, CIFAR-10 Batch 2:  loss: 0.761204
accuracy: 0.800000
Epoch 283, CIFAR-10 Batch 3:  loss: 0.834513
accuracy: 0.775000
Epoch 283, CIFAR-10 Batch 4:  loss: 1.273261
accuracy: 0.575000
Epoch 283, CIFAR-10 Batch 5:  loss: 1.105171
accuracy: 0.625000
Epoch 284, CIFAR-10 Batch 1:  loss: 0.802819
accuracy: 0.800000
Epoch 284, CIFAR-10 Batch 2:  loss: 0.770206
accuracy: 0.775000
Epoch 284, CIFAR-10 Batch 3:  loss: 0.874375
accuracy: 0.775000
Epoch 284, CIFAR-10 Batch 4:  loss: 1.286663
accuracy: 0.475000
Epoch 284, CIFAR-10 Batch 5:  loss: 1.125892
accuracy: 0.600000
Epoch 285, CIFAR-10 Batch 1:  loss: 0.855497
accuracy: 0.725000
Epoch 285, CIFAR-10 Batch 2:  loss: 0.799483
accuracy: 0.725000
Epoch 285, CIFAR-10 Batch 3:  loss: 0.854523
accuracy: 0.800000
Epoch 285, CIFAR-10 Batch 4:  loss: 1.289266
accuracy: 0.500000
Epoch 285, CIFAR-10 Batch 5:  loss: 1.088814
accuracy: 0.650000
Epoch 286, CIFAR-10 Batch 1:  loss: 0.815093
accuracy: 0.800000
Epoch 286, CIFAR-10 Batch 2:  loss: 0.790365
accuracy: 0.750000
Epoch 286, CIFAR-10 Batch 3:  loss: 0.847419
accuracy: 0.775000
Epoch 286, CIFAR-10 Batch 4:  loss: 1.277086
accuracy: 0.475000
Epoch 286, CIFAR-10 Batch 5:  loss: 1.079388
accuracy: 0.625000
Epoch 287, CIFAR-10 Batch 1:  loss: 0.850431
accuracy: 0.750000
Epoch 287, CIFAR-10 Batch 2:  loss: 0.753699
accuracy: 0.750000
Epoch 287, CIFAR-10 Batch 3:  loss: 0.835497
accuracy: 0.825000
Epoch 287, CIFAR-10 Batch 4:  loss: 1.573007
accuracy: 0.475000
Epoch 287, CIFAR-10 Batch 5:  loss: 1.110229
accuracy: 0.625000
Epoch 288, CIFAR-10 Batch 1:  loss: 0.838140
accuracy: 0.750000
Epoch 288, CIFAR-10 Batch 2:  loss: 0.776460
accuracy: 0.775000
Epoch 288, CIFAR-10 Batch 3:  loss: 0.842203
accuracy: 0.775000
Epoch 288, CIFAR-10 Batch 4:  loss: 1.276914
accuracy: 0.525000
Epoch 288, CIFAR-10 Batch 5:  loss: 1.084660
accuracy: 0.650000
Epoch 289, CIFAR-10 Batch 1:  loss: 0.847419
accuracy: 0.775000
Epoch 289, CIFAR-10 Batch 2:  loss: 0.769190
accuracy: 0.800000
Epoch 289, CIFAR-10 Batch 3:  loss: 0.854744
accuracy: 0.800000
Epoch 289, CIFAR-10 Batch 4:  loss: 1.252587
accuracy: 0.550000
Epoch 289, CIFAR-10 Batch 5:  loss: 1.077917
accuracy: 0.600000
Epoch 290, CIFAR-10 Batch 1:  loss: 0.812994
accuracy: 0.775000
Epoch 290, CIFAR-10 Batch 2:  loss: 0.791171
accuracy: 0.775000
Epoch 290, CIFAR-10 Batch 3:  loss: 0.810910
accuracy: 0.825000
Epoch 290, CIFAR-10 Batch 4:  loss: 1.236110
accuracy: 0.525000
Epoch 290, CIFAR-10 Batch 5:  loss: 1.087514
accuracy: 0.625000
Epoch 291, CIFAR-10 Batch 1:  loss: 0.832143
accuracy: 0.800000
Epoch 291, CIFAR-10 Batch 2:  loss: 0.760236
accuracy: 0.775000
Epoch 291, CIFAR-10 Batch 3:  loss: 0.825140
accuracy: 0.800000
Epoch 291, CIFAR-10 Batch 4:  loss: 1.304717
accuracy: 0.475000
Epoch 291, CIFAR-10 Batch 5:  loss: 1.070235
accuracy: 0.675000
Epoch 292, CIFAR-10 Batch 1:  loss: 0.832255
accuracy: 0.800000
Epoch 292, CIFAR-10 Batch 2:  loss: 0.779894
accuracy: 0.775000
Epoch 292, CIFAR-10 Batch 3:  loss: 0.854083
accuracy: 0.800000
Epoch 292, CIFAR-10 Batch 4:  loss: 1.253574
accuracy: 0.575000
Epoch 292, CIFAR-10 Batch 5:  loss: 1.090491
accuracy: 0.650000
Epoch 293, CIFAR-10 Batch 1:  loss: 0.846046
accuracy: 0.725000
Epoch 293, CIFAR-10 Batch 2:  loss: 0.792409
accuracy: 0.775000
Epoch 293, CIFAR-10 Batch 3:  loss: 0.827747
accuracy: 0.775000
Epoch 293, CIFAR-10 Batch 4:  loss: 1.311013
accuracy: 0.475000
Epoch 293, CIFAR-10 Batch 5:  loss: 1.089588
accuracy: 0.625000
Epoch 294, CIFAR-10 Batch 1:  loss: 0.826962
accuracy: 0.725000
Epoch 294, CIFAR-10 Batch 2:  loss: 0.788567
accuracy: 0.775000
Epoch 294, CIFAR-10 Batch 3:  loss: 0.839875
accuracy: 0.775000
Epoch 294, CIFAR-10 Batch 4:  loss: 1.202702
accuracy: 0.600000
Epoch 294, CIFAR-10 Batch 5:  loss: 1.145032
accuracy: 0.600000
Epoch 295, CIFAR-10 Batch 1:  loss: 0.836041
accuracy: 0.775000
Epoch 295, CIFAR-10 Batch 2:  loss: 0.791511
accuracy: 0.775000
Epoch 295, CIFAR-10 Batch 3:  loss: 0.818245
accuracy: 0.775000
Epoch 295, CIFAR-10 Batch 4:  loss: 1.241888
accuracy: 0.550000
Epoch 295, CIFAR-10 Batch 5:  loss: 1.141476
accuracy: 0.600000
Epoch 296, CIFAR-10 Batch 1:  loss: 0.823138
accuracy: 0.800000
Epoch 296, CIFAR-10 Batch 2:  loss: 0.754331
accuracy: 0.800000
Epoch 296, CIFAR-10 Batch 3:  loss: 0.874779
accuracy: 0.775000
Epoch 296, CIFAR-10 Batch 4:  loss: 1.263394
accuracy: 0.525000
Epoch 296, CIFAR-10 Batch 5:  loss: 1.175452
accuracy: 0.625000
Epoch 297, CIFAR-10 Batch 1:  loss: 0.815771
accuracy: 0.775000
Epoch 297, CIFAR-10 Batch 2:  loss: 0.750915
accuracy: 0.800000
Epoch 297, CIFAR-10 Batch 3:  loss: 0.860864
accuracy: 0.750000
Epoch 297, CIFAR-10 Batch 4:  loss: 1.276027
accuracy: 0.525000
Epoch 297, CIFAR-10 Batch 5:  loss: 1.121346
accuracy: 0.650000
Epoch 298, CIFAR-10 Batch 1:  loss: 0.830280
accuracy: 0.775000
Epoch 298, CIFAR-10 Batch 2:  loss: 0.844606
accuracy: 0.750000
Epoch 298, CIFAR-10 Batch 3:  loss: 0.852849
accuracy: 0.775000
Epoch 298, CIFAR-10 Batch 4:  loss: 1.251385
accuracy: 0.575000
Epoch 298, CIFAR-10 Batch 5:  loss: 1.069444
accuracy: 0.675000
Epoch 299, CIFAR-10 Batch 1:  loss: 0.828379
accuracy: 0.800000
Epoch 299, CIFAR-10 Batch 2:  loss: 0.769937
accuracy: 0.800000
Epoch 299, CIFAR-10 Batch 3:  loss: 0.838093
accuracy: 0.775000
Epoch 299, CIFAR-10 Batch 4:  loss: 1.239049
accuracy: 0.550000
Epoch 299, CIFAR-10 Batch 5:  loss: 1.086567
accuracy: 0.650000
Epoch 300, CIFAR-10 Batch 1:  loss: 0.790325
accuracy: 0.825000
Epoch 300, CIFAR-10 Batch 2:  loss: 0.816453
accuracy: 0.750000
Epoch 300, CIFAR-10 Batch 3:  loss: 0.871904
accuracy: 0.775000
Epoch 300, CIFAR-10 Batch 4:  loss: 1.300124
accuracy: 0.550000
Epoch 300, CIFAR-10 Batch 5:  loss: 1.107451
accuracy: 0.625000
Epoch 301, CIFAR-10 Batch 1:  loss: 0.828046
accuracy: 0.750000
Epoch 301, CIFAR-10 Batch 2:  loss: 0.789362
accuracy: 0.800000
Epoch 301, CIFAR-10 Batch 3:  loss: 0.835408
accuracy: 0.750000
Epoch 301, CIFAR-10 Batch 4:  loss: 1.303588
accuracy: 0.550000
Epoch 301, CIFAR-10 Batch 5:  loss: 1.079401
accuracy: 0.650000
Epoch 302, CIFAR-10 Batch 1:  loss: 0.812631
accuracy: 0.750000
Epoch 302, CIFAR-10 Batch 2:  loss: 0.766097
accuracy: 0.800000
Epoch 302, CIFAR-10 Batch 3:  loss: 0.867246
accuracy: 0.750000
Epoch 302, CIFAR-10 Batch 4:  loss: 1.293109
accuracy: 0.550000
Epoch 302, CIFAR-10 Batch 5:  loss: 1.132226
accuracy: 0.600000
Epoch 303, CIFAR-10 Batch 1:  loss: 0.806302
accuracy: 0.775000
Epoch 303, CIFAR-10 Batch 2:  loss: 0.767504
accuracy: 0.775000
Epoch 303, CIFAR-10 Batch 3:  loss: 0.822297
accuracy: 0.725000
Epoch 303, CIFAR-10 Batch 4:  loss: 1.244859
accuracy: 0.575000
Epoch 303, CIFAR-10 Batch 5:  loss: 1.103342
accuracy: 0.625000
Epoch 304, CIFAR-10 Batch 1:  loss: 0.811335
accuracy: 0.725000
Epoch 304, CIFAR-10 Batch 2:  loss: 0.784822
accuracy: 0.775000
Epoch 304, CIFAR-10 Batch 3:  loss: 0.854144
accuracy: 0.800000
Epoch 304, CIFAR-10 Batch 4:  loss: 1.254971
accuracy: 0.550000
Epoch 304, CIFAR-10 Batch 5:  loss: 1.130594
accuracy: 0.550000
Epoch 305, CIFAR-10 Batch 1:  loss: 0.816804
accuracy: 0.750000
Epoch 305, CIFAR-10 Batch 2:  loss: 0.780473
accuracy: 0.775000
Epoch 305, CIFAR-10 Batch 3:  loss: 0.834888
accuracy: 0.825000
Epoch 305, CIFAR-10 Batch 4:  loss: 1.252944
accuracy: 0.525000
Epoch 305, CIFAR-10 Batch 5:  loss: 1.115451
accuracy: 0.600000
Epoch 306, CIFAR-10 Batch 1:  loss: 0.841878
accuracy: 0.775000
Epoch 306, CIFAR-10 Batch 2:  loss: 0.794599
accuracy: 0.775000
Epoch 306, CIFAR-10 Batch 3:  loss: 0.854271
accuracy: 0.750000
Epoch 306, CIFAR-10 Batch 4:  loss: 1.202807
accuracy: 0.525000
Epoch 306, CIFAR-10 Batch 5:  loss: 1.065953
accuracy: 0.675000
Epoch 307, CIFAR-10 Batch 1:  loss: 0.825297
accuracy: 0.800000
Epoch 307, CIFAR-10 Batch 2:  loss: 0.804131
accuracy: 0.750000
Epoch 307, CIFAR-10 Batch 3:  loss: 0.875366
accuracy: 0.775000
Epoch 307, CIFAR-10 Batch 4:  loss: 1.270270
accuracy: 0.575000
Epoch 307, CIFAR-10 Batch 5:  loss: 1.052629
accuracy: 0.675000
Epoch 308, CIFAR-10 Batch 1:  loss: 0.814341
accuracy: 0.775000
Epoch 308, CIFAR-10 Batch 2:  loss: 0.786287
accuracy: 0.775000
Epoch 308, CIFAR-10 Batch 3:  loss: 0.870837
accuracy: 0.725000
Epoch 308, CIFAR-10 Batch 4:  loss: 1.233654
accuracy: 0.525000
Epoch 308, CIFAR-10 Batch 5:  loss: 1.068056
accuracy: 0.675000
Epoch 309, CIFAR-10 Batch 1:  loss: 0.820590
accuracy: 0.775000
Epoch 309, CIFAR-10 Batch 2:  loss: 0.769122
accuracy: 0.800000
Epoch 309, CIFAR-10 Batch 3:  loss: 0.875911
accuracy: 0.725000
Epoch 309, CIFAR-10 Batch 4:  loss: 1.244293
accuracy: 0.550000
Epoch 309, CIFAR-10 Batch 5:  loss: 1.052438
accuracy: 0.650000
Epoch 310, CIFAR-10 Batch 1:  loss: 0.831048
accuracy: 0.800000
Epoch 310, CIFAR-10 Batch 2:  loss: 0.787532
accuracy: 0.775000
Epoch 310, CIFAR-10 Batch 3:  loss: 0.853466
accuracy: 0.800000
Epoch 310, CIFAR-10 Batch 4:  loss: 1.311981
accuracy: 0.525000
Epoch 310, CIFAR-10 Batch 5:  loss: 1.061394
accuracy: 0.600000
Epoch 311, CIFAR-10 Batch 1:  loss: 0.803898
accuracy: 0.775000
Epoch 311, CIFAR-10 Batch 2:  loss: 0.785649
accuracy: 0.775000
Epoch 311, CIFAR-10 Batch 3:  loss: 0.823729
accuracy: 0.775000
Epoch 311, CIFAR-10 Batch 4:  loss: 1.265098
accuracy: 0.550000
Epoch 311, CIFAR-10 Batch 5:  loss: 1.063931
accuracy: 0.650000
Epoch 312, CIFAR-10 Batch 1:  loss: 0.835733
accuracy: 0.800000
Epoch 312, CIFAR-10 Batch 2:  loss: 0.790841
accuracy: 0.800000
Epoch 312, CIFAR-10 Batch 3:  loss: 0.810073
accuracy: 0.825000
Epoch 312, CIFAR-10 Batch 4:  loss: 1.242828
accuracy: 0.500000
Epoch 312, CIFAR-10 Batch 5:  loss: 1.063725
accuracy: 0.650000
Epoch 313, CIFAR-10 Batch 1:  loss: 0.819800
accuracy: 0.750000
Epoch 313, CIFAR-10 Batch 2:  loss: 0.788617
accuracy: 0.775000
Epoch 313, CIFAR-10 Batch 3:  loss: 0.935704
accuracy: 0.775000
Epoch 313, CIFAR-10 Batch 4:  loss: 1.235573
accuracy: 0.650000
Epoch 313, CIFAR-10 Batch 5:  loss: 1.078763
accuracy: 0.675000
Epoch 314, CIFAR-10 Batch 1:  loss: 0.816107
accuracy: 0.725000
Epoch 314, CIFAR-10 Batch 2:  loss: 0.802083
accuracy: 0.800000
Epoch 314, CIFAR-10 Batch 3:  loss: 0.897328
accuracy: 0.750000
Epoch 314, CIFAR-10 Batch 4:  loss: 1.267359
accuracy: 0.575000
Epoch 314, CIFAR-10 Batch 5:  loss: 1.073440
accuracy: 0.700000
Epoch 315, CIFAR-10 Batch 1:  loss: 0.848446
accuracy: 0.700000
Epoch 315, CIFAR-10 Batch 2:  loss: 0.792364
accuracy: 0.750000
Epoch 315, CIFAR-10 Batch 3:  loss: 0.874814
accuracy: 0.725000
Epoch 315, CIFAR-10 Batch 4:  loss: 1.251795
accuracy: 0.525000
Epoch 315, CIFAR-10 Batch 5:  loss: 1.079350
accuracy: 0.650000
Epoch 316, CIFAR-10 Batch 1:  loss: 0.839398
accuracy: 0.750000
Epoch 316, CIFAR-10 Batch 2:  loss: 0.764530
accuracy: 0.825000
Epoch 316, CIFAR-10 Batch 3:  loss: 0.847053
accuracy: 0.800000
Epoch 316, CIFAR-10 Batch 4:  loss: 1.188050
accuracy: 0.550000
Epoch 316, CIFAR-10 Batch 5:  loss: 1.049524
accuracy: 0.650000
Epoch 317, CIFAR-10 Batch 1:  loss: 0.833547
accuracy: 0.725000
Epoch 317, CIFAR-10 Batch 2:  loss: 0.785046
accuracy: 0.750000
Epoch 317, CIFAR-10 Batch 3:  loss: 0.904332
accuracy: 0.700000
Epoch 317, CIFAR-10 Batch 4:  loss: 1.255293
accuracy: 0.550000
Epoch 317, CIFAR-10 Batch 5:  loss: 1.138271
accuracy: 0.625000
Epoch 318, CIFAR-10 Batch 1:  loss: 0.834365
accuracy: 0.750000
Epoch 318, CIFAR-10 Batch 2:  loss: 0.773868
accuracy: 0.800000
Epoch 318, CIFAR-10 Batch 3:  loss: 0.873737
accuracy: 0.725000
Epoch 318, CIFAR-10 Batch 4:  loss: 1.244241
accuracy: 0.550000
Epoch 318, CIFAR-10 Batch 5:  loss: 1.082702
accuracy: 0.650000
Epoch 319, CIFAR-10 Batch 1:  loss: 0.841726
accuracy: 0.725000
Epoch 319, CIFAR-10 Batch 2:  loss: 0.797322
accuracy: 0.775000
Epoch 319, CIFAR-10 Batch 3:  loss: 0.894229
accuracy: 0.725000
Epoch 319, CIFAR-10 Batch 4:  loss: 1.227503
accuracy: 0.550000
Epoch 319, CIFAR-10 Batch 5:  loss: 1.118636
accuracy: 0.625000
Epoch 320, CIFAR-10 Batch 1:  loss: 0.823941
accuracy: 0.775000
Epoch 320, CIFAR-10 Batch 2:  loss: 0.783111
accuracy: 0.750000
Epoch 320, CIFAR-10 Batch 3:  loss: 0.894926
accuracy: 0.750000
Epoch 320, CIFAR-10 Batch 4:  loss: 1.201661
accuracy: 0.550000
Epoch 320, CIFAR-10 Batch 5:  loss: 1.079060
accuracy: 0.650000
Epoch 321, CIFAR-10 Batch 1:  loss: 0.831186
accuracy: 0.750000
Epoch 321, CIFAR-10 Batch 2:  loss: 0.789435
accuracy: 0.775000
Epoch 321, CIFAR-10 Batch 3:  loss: 0.887489
accuracy: 0.725000
Epoch 321, CIFAR-10 Batch 4:  loss: 1.159578
accuracy: 0.550000
Epoch 321, CIFAR-10 Batch 5:  loss: 1.087820
accuracy: 0.650000
Epoch 322, CIFAR-10 Batch 1:  loss: 0.817234
accuracy: 0.775000
Epoch 322, CIFAR-10 Batch 2:  loss: 0.795385
accuracy: 0.775000
Epoch 322, CIFAR-10 Batch 3:  loss: 0.891188
accuracy: 0.725000
Epoch 322, CIFAR-10 Batch 4:  loss: 1.192060
accuracy: 0.575000
Epoch 322, CIFAR-10 Batch 5:  loss: 1.120344
accuracy: 0.625000
Epoch 323, CIFAR-10 Batch 1:  loss: 0.818044
accuracy: 0.725000
Epoch 323, CIFAR-10 Batch 2:  loss: 0.809524
accuracy: 0.750000
Epoch 323, CIFAR-10 Batch 3:  loss: 0.880065
accuracy: 0.800000
Epoch 323, CIFAR-10 Batch 4:  loss: 1.199733
accuracy: 0.525000
Epoch 323, CIFAR-10 Batch 5:  loss: 1.127747
accuracy: 0.650000
Epoch 324, CIFAR-10 Batch 1:  loss: 0.858570
accuracy: 0.700000
Epoch 324, CIFAR-10 Batch 2:  loss: 0.819052
accuracy: 0.775000
Epoch 324, CIFAR-10 Batch 3:  loss: 0.845471
accuracy: 0.725000
Epoch 324, CIFAR-10 Batch 4:  loss: 1.222817
accuracy: 0.550000
Epoch 324, CIFAR-10 Batch 5:  loss: 1.174804
accuracy: 0.575000
Epoch 325, CIFAR-10 Batch 1:  loss: 0.845649
accuracy: 0.775000
Epoch 325, CIFAR-10 Batch 2:  loss: 0.811163
accuracy: 0.800000
Epoch 325, CIFAR-10 Batch 3:  loss: 0.903106
accuracy: 0.750000
Epoch 325, CIFAR-10 Batch 4:  loss: 1.190687
accuracy: 0.525000
Epoch 325, CIFAR-10 Batch 5:  loss: 1.097725
accuracy: 0.650000
Epoch 326, CIFAR-10 Batch 1:  loss: 0.849526
accuracy: 0.725000
Epoch 326, CIFAR-10 Batch 2:  loss: 0.784319
accuracy: 0.775000
Epoch 326, CIFAR-10 Batch 3:  loss: 0.890471
accuracy: 0.750000
Epoch 326, CIFAR-10 Batch 4:  loss: 1.232843
accuracy: 0.550000
Epoch 326, CIFAR-10 Batch 5:  loss: 1.116404
accuracy: 0.575000
Epoch 327, CIFAR-10 Batch 1:  loss: 0.808674
accuracy: 0.725000
Epoch 327, CIFAR-10 Batch 2:  loss: 0.774246
accuracy: 0.775000
Epoch 327, CIFAR-10 Batch 3:  loss: 0.897960
accuracy: 0.725000
Epoch 327, CIFAR-10 Batch 4:  loss: 1.230557
accuracy: 0.525000
Epoch 327, CIFAR-10 Batch 5:  loss: 1.096094
accuracy: 0.675000
Epoch 328, CIFAR-10 Batch 1:  loss: 0.778671
accuracy: 0.775000
Epoch 328, CIFAR-10 Batch 2:  loss: 0.777468
accuracy: 0.750000
Epoch 328, CIFAR-10 Batch 3:  loss: 0.865326
accuracy: 0.825000
Epoch 328, CIFAR-10 Batch 4:  loss: 1.203115
accuracy: 0.550000
Epoch 328, CIFAR-10 Batch 5:  loss: 1.065104
accuracy: 0.650000
Epoch 329, CIFAR-10 Batch 1:  loss: 0.786190
accuracy: 0.800000
Epoch 329, CIFAR-10 Batch 2:  loss: 0.779724
accuracy: 0.775000
Epoch 329, CIFAR-10 Batch 3:  loss: 0.851638
accuracy: 0.725000
Epoch 329, CIFAR-10 Batch 4:  loss: 1.253279
accuracy: 0.525000
Epoch 329, CIFAR-10 Batch 5:  loss: 1.110788
accuracy: 0.625000
Epoch 330, CIFAR-10 Batch 1:  loss: 0.802076
accuracy: 0.750000
Epoch 330, CIFAR-10 Batch 2:  loss: 0.790350
accuracy: 0.800000
Epoch 330, CIFAR-10 Batch 3:  loss: 0.940510
accuracy: 0.750000
Epoch 330, CIFAR-10 Batch 4:  loss: 1.241900
accuracy: 0.525000
Epoch 330, CIFAR-10 Batch 5:  loss: 1.082443
accuracy: 0.625000
Epoch 331, CIFAR-10 Batch 1:  loss: 0.830113
accuracy: 0.775000
Epoch 331, CIFAR-10 Batch 2:  loss: 0.780261
accuracy: 0.800000
Epoch 331, CIFAR-10 Batch 3:  loss: 0.897569
accuracy: 0.775000
Epoch 331, CIFAR-10 Batch 4:  loss: 1.194305
accuracy: 0.575000
Epoch 331, CIFAR-10 Batch 5:  loss: 1.093257
accuracy: 0.650000
Epoch 332, CIFAR-10 Batch 1:  loss: 0.832837
accuracy: 0.750000
Epoch 332, CIFAR-10 Batch 2:  loss: 0.803433
accuracy: 0.775000
Epoch 332, CIFAR-10 Batch 3:  loss: 0.902435
accuracy: 0.700000
Epoch 332, CIFAR-10 Batch 4:  loss: 1.239951
accuracy: 0.550000
Epoch 332, CIFAR-10 Batch 5:  loss: 1.093261
accuracy: 0.675000
Epoch 333, CIFAR-10 Batch 1:  loss: 0.824554
accuracy: 0.750000
Epoch 333, CIFAR-10 Batch 2:  loss: 0.786929
accuracy: 0.800000
Epoch 333, CIFAR-10 Batch 3:  loss: 0.884337
accuracy: 0.750000
Epoch 333, CIFAR-10 Batch 4:  loss: 1.249722
accuracy: 0.525000
Epoch 333, CIFAR-10 Batch 5:  loss: 1.138252
accuracy: 0.675000
Epoch 334, CIFAR-10 Batch 1:  loss: 0.799677
accuracy: 0.750000
Epoch 334, CIFAR-10 Batch 2:  loss: 0.776243
accuracy: 0.825000
Epoch 334, CIFAR-10 Batch 3:  loss: 0.935012
accuracy: 0.700000
Epoch 334, CIFAR-10 Batch 4:  loss: 1.208688
accuracy: 0.575000
Epoch 334, CIFAR-10 Batch 5:  loss: 1.114705
accuracy: 0.625000
Epoch 335, CIFAR-10 Batch 1:  loss: 0.797178
accuracy: 0.775000
Epoch 335, CIFAR-10 Batch 2:  loss: 0.778116
accuracy: 0.800000
Epoch 335, CIFAR-10 Batch 3:  loss: 0.901160
accuracy: 0.700000
Epoch 335, CIFAR-10 Batch 4:  loss: 1.210552
accuracy: 0.550000
Epoch 335, CIFAR-10 Batch 5:  loss: 1.134739
accuracy: 0.625000
Epoch 336, CIFAR-10 Batch 1:  loss: 0.791926
accuracy: 0.775000
Epoch 336, CIFAR-10 Batch 2:  loss: 0.795357
accuracy: 0.775000
Epoch 336, CIFAR-10 Batch 3:  loss: 0.895005
accuracy: 0.700000
Epoch 336, CIFAR-10 Batch 4:  loss: 1.209844
accuracy: 0.550000
Epoch 336, CIFAR-10 Batch 5:  loss: 1.109457
accuracy: 0.625000
Epoch 337, CIFAR-10 Batch 1:  loss: 0.819006
accuracy: 0.750000
Epoch 337, CIFAR-10 Batch 2:  loss: 0.789936
accuracy: 0.800000
Epoch 337, CIFAR-10 Batch 3:  loss: 0.891653
accuracy: 0.725000
Epoch 337, CIFAR-10 Batch 4:  loss: 1.253394
accuracy: 0.500000
Epoch 337, CIFAR-10 Batch 5:  loss: 1.088999
accuracy: 0.625000
Epoch 338, CIFAR-10 Batch 1:  loss: 0.827583
accuracy: 0.750000
Epoch 338, CIFAR-10 Batch 2:  loss: 0.776707
accuracy: 0.825000
Epoch 338, CIFAR-10 Batch 3:  loss: 0.878371
accuracy: 0.775000
Epoch 338, CIFAR-10 Batch 4:  loss: 1.203966
accuracy: 0.550000
Epoch 338, CIFAR-10 Batch 5:  loss: 1.130172
accuracy: 0.625000
Epoch 339, CIFAR-10 Batch 1:  loss: 0.811520
accuracy: 0.800000
Epoch 339, CIFAR-10 Batch 2:  loss: 0.787330
accuracy: 0.775000
Epoch 339, CIFAR-10 Batch 3:  loss: 0.913591
accuracy: 0.700000
Epoch 339, CIFAR-10 Batch 4:  loss: 1.227166
accuracy: 0.575000
Epoch 339, CIFAR-10 Batch 5:  loss: 1.146162
accuracy: 0.625000
Epoch 340, CIFAR-10 Batch 1:  loss: 0.805243
accuracy: 0.775000
Epoch 340, CIFAR-10 Batch 2:  loss: 0.815760
accuracy: 0.775000
Epoch 340, CIFAR-10 Batch 3:  loss: 0.931966
accuracy: 0.675000
Epoch 340, CIFAR-10 Batch 4:  loss: 1.906383
accuracy: 0.525000
Epoch 340, CIFAR-10 Batch 5:  loss: 1.138102
accuracy: 0.575000
Epoch 341, CIFAR-10 Batch 1:  loss: 0.801992
accuracy: 0.775000
Epoch 341, CIFAR-10 Batch 2:  loss: 0.770697
accuracy: 0.800000
Epoch 341, CIFAR-10 Batch 3:  loss: 0.913232
accuracy: 0.650000
Epoch 341, CIFAR-10 Batch 4:  loss: 1.170571
accuracy: 0.575000
Epoch 341, CIFAR-10 Batch 5:  loss: 1.093297
accuracy: 0.650000
Epoch 342, CIFAR-10 Batch 1:  loss: 0.825449
accuracy: 0.775000
Epoch 342, CIFAR-10 Batch 2:  loss: 0.791907
accuracy: 0.800000
Epoch 342, CIFAR-10 Batch 3:  loss: 0.925430
accuracy: 0.625000
Epoch 342, CIFAR-10 Batch 4:  loss: 1.194941
accuracy: 0.550000
Epoch 342, CIFAR-10 Batch 5:  loss: 1.140396
accuracy: 0.600000
Epoch 343, CIFAR-10 Batch 1:  loss: 0.828723
accuracy: 0.800000
Epoch 343, CIFAR-10 Batch 2:  loss: 0.788673
accuracy: 0.800000
Epoch 343, CIFAR-10 Batch 3:  loss: 0.893676
accuracy: 0.750000
Epoch 343, CIFAR-10 Batch 4:  loss: 1.204186
accuracy: 0.525000
Epoch 343, CIFAR-10 Batch 5:  loss: 1.082209
accuracy: 0.650000
Epoch 344, CIFAR-10 Batch 1:  loss: 0.805062
accuracy: 0.800000
Epoch 344, CIFAR-10 Batch 2:  loss: 0.783328
accuracy: 0.800000
Epoch 344, CIFAR-10 Batch 3:  loss: 0.870527
accuracy: 0.725000
Epoch 344, CIFAR-10 Batch 4:  loss: 1.213906
accuracy: 0.475000
Epoch 344, CIFAR-10 Batch 5:  loss: 1.071915
accuracy: 0.625000
Epoch 345, CIFAR-10 Batch 1:  loss: 0.809326
accuracy: 0.775000
Epoch 345, CIFAR-10 Batch 2:  loss: 0.779470
accuracy: 0.775000
Epoch 345, CIFAR-10 Batch 3:  loss: 0.896220
accuracy: 0.725000
Epoch 345, CIFAR-10 Batch 4:  loss: 1.212796
accuracy: 0.525000
Epoch 345, CIFAR-10 Batch 5:  loss: 1.148657
accuracy: 0.625000
Epoch 346, CIFAR-10 Batch 1:  loss: 1.068598
accuracy: 0.775000
Epoch 346, CIFAR-10 Batch 2:  loss: 0.803438
accuracy: 0.775000
Epoch 346, CIFAR-10 Batch 3:  loss: 0.898229
accuracy: 0.700000
Epoch 346, CIFAR-10 Batch 4:  loss: 1.232024
accuracy: 0.500000
Epoch 346, CIFAR-10 Batch 5:  loss: 1.090076
accuracy: 0.650000
Epoch 347, CIFAR-10 Batch 1:  loss: 0.768060
accuracy: 0.800000
Epoch 347, CIFAR-10 Batch 2:  loss: 0.779419
accuracy: 0.775000
Epoch 347, CIFAR-10 Batch 3:  loss: 0.930212
accuracy: 0.675000
Epoch 347, CIFAR-10 Batch 4:  loss: 1.225521
accuracy: 0.475000
Epoch 347, CIFAR-10 Batch 5:  loss: 1.083796
accuracy: 0.625000
Epoch 348, CIFAR-10 Batch 1:  loss: 0.799612
accuracy: 0.800000
Epoch 348, CIFAR-10 Batch 2:  loss: 0.779931
accuracy: 0.775000
Epoch 348, CIFAR-10 Batch 3:  loss: 0.874170
accuracy: 0.725000
Epoch 348, CIFAR-10 Batch 4:  loss: 1.217064
accuracy: 0.550000
Epoch 348, CIFAR-10 Batch 5:  loss: 1.105531
accuracy: 0.600000
Epoch 349, CIFAR-10 Batch 1:  loss: 0.788621
accuracy: 0.800000
Epoch 349, CIFAR-10 Batch 2:  loss: 0.766260
accuracy: 0.775000
Epoch 349, CIFAR-10 Batch 3:  loss: 0.912234
accuracy: 0.700000
Epoch 349, CIFAR-10 Batch 4:  loss: 1.244460
accuracy: 0.525000
Epoch 349, CIFAR-10 Batch 5:  loss: 1.100305
accuracy: 0.600000
Epoch 350, CIFAR-10 Batch 1:  loss: 0.783747
accuracy: 0.775000
Epoch 350, CIFAR-10 Batch 2:  loss: 0.789526
accuracy: 0.775000
Epoch 350, CIFAR-10 Batch 3:  loss: 0.880060
accuracy: 0.750000
Epoch 350, CIFAR-10 Batch 4:  loss: 1.229373
accuracy: 0.500000
Epoch 350, CIFAR-10 Batch 5:  loss: 1.095486
accuracy: 0.575000
Epoch 351, CIFAR-10 Batch 1:  loss: 0.804744
accuracy: 0.775000
Epoch 351, CIFAR-10 Batch 2:  loss: 0.803250
accuracy: 0.750000
Epoch 351, CIFAR-10 Batch 3:  loss: 0.878047
accuracy: 0.700000
Epoch 351, CIFAR-10 Batch 4:  loss: 1.232480
accuracy: 0.450000
Epoch 351, CIFAR-10 Batch 5:  loss: 1.058912
accuracy: 0.625000
Epoch 352, CIFAR-10 Batch 1:  loss: 0.785544
accuracy: 0.800000
Epoch 352, CIFAR-10 Batch 2:  loss: 0.787417
accuracy: 0.750000
Epoch 352, CIFAR-10 Batch 3:  loss: 0.871515
accuracy: 0.725000
Epoch 352, CIFAR-10 Batch 4:  loss: 1.257139
accuracy: 0.500000
Epoch 352, CIFAR-10 Batch 5:  loss: 1.120125
accuracy: 0.625000
Epoch 353, CIFAR-10 Batch 1:  loss: 0.794865
accuracy: 0.775000
Epoch 353, CIFAR-10 Batch 2:  loss: 0.797388
accuracy: 0.750000
Epoch 353, CIFAR-10 Batch 3:  loss: 0.891898
accuracy: 0.750000
Epoch 353, CIFAR-10 Batch 4:  loss: 1.276847
accuracy: 0.475000
Epoch 353, CIFAR-10 Batch 5:  loss: 1.071603
accuracy: 0.625000
Epoch 354, CIFAR-10 Batch 1:  loss: 0.823344
accuracy: 0.750000
Epoch 354, CIFAR-10 Batch 2:  loss: 0.779082
accuracy: 0.800000
Epoch 354, CIFAR-10 Batch 3:  loss: 0.912876
accuracy: 0.725000
Epoch 354, CIFAR-10 Batch 4:  loss: 1.272126
accuracy: 0.450000
Epoch 354, CIFAR-10 Batch 5:  loss: 1.072512
accuracy: 0.650000
Epoch 355, CIFAR-10 Batch 1:  loss: 0.842275
accuracy: 0.775000
Epoch 355, CIFAR-10 Batch 2:  loss: 0.771227
accuracy: 0.775000
Epoch 355, CIFAR-10 Batch 3:  loss: 0.925095
accuracy: 0.675000
Epoch 355, CIFAR-10 Batch 4:  loss: 1.224038
accuracy: 0.500000
Epoch 355, CIFAR-10 Batch 5:  loss: 1.061366
accuracy: 0.650000
Epoch 356, CIFAR-10 Batch 1:  loss: 0.845243
accuracy: 0.800000
Epoch 356, CIFAR-10 Batch 2:  loss: 0.791049
accuracy: 0.775000
Epoch 356, CIFAR-10 Batch 3:  loss: 0.897898
accuracy: 0.775000
Epoch 356, CIFAR-10 Batch 4:  loss: 1.211389
accuracy: 0.525000
Epoch 356, CIFAR-10 Batch 5:  loss: 1.074266
accuracy: 0.625000
Epoch 357, CIFAR-10 Batch 1:  loss: 0.816017
accuracy: 0.750000
Epoch 357, CIFAR-10 Batch 2:  loss: 0.806834
accuracy: 0.750000
Epoch 357, CIFAR-10 Batch 3:  loss: 0.875087
accuracy: 0.725000
Epoch 357, CIFAR-10 Batch 4:  loss: 1.205348
accuracy: 0.525000
Epoch 357, CIFAR-10 Batch 5:  loss: 1.081122
accuracy: 0.625000
Epoch 358, CIFAR-10 Batch 1:  loss: 0.804061
accuracy: 0.775000
Epoch 358, CIFAR-10 Batch 2:  loss: 0.745767
accuracy: 0.800000
Epoch 358, CIFAR-10 Batch 3:  loss: 0.913984
accuracy: 0.700000
Epoch 358, CIFAR-10 Batch 4:  loss: 1.208225
accuracy: 0.525000
Epoch 358, CIFAR-10 Batch 5:  loss: 1.107966
accuracy: 0.625000
Epoch 359, CIFAR-10 Batch 1:  loss: 0.842326
accuracy: 0.775000
Epoch 359, CIFAR-10 Batch 2:  loss: 0.832969
accuracy: 0.775000
Epoch 359, CIFAR-10 Batch 3:  loss: 1.180292
accuracy: 0.725000
Epoch 359, CIFAR-10 Batch 4:  loss: 2.081995
accuracy: 0.525000
Epoch 359, CIFAR-10 Batch 5:  loss: 1.130101
accuracy: 0.575000
Epoch 360, CIFAR-10 Batch 1:  loss: 0.794896
accuracy: 0.775000
Epoch 360, CIFAR-10 Batch 2:  loss: 0.824236
accuracy: 0.750000
Epoch 360, CIFAR-10 Batch 3:  loss: 1.174263
accuracy: 0.725000
Epoch 360, CIFAR-10 Batch 4:  loss: 1.289079
accuracy: 0.500000
Epoch 360, CIFAR-10 Batch 5:  loss: 1.090272
accuracy: 0.625000
Epoch 361, CIFAR-10 Batch 1:  loss: 0.810131
accuracy: 0.750000
Epoch 361, CIFAR-10 Batch 2:  loss: 0.816666
accuracy: 0.775000
Epoch 361, CIFAR-10 Batch 3:  loss: 1.086937
accuracy: 0.725000
Epoch 361, CIFAR-10 Batch 4:  loss: 1.230441
accuracy: 0.500000
Epoch 361, CIFAR-10 Batch 5:  loss: 1.121844
accuracy: 0.600000
Epoch 362, CIFAR-10 Batch 1:  loss: 0.812142
accuracy: 0.775000
Epoch 362, CIFAR-10 Batch 2:  loss: 0.813576
accuracy: 0.775000
Epoch 362, CIFAR-10 Batch 3:  loss: 1.026275
accuracy: 0.700000
Epoch 362, CIFAR-10 Batch 4:  loss: 1.201598
accuracy: 0.550000
Epoch 362, CIFAR-10 Batch 5:  loss: 1.079108
accuracy: 0.650000
Epoch 363, CIFAR-10 Batch 1:  loss: 0.852450
accuracy: 0.700000
Epoch 363, CIFAR-10 Batch 2:  loss: 0.775738
accuracy: 0.800000
Epoch 363, CIFAR-10 Batch 3:  loss: 0.868354
accuracy: 0.675000
Epoch 363, CIFAR-10 Batch 4:  loss: 1.214621
accuracy: 0.550000
Epoch 363, CIFAR-10 Batch 5:  loss: 1.139229
accuracy: 0.600000
Epoch 364, CIFAR-10 Batch 1:  loss: 0.804851
accuracy: 0.775000
Epoch 364, CIFAR-10 Batch 2:  loss: 0.777133
accuracy: 0.800000
Epoch 364, CIFAR-10 Batch 3:  loss: 0.907235
accuracy: 0.700000
Epoch 364, CIFAR-10 Batch 4:  loss: 1.218180
accuracy: 0.525000
Epoch 364, CIFAR-10 Batch 5:  loss: 1.077608
accuracy: 0.625000
Epoch 365, CIFAR-10 Batch 1:  loss: 0.846033
accuracy: 0.725000
Epoch 365, CIFAR-10 Batch 2:  loss: 0.782972
accuracy: 0.800000
Epoch 365, CIFAR-10 Batch 3:  loss: 0.869471
accuracy: 0.750000
Epoch 365, CIFAR-10 Batch 4:  loss: 1.199414
accuracy: 0.550000
Epoch 365, CIFAR-10 Batch 5:  loss: 1.051618
accuracy: 0.625000
Epoch 366, CIFAR-10 Batch 1:  loss: 0.840749
accuracy: 0.725000
Epoch 366, CIFAR-10 Batch 2:  loss: 0.772846
accuracy: 0.775000
Epoch 366, CIFAR-10 Batch 3:  loss: 0.895089
accuracy: 0.725000
Epoch 366, CIFAR-10 Batch 4:  loss: 1.209674
accuracy: 0.575000
Epoch 366, CIFAR-10 Batch 5:  loss: 1.042692
accuracy: 0.650000
Epoch 367, CIFAR-10 Batch 1:  loss: 0.853994
accuracy: 0.750000
Epoch 367, CIFAR-10 Batch 2:  loss: 0.788449
accuracy: 0.750000
Epoch 367, CIFAR-10 Batch 3:  loss: 0.900526
accuracy: 0.700000
Epoch 367, CIFAR-10 Batch 4:  loss: 1.217645
accuracy: 0.500000
Epoch 367, CIFAR-10 Batch 5:  loss: 1.040768
accuracy: 0.650000
Epoch 368, CIFAR-10 Batch 1:  loss: 0.879405
accuracy: 0.725000
Epoch 368, CIFAR-10 Batch 2:  loss: 0.811748
accuracy: 0.775000
Epoch 368, CIFAR-10 Batch 3:  loss: 0.943722
accuracy: 0.650000
Epoch 368, CIFAR-10 Batch 4:  loss: 1.233012
accuracy: 0.475000
Epoch 368, CIFAR-10 Batch 5:  loss: 1.071273
accuracy: 0.600000
Epoch 369, CIFAR-10 Batch 1:  loss: 0.846036
accuracy: 0.750000
Epoch 369, CIFAR-10 Batch 2:  loss: 0.824238
accuracy: 0.725000
Epoch 369, CIFAR-10 Batch 3:  loss: 0.960822
accuracy: 0.625000
Epoch 369, CIFAR-10 Batch 4:  loss: 1.176650
accuracy: 0.550000
Epoch 369, CIFAR-10 Batch 5:  loss: 1.089184
accuracy: 0.625000
Epoch 370, CIFAR-10 Batch 1:  loss: 0.827476
accuracy: 0.750000
Epoch 370, CIFAR-10 Batch 2:  loss: 0.825576
accuracy: 0.725000
Epoch 370, CIFAR-10 Batch 3:  loss: 0.902892
accuracy: 0.700000
Epoch 370, CIFAR-10 Batch 4:  loss: 1.186663
accuracy: 0.525000
Epoch 370, CIFAR-10 Batch 5:  loss: 1.071015
accuracy: 0.650000
Epoch 371, CIFAR-10 Batch 1:  loss: 0.859797
accuracy: 0.725000
Epoch 371, CIFAR-10 Batch 2:  loss: 0.799880
accuracy: 0.775000
Epoch 371, CIFAR-10 Batch 3:  loss: 0.900317
accuracy: 0.750000
Epoch 371, CIFAR-10 Batch 4:  loss: 1.203830
accuracy: 0.500000
Epoch 371, CIFAR-10 Batch 5:  loss: 1.080306
accuracy: 0.650000
Epoch 372, CIFAR-10 Batch 1:  loss: 0.862319
accuracy: 0.750000
Epoch 372, CIFAR-10 Batch 2:  loss: 0.768155
accuracy: 0.800000
Epoch 372, CIFAR-10 Batch 3:  loss: 0.911883
accuracy: 0.775000
Epoch 372, CIFAR-10 Batch 4:  loss: 1.219272
accuracy: 0.525000
Epoch 372, CIFAR-10 Batch 5:  loss: 1.076345
accuracy: 0.625000
Epoch 373, CIFAR-10 Batch 1:  loss: 0.847808
accuracy: 0.725000
Epoch 373, CIFAR-10 Batch 2:  loss: 0.773306
accuracy: 0.775000
Epoch 373, CIFAR-10 Batch 3:  loss: 0.886588
accuracy: 0.750000
Epoch 373, CIFAR-10 Batch 4:  loss: 1.220993
accuracy: 0.500000
Epoch 373, CIFAR-10 Batch 5:  loss: 1.063309
accuracy: 0.650000
Epoch 374, CIFAR-10 Batch 1:  loss: 0.879095
accuracy: 0.725000
Epoch 374, CIFAR-10 Batch 2:  loss: 0.829592
accuracy: 0.775000
Epoch 374, CIFAR-10 Batch 3:  loss: 0.883674
accuracy: 0.800000
Epoch 374, CIFAR-10 Batch 4:  loss: 1.235210
accuracy: 0.525000
Epoch 374, CIFAR-10 Batch 5:  loss: 1.072630
accuracy: 0.650000
Epoch 375, CIFAR-10 Batch 1:  loss: 0.846635
accuracy: 0.725000
Epoch 375, CIFAR-10 Batch 2:  loss: 0.832524
accuracy: 0.750000
Epoch 375, CIFAR-10 Batch 3:  loss: 0.911063
accuracy: 0.800000
Epoch 375, CIFAR-10 Batch 4:  loss: 1.239947
accuracy: 0.525000
Epoch 375, CIFAR-10 Batch 5:  loss: 1.056841
accuracy: 0.675000
Epoch 376, CIFAR-10 Batch 1:  loss: 0.878455
accuracy: 0.750000
Epoch 376, CIFAR-10 Batch 2:  loss: 0.780204
accuracy: 0.775000
Epoch 376, CIFAR-10 Batch 3:  loss: 0.894275
accuracy: 0.800000
Epoch 376, CIFAR-10 Batch 4:  loss: 1.198517
accuracy: 0.525000
Epoch 376, CIFAR-10 Batch 5:  loss: 1.044504
accuracy: 0.650000
Epoch 377, CIFAR-10 Batch 1:  loss: 0.833544
accuracy: 0.775000
Epoch 377, CIFAR-10 Batch 2:  loss: 0.788338
accuracy: 0.775000
Epoch 377, CIFAR-10 Batch 3:  loss: 0.915169
accuracy: 0.800000
Epoch 377, CIFAR-10 Batch 4:  loss: 1.259675
accuracy: 0.475000
Epoch 377, CIFAR-10 Batch 5:  loss: 1.051246
accuracy: 0.675000
Epoch 378, CIFAR-10 Batch 1:  loss: 0.858996
accuracy: 0.725000
Epoch 378, CIFAR-10 Batch 2:  loss: 0.767470
accuracy: 0.775000
Epoch 378, CIFAR-10 Batch 3:  loss: 0.936656
accuracy: 0.700000
Epoch 378, CIFAR-10 Batch 4:  loss: 1.237160
accuracy: 0.500000
Epoch 378, CIFAR-10 Batch 5:  loss: 1.048681
accuracy: 0.650000
Epoch 379, CIFAR-10 Batch 1:  loss: 0.847447
accuracy: 0.725000
Epoch 379, CIFAR-10 Batch 2:  loss: 0.809405
accuracy: 0.775000
Epoch 379, CIFAR-10 Batch 3:  loss: 0.943968
accuracy: 0.675000
Epoch 379, CIFAR-10 Batch 4:  loss: 1.231766
accuracy: 0.475000
Epoch 379, CIFAR-10 Batch 5:  loss: 1.058952
accuracy: 0.675000
Epoch 380, CIFAR-10 Batch 1:  loss: 0.842807
accuracy: 0.750000
Epoch 380, CIFAR-10 Batch 2:  loss: 0.760824
accuracy: 0.750000
Epoch 380, CIFAR-10 Batch 3:  loss: 0.928331
accuracy: 0.650000
Epoch 380, CIFAR-10 Batch 4:  loss: 1.227912
accuracy: 0.500000
Epoch 380, CIFAR-10 Batch 5:  loss: 1.033359
accuracy: 0.650000
Epoch 381, CIFAR-10 Batch 1:  loss: 0.848322
accuracy: 0.750000
Epoch 381, CIFAR-10 Batch 2:  loss: 0.780980
accuracy: 0.800000
Epoch 381, CIFAR-10 Batch 3:  loss: 0.913502
accuracy: 0.750000
Epoch 381, CIFAR-10 Batch 4:  loss: 1.232688
accuracy: 0.500000
Epoch 381, CIFAR-10 Batch 5:  loss: 1.045603
accuracy: 0.650000
Epoch 382, CIFAR-10 Batch 1:  loss: 0.822636
accuracy: 0.750000
Epoch 382, CIFAR-10 Batch 2:  loss: 0.811832
accuracy: 0.750000
Epoch 382, CIFAR-10 Batch 3:  loss: 0.890459
accuracy: 0.775000
Epoch 382, CIFAR-10 Batch 4:  loss: 1.235826
accuracy: 0.500000
Epoch 382, CIFAR-10 Batch 5:  loss: 1.069176
accuracy: 0.625000
Epoch 383, CIFAR-10 Batch 1:  loss: 0.840592
accuracy: 0.750000
Epoch 383, CIFAR-10 Batch 2:  loss: 0.780930
accuracy: 0.750000
Epoch 383, CIFAR-10 Batch 3:  loss: 0.907964
accuracy: 0.675000
Epoch 383, CIFAR-10 Batch 4:  loss: 1.229465
accuracy: 0.525000
Epoch 383, CIFAR-10 Batch 5:  loss: 1.048363
accuracy: 0.650000
Epoch 384, CIFAR-10 Batch 1:  loss: 0.843110
accuracy: 0.750000
Epoch 384, CIFAR-10 Batch 2:  loss: 0.769006
accuracy: 0.800000
Epoch 384, CIFAR-10 Batch 3:  loss: 0.918000
accuracy: 0.700000
Epoch 384, CIFAR-10 Batch 4:  loss: 1.213154
accuracy: 0.500000
Epoch 384, CIFAR-10 Batch 5:  loss: 1.058760
accuracy: 0.650000
Epoch 385, CIFAR-10 Batch 1:  loss: 0.853296
accuracy: 0.750000
Epoch 385, CIFAR-10 Batch 2:  loss: 0.803978
accuracy: 0.775000
Epoch 385, CIFAR-10 Batch 3:  loss: 0.894402
accuracy: 0.800000
Epoch 385, CIFAR-10 Batch 4:  loss: 1.232948
accuracy: 0.500000
Epoch 385, CIFAR-10 Batch 5:  loss: 1.086880
accuracy: 0.625000
Epoch 386, CIFAR-10 Batch 1:  loss: 0.869823
accuracy: 0.700000
Epoch 386, CIFAR-10 Batch 2:  loss: 0.825012
accuracy: 0.750000
Epoch 386, CIFAR-10 Batch 3:  loss: 0.940707
accuracy: 0.700000
Epoch 386, CIFAR-10 Batch 4:  loss: 1.192165
accuracy: 0.525000
Epoch 386, CIFAR-10 Batch 5:  loss: 1.064430
accuracy: 0.650000
Epoch 387, CIFAR-10 Batch 1:  loss: 0.815420
accuracy: 0.750000
Epoch 387, CIFAR-10 Batch 2:  loss: 0.761643
accuracy: 0.775000
Epoch 387, CIFAR-10 Batch 3:  loss: 0.902617
accuracy: 0.725000
Epoch 387, CIFAR-10 Batch 4:  loss: 1.262178
accuracy: 0.475000
Epoch 387, CIFAR-10 Batch 5:  loss: 1.035932
accuracy: 0.675000
Epoch 388, CIFAR-10 Batch 1:  loss: 0.845251
accuracy: 0.725000
Epoch 388, CIFAR-10 Batch 2:  loss: 0.785437
accuracy: 0.750000
Epoch 388, CIFAR-10 Batch 3:  loss: 0.899664
accuracy: 0.775000
Epoch 388, CIFAR-10 Batch 4:  loss: 1.226299
accuracy: 0.500000
Epoch 388, CIFAR-10 Batch 5:  loss: 1.033461
accuracy: 0.675000
Epoch 389, CIFAR-10 Batch 1:  loss: 0.821142
accuracy: 0.725000
Epoch 389, CIFAR-10 Batch 2:  loss: 0.790787
accuracy: 0.775000
Epoch 389, CIFAR-10 Batch 3:  loss: 0.896965
accuracy: 0.725000
Epoch 389, CIFAR-10 Batch 4:  loss: 1.248631
accuracy: 0.475000
Epoch 389, CIFAR-10 Batch 5:  loss: 1.098478
accuracy: 0.650000
Epoch 390, CIFAR-10 Batch 1:  loss: 0.827269
accuracy: 0.775000
Epoch 390, CIFAR-10 Batch 2:  loss: 0.780194
accuracy: 0.775000
Epoch 390, CIFAR-10 Batch 3:  loss: 0.936602
accuracy: 0.750000
Epoch 390, CIFAR-10 Batch 4:  loss: 1.217463
accuracy: 0.525000
Epoch 390, CIFAR-10 Batch 5:  loss: 1.046782
accuracy: 0.675000
Epoch 391, CIFAR-10 Batch 1:  loss: 0.824408
accuracy: 0.800000
Epoch 391, CIFAR-10 Batch 2:  loss: 0.841629
accuracy: 0.750000
Epoch 391, CIFAR-10 Batch 3:  loss: 0.927246
accuracy: 0.700000
Epoch 391, CIFAR-10 Batch 4:  loss: 1.206616
accuracy: 0.550000
Epoch 391, CIFAR-10 Batch 5:  loss: 1.066733
accuracy: 0.700000
Epoch 392, CIFAR-10 Batch 1:  loss: 0.868286
accuracy: 0.725000
Epoch 392, CIFAR-10 Batch 2:  loss: 0.756562
accuracy: 0.800000
Epoch 392, CIFAR-10 Batch 3:  loss: 0.872221
accuracy: 0.725000
Epoch 392, CIFAR-10 Batch 4:  loss: 1.240931
accuracy: 0.500000
Epoch 392, CIFAR-10 Batch 5:  loss: 1.027735
accuracy: 0.625000
Epoch 393, CIFAR-10 Batch 1:  loss: 0.843835
accuracy: 0.750000
Epoch 393, CIFAR-10 Batch 2:  loss: 0.792933
accuracy: 0.775000
Epoch 393, CIFAR-10 Batch 3:  loss: 0.922834
accuracy: 0.700000
Epoch 393, CIFAR-10 Batch 4:  loss: 1.244474
accuracy: 0.525000
Epoch 393, CIFAR-10 Batch 5:  loss: 1.026644
accuracy: 0.650000
Epoch 394, CIFAR-10 Batch 1:  loss: 0.851276
accuracy: 0.725000
Epoch 394, CIFAR-10 Batch 2:  loss: 0.777210
accuracy: 0.775000
Epoch 394, CIFAR-10 Batch 3:  loss: 0.918582
accuracy: 0.750000
Epoch 394, CIFAR-10 Batch 4:  loss: 1.229900
accuracy: 0.525000
Epoch 394, CIFAR-10 Batch 5:  loss: 1.074068
accuracy: 0.675000
Epoch 395, CIFAR-10 Batch 1:  loss: 0.840010
accuracy: 0.700000
Epoch 395, CIFAR-10 Batch 2:  loss: 0.783382
accuracy: 0.800000
Epoch 395, CIFAR-10 Batch 3:  loss: 0.940388
accuracy: 0.725000
Epoch 395, CIFAR-10 Batch 4:  loss: 1.242236
accuracy: 0.450000
Epoch 395, CIFAR-10 Batch 5:  loss: 1.026122
accuracy: 0.675000
Epoch 396, CIFAR-10 Batch 1:  loss: 0.829642
accuracy: 0.750000
Epoch 396, CIFAR-10 Batch 2:  loss: 0.782820
accuracy: 0.800000
Epoch 396, CIFAR-10 Batch 3:  loss: 0.912903
accuracy: 0.725000
Epoch 396, CIFAR-10 Batch 4:  loss: 1.247336
accuracy: 0.500000
Epoch 396, CIFAR-10 Batch 5:  loss: 1.025825
accuracy: 0.675000
Epoch 397, CIFAR-10 Batch 1:  loss: 0.834162
accuracy: 0.750000
Epoch 397, CIFAR-10 Batch 2:  loss: 0.789864
accuracy: 0.800000
Epoch 397, CIFAR-10 Batch 3:  loss: 0.915795
accuracy: 0.750000
Epoch 397, CIFAR-10 Batch 4:  loss: 1.214862
accuracy: 0.500000
Epoch 397, CIFAR-10 Batch 5:  loss: 1.071172
accuracy: 0.650000
Epoch 398, CIFAR-10 Batch 1:  loss: 0.818948
accuracy: 0.775000
Epoch 398, CIFAR-10 Batch 2:  loss: 0.812029
accuracy: 0.775000
Epoch 398, CIFAR-10 Batch 3:  loss: 0.906970
accuracy: 0.775000
Epoch 398, CIFAR-10 Batch 4:  loss: 1.210028
accuracy: 0.550000
Epoch 398, CIFAR-10 Batch 5:  loss: 1.029979
accuracy: 0.675000
Epoch 399, CIFAR-10 Batch 1:  loss: 1.806284
accuracy: 0.725000
Epoch 399, CIFAR-10 Batch 2:  loss: 0.794876
accuracy: 0.775000
Epoch 399, CIFAR-10 Batch 3:  loss: 0.915062
accuracy: 0.775000
Epoch 399, CIFAR-10 Batch 4:  loss: 1.261410
accuracy: 0.475000
Epoch 399, CIFAR-10 Batch 5:  loss: 1.033585
accuracy: 0.675000
Epoch 400, CIFAR-10 Batch 1:  loss: 0.857082
accuracy: 0.725000
Epoch 400, CIFAR-10 Batch 2:  loss: 0.785070
accuracy: 0.750000
Epoch 400, CIFAR-10 Batch 3:  loss: 0.926081
accuracy: 0.750000
Epoch 400, CIFAR-10 Batch 4:  loss: 1.230742
accuracy: 0.500000
Epoch 400, CIFAR-10 Batch 5:  loss: 1.028530
accuracy: 0.700000
Epoch 401, CIFAR-10 Batch 1:  loss: 0.834499
accuracy: 0.750000
Epoch 401, CIFAR-10 Batch 2:  loss: 0.811284
accuracy: 0.750000
Epoch 401, CIFAR-10 Batch 3:  loss: 0.902313
accuracy: 0.750000
Epoch 401, CIFAR-10 Batch 4:  loss: 1.257776
accuracy: 0.450000
Epoch 401, CIFAR-10 Batch 5:  loss: 1.028653
accuracy: 0.675000
Epoch 402, CIFAR-10 Batch 1:  loss: 0.855047
accuracy: 0.700000
Epoch 402, CIFAR-10 Batch 2:  loss: 0.738467
accuracy: 0.775000
Epoch 402, CIFAR-10 Batch 3:  loss: 0.913117
accuracy: 0.750000
Epoch 402, CIFAR-10 Batch 4:  loss: 1.252438
accuracy: 0.550000
Epoch 402, CIFAR-10 Batch 5:  loss: 1.037011
accuracy: 0.700000
Epoch 403, CIFAR-10 Batch 1:  loss: 0.875635
accuracy: 0.700000
Epoch 403, CIFAR-10 Batch 2:  loss: 0.797649
accuracy: 0.800000
Epoch 403, CIFAR-10 Batch 3:  loss: 0.898843
accuracy: 0.800000
Epoch 403, CIFAR-10 Batch 4:  loss: 1.258925
accuracy: 0.500000
Epoch 403, CIFAR-10 Batch 5:  loss: 1.044619
accuracy: 0.650000
Epoch 404, CIFAR-10 Batch 1:  loss: 0.879960
accuracy: 0.700000
Epoch 404, CIFAR-10 Batch 2:  loss: 0.826489
accuracy: 0.750000
Epoch 404, CIFAR-10 Batch 3:  loss: 0.929765
accuracy: 0.725000
Epoch 404, CIFAR-10 Batch 4:  loss: 1.257637
accuracy: 0.475000
Epoch 404, CIFAR-10 Batch 5:  loss: 1.040143
accuracy: 0.675000
Epoch 405, CIFAR-10 Batch 1:  loss: 0.852673
accuracy: 0.750000
Epoch 405, CIFAR-10 Batch 2:  loss: 0.840495
accuracy: 0.750000
Epoch 405, CIFAR-10 Batch 3:  loss: 0.915174
accuracy: 0.725000
Epoch 405, CIFAR-10 Batch 4:  loss: 1.250712
accuracy: 0.500000
Epoch 405, CIFAR-10 Batch 5:  loss: 1.092160
accuracy: 0.650000
Epoch 406, CIFAR-10 Batch 1:  loss: 0.840124
accuracy: 0.750000
Epoch 406, CIFAR-10 Batch 2:  loss: 0.804248
accuracy: 0.800000
Epoch 406, CIFAR-10 Batch 3:  loss: 0.911554
accuracy: 0.725000
Epoch 406, CIFAR-10 Batch 4:  loss: 1.246724
accuracy: 0.500000
Epoch 406, CIFAR-10 Batch 5:  loss: 1.055182
accuracy: 0.675000
Epoch 407, CIFAR-10 Batch 1:  loss: 0.854512
accuracy: 0.700000
Epoch 407, CIFAR-10 Batch 2:  loss: 0.790033
accuracy: 0.725000
Epoch 407, CIFAR-10 Batch 3:  loss: 0.881427
accuracy: 0.750000
Epoch 407, CIFAR-10 Batch 4:  loss: 1.209794
accuracy: 0.550000
Epoch 407, CIFAR-10 Batch 5:  loss: 1.016036
accuracy: 0.700000
Epoch 408, CIFAR-10 Batch 1:  loss: 0.845865
accuracy: 0.725000
Epoch 408, CIFAR-10 Batch 2:  loss: 0.773656
accuracy: 0.825000
Epoch 408, CIFAR-10 Batch 3:  loss: 0.884932
accuracy: 0.750000
Epoch 408, CIFAR-10 Batch 4:  loss: 1.233414
accuracy: 0.550000
Epoch 408, CIFAR-10 Batch 5:  loss: 1.048263
accuracy: 0.650000
Epoch 409, CIFAR-10 Batch 1:  loss: 0.825289
accuracy: 0.750000
Epoch 409, CIFAR-10 Batch 2:  loss: 0.760232
accuracy: 0.725000
Epoch 409, CIFAR-10 Batch 3:  loss: 0.922445
accuracy: 0.775000
Epoch 409, CIFAR-10 Batch 4:  loss: 1.223865
accuracy: 0.550000
Epoch 409, CIFAR-10 Batch 5:  loss: 1.042665
accuracy: 0.650000
Epoch 410, CIFAR-10 Batch 1:  loss: 0.851692
accuracy: 0.725000
Epoch 410, CIFAR-10 Batch 2:  loss: 0.746898
accuracy: 0.750000
Epoch 410, CIFAR-10 Batch 3:  loss: 0.916840
accuracy: 0.700000
Epoch 410, CIFAR-10 Batch 4:  loss: 1.255117
accuracy: 0.475000
Epoch 410, CIFAR-10 Batch 5:  loss: 1.009785
accuracy: 0.675000
Epoch 411, CIFAR-10 Batch 1:  loss: 0.846750
accuracy: 0.700000
Epoch 411, CIFAR-10 Batch 2:  loss: 0.778472
accuracy: 0.800000
Epoch 411, CIFAR-10 Batch 3:  loss: 0.912400
accuracy: 0.725000
Epoch 411, CIFAR-10 Batch 4:  loss: 1.216221
accuracy: 0.525000
Epoch 411, CIFAR-10 Batch 5:  loss: 1.021806
accuracy: 0.675000
Epoch 412, CIFAR-10 Batch 1:  loss: 0.831677
accuracy: 0.725000
Epoch 412, CIFAR-10 Batch 2:  loss: 0.784631
accuracy: 0.775000
Epoch 412, CIFAR-10 Batch 3:  loss: 0.891247
accuracy: 0.750000
Epoch 412, CIFAR-10 Batch 4:  loss: 1.206005
accuracy: 0.550000
Epoch 412, CIFAR-10 Batch 5:  loss: 1.001974
accuracy: 0.675000
Epoch 413, CIFAR-10 Batch 1:  loss: 0.816122
accuracy: 0.725000
Epoch 413, CIFAR-10 Batch 2:  loss: 0.808405
accuracy: 0.825000
Epoch 413, CIFAR-10 Batch 3:  loss: 0.891620
accuracy: 0.750000
Epoch 413, CIFAR-10 Batch 4:  loss: 1.220904
accuracy: 0.525000
Epoch 413, CIFAR-10 Batch 5:  loss: 1.017271
accuracy: 0.675000
Epoch 414, CIFAR-10 Batch 1:  loss: 0.843865
accuracy: 0.775000
Epoch 414, CIFAR-10 Batch 2:  loss: 0.810323
accuracy: 0.775000
Epoch 414, CIFAR-10 Batch 3:  loss: 0.940515
accuracy: 0.725000
Epoch 414, CIFAR-10 Batch 4:  loss: 1.235669
accuracy: 0.475000
Epoch 414, CIFAR-10 Batch 5:  loss: 1.041167
accuracy: 0.650000
Epoch 415, CIFAR-10 Batch 1:  loss: 0.840482
accuracy: 0.725000
Epoch 415, CIFAR-10 Batch 2:  loss: 0.796999
accuracy: 0.775000
Epoch 415, CIFAR-10 Batch 3:  loss: 0.922623
accuracy: 0.775000
Epoch 415, CIFAR-10 Batch 4:  loss: 1.247235
accuracy: 0.475000
Epoch 415, CIFAR-10 Batch 5:  loss: 1.022880
accuracy: 0.650000
Epoch 416, CIFAR-10 Batch 1:  loss: 0.843952
accuracy: 0.700000
Epoch 416, CIFAR-10 Batch 2:  loss: 0.836402
accuracy: 0.750000
Epoch 416, CIFAR-10 Batch 3:  loss: 0.908861
accuracy: 0.725000
Epoch 416, CIFAR-10 Batch 4:  loss: 1.257158
accuracy: 0.500000
Epoch 416, CIFAR-10 Batch 5:  loss: 1.037345
accuracy: 0.700000
Epoch 417, CIFAR-10 Batch 1:  loss: 0.848468
accuracy: 0.725000
Epoch 417, CIFAR-10 Batch 2:  loss: 0.805078
accuracy: 0.775000
Epoch 417, CIFAR-10 Batch 3:  loss: 0.918328
accuracy: 0.700000
Epoch 417, CIFAR-10 Batch 4:  loss: 1.231004
accuracy: 0.525000
Epoch 417, CIFAR-10 Batch 5:  loss: 1.005915
accuracy: 0.650000
Epoch 418, CIFAR-10 Batch 1:  loss: 0.836080
accuracy: 0.750000
Epoch 418, CIFAR-10 Batch 2:  loss: 0.793141
accuracy: 0.775000
Epoch 418, CIFAR-10 Batch 3:  loss: 0.939735
accuracy: 0.725000
Epoch 418, CIFAR-10 Batch 4:  loss: 1.221887
accuracy: 0.550000
Epoch 418, CIFAR-10 Batch 5:  loss: 1.027770
accuracy: 0.675000
Epoch 419, CIFAR-10 Batch 1:  loss: 0.810996
accuracy: 0.725000
Epoch 419, CIFAR-10 Batch 2:  loss: 0.780613
accuracy: 0.800000
Epoch 419, CIFAR-10 Batch 3:  loss: 0.893091
accuracy: 0.725000
Epoch 419, CIFAR-10 Batch 4:  loss: 1.239928
accuracy: 0.475000
Epoch 419, CIFAR-10 Batch 5:  loss: 1.021835
accuracy: 0.675000
Epoch 420, CIFAR-10 Batch 1:  loss: 0.816772
accuracy: 0.725000
Epoch 420, CIFAR-10 Batch 2:  loss: 0.768449
accuracy: 0.825000
Epoch 420, CIFAR-10 Batch 3:  loss: 0.899248
accuracy: 0.750000
Epoch 420, CIFAR-10 Batch 4:  loss: 1.221636
accuracy: 0.500000
Epoch 420, CIFAR-10 Batch 5:  loss: 1.032464
accuracy: 0.625000
Epoch 421, CIFAR-10 Batch 1:  loss: 0.849385
accuracy: 0.700000
Epoch 421, CIFAR-10 Batch 2:  loss: 0.797125
accuracy: 0.750000
Epoch 421, CIFAR-10 Batch 3:  loss: 0.901130
accuracy: 0.700000
Epoch 421, CIFAR-10 Batch 4:  loss: 1.250503
accuracy: 0.525000
Epoch 421, CIFAR-10 Batch 5:  loss: 1.012497
accuracy: 0.675000
Epoch 422, CIFAR-10 Batch 1:  loss: 0.828058
accuracy: 0.700000
Epoch 422, CIFAR-10 Batch 2:  loss: 0.811063
accuracy: 0.700000
Epoch 422, CIFAR-10 Batch 3:  loss: 0.902883
accuracy: 0.700000
Epoch 422, CIFAR-10 Batch 4:  loss: 1.243814
accuracy: 0.525000
Epoch 422, CIFAR-10 Batch 5:  loss: 1.081934
accuracy: 0.600000
Epoch 423, CIFAR-10 Batch 1:  loss: 0.843092
accuracy: 0.725000
Epoch 423, CIFAR-10 Batch 2:  loss: 0.831717
accuracy: 0.725000
Epoch 423, CIFAR-10 Batch 3:  loss: 0.900052
accuracy: 0.775000
Epoch 423, CIFAR-10 Batch 4:  loss: 1.214395
accuracy: 0.550000
Epoch 423, CIFAR-10 Batch 5:  loss: 1.016919
accuracy: 0.650000
Epoch 424, CIFAR-10 Batch 1:  loss: 0.834398
accuracy: 0.750000
Epoch 424, CIFAR-10 Batch 2:  loss: 0.783502
accuracy: 0.750000
Epoch 424, CIFAR-10 Batch 3:  loss: 0.937511
accuracy: 0.700000
Epoch 424, CIFAR-10 Batch 4:  loss: 1.269615
accuracy: 0.500000
Epoch 424, CIFAR-10 Batch 5:  loss: 1.026647
accuracy: 0.675000
Epoch 425, CIFAR-10 Batch 1:  loss: 0.812560
accuracy: 0.750000
Epoch 425, CIFAR-10 Batch 2:  loss: 0.801428
accuracy: 0.725000
Epoch 425, CIFAR-10 Batch 3:  loss: 0.935534
accuracy: 0.725000
Epoch 425, CIFAR-10 Batch 4:  loss: 1.256138
accuracy: 0.425000
Epoch 425, CIFAR-10 Batch 5:  loss: 1.043112
accuracy: 0.650000
Epoch 426, CIFAR-10 Batch 1:  loss: 0.833389
accuracy: 0.750000
Epoch 426, CIFAR-10 Batch 2:  loss: 0.774480
accuracy: 0.775000
Epoch 426, CIFAR-10 Batch 3:  loss: 0.890070
accuracy: 0.775000
Epoch 426, CIFAR-10 Batch 4:  loss: 1.202532
accuracy: 0.500000
Epoch 426, CIFAR-10 Batch 5:  loss: 1.016960
accuracy: 0.675000
Epoch 427, CIFAR-10 Batch 1:  loss: 0.843011
accuracy: 0.700000
Epoch 427, CIFAR-10 Batch 2:  loss: 0.901781
accuracy: 0.725000
Epoch 427, CIFAR-10 Batch 3:  loss: 0.886755
accuracy: 0.725000
Epoch 427, CIFAR-10 Batch 4:  loss: 1.255516
accuracy: 0.450000
Epoch 427, CIFAR-10 Batch 5:  loss: 1.042697
accuracy: 0.625000
Epoch 428, CIFAR-10 Batch 1:  loss: 0.841129
accuracy: 0.750000
Epoch 428, CIFAR-10 Batch 2:  loss: 0.784058
accuracy: 0.750000
Epoch 428, CIFAR-10 Batch 3:  loss: 0.875815
accuracy: 0.725000
Epoch 428, CIFAR-10 Batch 4:  loss: 1.203532
accuracy: 0.525000
Epoch 428, CIFAR-10 Batch 5:  loss: 0.990645
accuracy: 0.700000
Epoch 429, CIFAR-10 Batch 1:  loss: 0.836660
accuracy: 0.725000
Epoch 429, CIFAR-10 Batch 2:  loss: 0.778097
accuracy: 0.775000
Epoch 429, CIFAR-10 Batch 3:  loss: 0.875714
accuracy: 0.750000
Epoch 429, CIFAR-10 Batch 4:  loss: 1.216765
accuracy: 0.525000
Epoch 429, CIFAR-10 Batch 5:  loss: 1.032729
accuracy: 0.675000
Epoch 430, CIFAR-10 Batch 1:  loss: 0.814756
accuracy: 0.750000
Epoch 430, CIFAR-10 Batch 2:  loss: 0.773388
accuracy: 0.750000
Epoch 430, CIFAR-10 Batch 3:  loss: 0.921606
accuracy: 0.675000
Epoch 430, CIFAR-10 Batch 4:  loss: 1.224561
accuracy: 0.500000
Epoch 430, CIFAR-10 Batch 5:  loss: 1.014822
accuracy: 0.675000
Epoch 431, CIFAR-10 Batch 1:  loss: 0.825288
accuracy: 0.725000
Epoch 431, CIFAR-10 Batch 2:  loss: 0.789750
accuracy: 0.750000
Epoch 431, CIFAR-10 Batch 3:  loss: 0.893920
accuracy: 0.725000
Epoch 431, CIFAR-10 Batch 4:  loss: 1.245582
accuracy: 0.500000
Epoch 431, CIFAR-10 Batch 5:  loss: 0.979609
accuracy: 0.675000
Epoch 432, CIFAR-10 Batch 1:  loss: 0.825020
accuracy: 0.725000
Epoch 432, CIFAR-10 Batch 2:  loss: 0.767751
accuracy: 0.750000
Epoch 432, CIFAR-10 Batch 3:  loss: 0.872676
accuracy: 0.750000
Epoch 432, CIFAR-10 Batch 4:  loss: 1.240735
accuracy: 0.500000
Epoch 432, CIFAR-10 Batch 5:  loss: 1.024291
accuracy: 0.675000
Epoch 433, CIFAR-10 Batch 1:  loss: 0.844785
accuracy: 0.725000
Epoch 433, CIFAR-10 Batch 2:  loss: 0.788706
accuracy: 0.750000
Epoch 433, CIFAR-10 Batch 3:  loss: 0.875306
accuracy: 0.725000
Epoch 433, CIFAR-10 Batch 4:  loss: 1.232735
accuracy: 0.475000
Epoch 433, CIFAR-10 Batch 5:  loss: 0.963568
accuracy: 0.675000
Epoch 434, CIFAR-10 Batch 1:  loss: 0.866208
accuracy: 0.725000
Epoch 434, CIFAR-10 Batch 2:  loss: 0.769372
accuracy: 0.750000
Epoch 434, CIFAR-10 Batch 3:  loss: 0.853454
accuracy: 0.800000
Epoch 434, CIFAR-10 Batch 4:  loss: 1.277545
accuracy: 0.475000
Epoch 434, CIFAR-10 Batch 5:  loss: 1.003205
accuracy: 0.675000
Epoch 435, CIFAR-10 Batch 1:  loss: 0.820703
accuracy: 0.725000
Epoch 435, CIFAR-10 Batch 2:  loss: 0.827329
accuracy: 0.700000
Epoch 435, CIFAR-10 Batch 3:  loss: 0.909967
accuracy: 0.725000
Epoch 435, CIFAR-10 Batch 4:  loss: 1.216157
accuracy: 0.525000
Epoch 435, CIFAR-10 Batch 5:  loss: 1.034941
accuracy: 0.650000
Epoch 436, CIFAR-10 Batch 1:  loss: 0.834298
accuracy: 0.750000
Epoch 436, CIFAR-10 Batch 2:  loss: 0.781910
accuracy: 0.775000
Epoch 436, CIFAR-10 Batch 3:  loss: 0.894263
accuracy: 0.775000
Epoch 436, CIFAR-10 Batch 4:  loss: 1.282304
accuracy: 0.475000
Epoch 436, CIFAR-10 Batch 5:  loss: 1.032809
accuracy: 0.600000
Epoch 437, CIFAR-10 Batch 1:  loss: 0.860033
accuracy: 0.650000
Epoch 437, CIFAR-10 Batch 2:  loss: 0.774788
accuracy: 0.775000
Epoch 437, CIFAR-10 Batch 3:  loss: 0.881245
accuracy: 0.725000
Epoch 437, CIFAR-10 Batch 4:  loss: 1.293833
accuracy: 0.475000
Epoch 437, CIFAR-10 Batch 5:  loss: 1.070220
accuracy: 0.650000
Epoch 438, CIFAR-10 Batch 1:  loss: 0.816259
accuracy: 0.700000
Epoch 438, CIFAR-10 Batch 2:  loss: 0.773847
accuracy: 0.775000
Epoch 438, CIFAR-10 Batch 3:  loss: 0.917746
accuracy: 0.750000
Epoch 438, CIFAR-10 Batch 4:  loss: 1.319521
accuracy: 0.500000
Epoch 438, CIFAR-10 Batch 5:  loss: 1.014741
accuracy: 0.725000
Epoch 439, CIFAR-10 Batch 1:  loss: 0.840194
accuracy: 0.700000
Epoch 439, CIFAR-10 Batch 2:  loss: 0.748348
accuracy: 0.750000
Epoch 439, CIFAR-10 Batch 3:  loss: 0.899924
accuracy: 0.700000
Epoch 439, CIFAR-10 Batch 4:  loss: 1.277091
accuracy: 0.450000
Epoch 439, CIFAR-10 Batch 5:  loss: 1.012626
accuracy: 0.700000
Epoch 440, CIFAR-10 Batch 1:  loss: 0.822694
accuracy: 0.700000
Epoch 440, CIFAR-10 Batch 2:  loss: 0.786177
accuracy: 0.750000
Epoch 440, CIFAR-10 Batch 3:  loss: 0.884157
accuracy: 0.725000
Epoch 440, CIFAR-10 Batch 4:  loss: 1.226736
accuracy: 0.500000
Epoch 440, CIFAR-10 Batch 5:  loss: 1.035085
accuracy: 0.625000
Epoch 441, CIFAR-10 Batch 1:  loss: 0.824748
accuracy: 0.675000
Epoch 441, CIFAR-10 Batch 2:  loss: 0.804026
accuracy: 0.725000
Epoch 441, CIFAR-10 Batch 3:  loss: 0.939384
accuracy: 0.700000
Epoch 441, CIFAR-10 Batch 4:  loss: 1.239476
accuracy: 0.450000
Epoch 441, CIFAR-10 Batch 5:  loss: 1.010735
accuracy: 0.675000
Epoch 442, CIFAR-10 Batch 1:  loss: 0.836729
accuracy: 0.725000
Epoch 442, CIFAR-10 Batch 2:  loss: 0.798771
accuracy: 0.750000
Epoch 442, CIFAR-10 Batch 3:  loss: 0.984938
accuracy: 0.700000
Epoch 442, CIFAR-10 Batch 4:  loss: 1.225269
accuracy: 0.500000
Epoch 442, CIFAR-10 Batch 5:  loss: 1.054919
accuracy: 0.625000
Epoch 443, CIFAR-10 Batch 1:  loss: 0.846534
accuracy: 0.650000
Epoch 443, CIFAR-10 Batch 2:  loss: 0.808709
accuracy: 0.725000
Epoch 443, CIFAR-10 Batch 3:  loss: 1.023870
accuracy: 0.675000
Epoch 443, CIFAR-10 Batch 4:  loss: 1.215564
accuracy: 0.550000
Epoch 443, CIFAR-10 Batch 5:  loss: 1.061211
accuracy: 0.675000
Epoch 444, CIFAR-10 Batch 1:  loss: 0.841636
accuracy: 0.700000
Epoch 444, CIFAR-10 Batch 2:  loss: 0.820816
accuracy: 0.775000
Epoch 444, CIFAR-10 Batch 3:  loss: 0.889547
accuracy: 0.775000
Epoch 444, CIFAR-10 Batch 4:  loss: 1.254010
accuracy: 0.500000
Epoch 444, CIFAR-10 Batch 5:  loss: 1.044419
accuracy: 0.625000
Epoch 445, CIFAR-10 Batch 1:  loss: 0.833624
accuracy: 0.725000
Epoch 445, CIFAR-10 Batch 2:  loss: 0.819931
accuracy: 0.725000
Epoch 445, CIFAR-10 Batch 3:  loss: 1.026675
accuracy: 0.700000
Epoch 445, CIFAR-10 Batch 4:  loss: 1.245013
accuracy: 0.475000
Epoch 445, CIFAR-10 Batch 5:  loss: 0.991249
accuracy: 0.725000
Epoch 446, CIFAR-10 Batch 1:  loss: 0.826438
accuracy: 0.750000
Epoch 446, CIFAR-10 Batch 2:  loss: 0.769569
accuracy: 0.775000
Epoch 446, CIFAR-10 Batch 3:  loss: 0.884858
accuracy: 0.775000
Epoch 446, CIFAR-10 Batch 4:  loss: 1.221999
accuracy: 0.500000
Epoch 446, CIFAR-10 Batch 5:  loss: 1.036325
accuracy: 0.675000
Epoch 447, CIFAR-10 Batch 1:  loss: 0.851025
accuracy: 0.725000
Epoch 447, CIFAR-10 Batch 2:  loss: 0.779664
accuracy: 0.750000
Epoch 447, CIFAR-10 Batch 3:  loss: 0.873211
accuracy: 0.725000
Epoch 447, CIFAR-10 Batch 4:  loss: 1.197734
accuracy: 0.550000
Epoch 447, CIFAR-10 Batch 5:  loss: 1.003450
accuracy: 0.675000
Epoch 448, CIFAR-10 Batch 1:  loss: 0.835385
accuracy: 0.725000
Epoch 448, CIFAR-10 Batch 2:  loss: 0.803343
accuracy: 0.700000
Epoch 448, CIFAR-10 Batch 3:  loss: 0.890110
accuracy: 0.750000
Epoch 448, CIFAR-10 Batch 4:  loss: 1.193254
accuracy: 0.550000
Epoch 448, CIFAR-10 Batch 5:  loss: 1.005909
accuracy: 0.700000
Epoch 449, CIFAR-10 Batch 1:  loss: 0.832874
accuracy: 0.700000
Epoch 449, CIFAR-10 Batch 2:  loss: 0.824192
accuracy: 0.700000
Epoch 449, CIFAR-10 Batch 3:  loss: 0.899212
accuracy: 0.725000
Epoch 449, CIFAR-10 Batch 4:  loss: 1.183700
accuracy: 0.525000
Epoch 449, CIFAR-10 Batch 5:  loss: 1.042804
accuracy: 0.650000
Epoch 450, CIFAR-10 Batch 1:  loss: 0.825262
accuracy: 0.700000
Epoch 450, CIFAR-10 Batch 2:  loss: 0.810690
accuracy: 0.700000
Epoch 450, CIFAR-10 Batch 3:  loss: 0.888100
accuracy: 0.750000
Epoch 450, CIFAR-10 Batch 4:  loss: 1.200123
accuracy: 0.550000
Epoch 450, CIFAR-10 Batch 5:  loss: 1.015021
accuracy: 0.700000
Epoch 451, CIFAR-10 Batch 1:  loss: 0.837116
accuracy: 0.725000
Epoch 451, CIFAR-10 Batch 2:  loss: 0.841559
accuracy: 0.700000
Epoch 451, CIFAR-10 Batch 3:  loss: 0.907158
accuracy: 0.725000
Epoch 451, CIFAR-10 Batch 4:  loss: 1.270185
accuracy: 0.475000
Epoch 451, CIFAR-10 Batch 5:  loss: 1.012981
accuracy: 0.675000
Epoch 452, CIFAR-10 Batch 1:  loss: 0.842083
accuracy: 0.725000
Epoch 452, CIFAR-10 Batch 2:  loss: 0.790912
accuracy: 0.750000
Epoch 452, CIFAR-10 Batch 3:  loss: 0.901343
accuracy: 0.675000
Epoch 452, CIFAR-10 Batch 4:  loss: 1.211520
accuracy: 0.525000
Epoch 452, CIFAR-10 Batch 5:  loss: 1.024696
accuracy: 0.650000
Epoch 453, CIFAR-10 Batch 1:  loss: 0.846196
accuracy: 0.725000
Epoch 453, CIFAR-10 Batch 2:  loss: 0.862842
accuracy: 0.750000
Epoch 453, CIFAR-10 Batch 3:  loss: 0.940786
accuracy: 0.775000
Epoch 453, CIFAR-10 Batch 4:  loss: 1.287016
accuracy: 0.475000
Epoch 453, CIFAR-10 Batch 5:  loss: 1.056581
accuracy: 0.675000
Epoch 454, CIFAR-10 Batch 1:  loss: 0.826864
accuracy: 0.725000
Epoch 454, CIFAR-10 Batch 2:  loss: 0.805776
accuracy: 0.725000
Epoch 454, CIFAR-10 Batch 3:  loss: 0.904204
accuracy: 0.725000
Epoch 454, CIFAR-10 Batch 4:  loss: 1.272248
accuracy: 0.475000
Epoch 454, CIFAR-10 Batch 5:  loss: 1.122241
accuracy: 0.625000
Epoch 455, CIFAR-10 Batch 1:  loss: 1.164691
accuracy: 0.700000
Epoch 455, CIFAR-10 Batch 2:  loss: 0.790688
accuracy: 0.675000
Epoch 455, CIFAR-10 Batch 3:  loss: 0.914523
accuracy: 0.725000
Epoch 455, CIFAR-10 Batch 4:  loss: 1.238269
accuracy: 0.475000
Epoch 455, CIFAR-10 Batch 5:  loss: 1.065989
accuracy: 0.675000
Epoch 456, CIFAR-10 Batch 1:  loss: 1.110294
accuracy: 0.725000
Epoch 456, CIFAR-10 Batch 2:  loss: 0.805298
accuracy: 0.675000
Epoch 456, CIFAR-10 Batch 3:  loss: 0.887206
accuracy: 0.725000
Epoch 456, CIFAR-10 Batch 4:  loss: 1.211631
accuracy: 0.525000
Epoch 456, CIFAR-10 Batch 5:  loss: 1.030651
accuracy: 0.675000
Epoch 457, CIFAR-10 Batch 1:  loss: 1.003087
accuracy: 0.700000
Epoch 457, CIFAR-10 Batch 2:  loss: 0.799102
accuracy: 0.750000
Epoch 457, CIFAR-10 Batch 3:  loss: 0.904928
accuracy: 0.700000
Epoch 457, CIFAR-10 Batch 4:  loss: 1.237136
accuracy: 0.550000
Epoch 457, CIFAR-10 Batch 5:  loss: 1.034480
accuracy: 0.625000
Epoch 458, CIFAR-10 Batch 1:  loss: 0.844763
accuracy: 0.750000
Epoch 458, CIFAR-10 Batch 2:  loss: 0.792130
accuracy: 0.700000
Epoch 458, CIFAR-10 Batch 3:  loss: 0.874155
accuracy: 0.750000
Epoch 458, CIFAR-10 Batch 4:  loss: 1.197407
accuracy: 0.550000
Epoch 458, CIFAR-10 Batch 5:  loss: 1.065335
accuracy: 0.650000
Epoch 459, CIFAR-10 Batch 1:  loss: 0.845411
accuracy: 0.650000
Epoch 459, CIFAR-10 Batch 2:  loss: 0.799417
accuracy: 0.725000
Epoch 459, CIFAR-10 Batch 3:  loss: 0.932648
accuracy: 0.675000
Epoch 459, CIFAR-10 Batch 4:  loss: 1.253959
accuracy: 0.525000
Epoch 459, CIFAR-10 Batch 5:  loss: 1.015308
accuracy: 0.675000
Epoch 460, CIFAR-10 Batch 1:  loss: 0.837711
accuracy: 0.725000
Epoch 460, CIFAR-10 Batch 2:  loss: 0.826627
accuracy: 0.675000
Epoch 460, CIFAR-10 Batch 3:  loss: 0.944347
accuracy: 0.775000
Epoch 460, CIFAR-10 Batch 4:  loss: 1.232144
accuracy: 0.525000
Epoch 460, CIFAR-10 Batch 5:  loss: 1.076792
accuracy: 0.625000
Epoch 461, CIFAR-10 Batch 1:  loss: 0.832677
accuracy: 0.725000
Epoch 461, CIFAR-10 Batch 2:  loss: 0.804820
accuracy: 0.750000
Epoch 461, CIFAR-10 Batch 3:  loss: 0.958059
accuracy: 0.725000
Epoch 461, CIFAR-10 Batch 4:  loss: 1.226261
accuracy: 0.525000
Epoch 461, CIFAR-10 Batch 5:  loss: 1.054982
accuracy: 0.650000
Epoch 462, CIFAR-10 Batch 1:  loss: 0.859052
accuracy: 0.700000
Epoch 462, CIFAR-10 Batch 2:  loss: 0.803272
accuracy: 0.700000
Epoch 462, CIFAR-10 Batch 3:  loss: 0.874870
accuracy: 0.775000
Epoch 462, CIFAR-10 Batch 4:  loss: 1.230988
accuracy: 0.475000
Epoch 462, CIFAR-10 Batch 5:  loss: 1.083028
accuracy: 0.650000
Epoch 463, CIFAR-10 Batch 1:  loss: 0.866240
accuracy: 0.700000
Epoch 463, CIFAR-10 Batch 2:  loss: 0.827439
accuracy: 0.700000
Epoch 463, CIFAR-10 Batch 3:  loss: 0.861771
accuracy: 0.775000
Epoch 463, CIFAR-10 Batch 4:  loss: 2.386117
accuracy: 0.450000
Epoch 463, CIFAR-10 Batch 5:  loss: 1.061533
accuracy: 0.675000
Epoch 464, CIFAR-10 Batch 1:  loss: 0.853354
accuracy: 0.700000
Epoch 464, CIFAR-10 Batch 2:  loss: 0.815122
accuracy: 0.725000
Epoch 464, CIFAR-10 Batch 3:  loss: 0.875587
accuracy: 0.775000
Epoch 464, CIFAR-10 Batch 4:  loss: 1.194705
accuracy: 0.525000
Epoch 464, CIFAR-10 Batch 5:  loss: 1.035862
accuracy: 0.650000
Epoch 465, CIFAR-10 Batch 1:  loss: 0.838770
accuracy: 0.725000
Epoch 465, CIFAR-10 Batch 2:  loss: 0.810444
accuracy: 0.750000
Epoch 465, CIFAR-10 Batch 3:  loss: 0.850462
accuracy: 0.750000
Epoch 465, CIFAR-10 Batch 4:  loss: 1.330327
accuracy: 0.550000
Epoch 465, CIFAR-10 Batch 5:  loss: 1.040191
accuracy: 0.650000
Epoch 466, CIFAR-10 Batch 1:  loss: 0.819778
accuracy: 0.725000
Epoch 466, CIFAR-10 Batch 2:  loss: 0.808053
accuracy: 0.700000
Epoch 466, CIFAR-10 Batch 3:  loss: 0.858530
accuracy: 0.700000
Epoch 466, CIFAR-10 Batch 4:  loss: 1.218996
accuracy: 0.525000
Epoch 466, CIFAR-10 Batch 5:  loss: 1.042298
accuracy: 0.650000
Epoch 467, CIFAR-10 Batch 1:  loss: 0.829373
accuracy: 0.700000
Epoch 467, CIFAR-10 Batch 2:  loss: 0.808099
accuracy: 0.725000
Epoch 467, CIFAR-10 Batch 3:  loss: 0.823439
accuracy: 0.775000
Epoch 467, CIFAR-10 Batch 4:  loss: 1.240600
accuracy: 0.500000
Epoch 467, CIFAR-10 Batch 5:  loss: 1.071183
accuracy: 0.650000
Epoch 468, CIFAR-10 Batch 1:  loss: 0.820788
accuracy: 0.725000
Epoch 468, CIFAR-10 Batch 2:  loss: 0.852907
accuracy: 0.700000
Epoch 468, CIFAR-10 Batch 3:  loss: 0.845507
accuracy: 0.825000
Epoch 468, CIFAR-10 Batch 4:  loss: 1.192210
accuracy: 0.550000
Epoch 468, CIFAR-10 Batch 5:  loss: 1.080131
accuracy: 0.650000
Epoch 469, CIFAR-10 Batch 1:  loss: 0.838149
accuracy: 0.725000
Epoch 469, CIFAR-10 Batch 2:  loss: 0.788804
accuracy: 0.750000
Epoch 469, CIFAR-10 Batch 3:  loss: 0.853276
accuracy: 0.750000
Epoch 469, CIFAR-10 Batch 4:  loss: 1.220337
accuracy: 0.525000
Epoch 469, CIFAR-10 Batch 5:  loss: 1.049608
accuracy: 0.650000
Epoch 470, CIFAR-10 Batch 1:  loss: 0.834832
accuracy: 0.700000
Epoch 470, CIFAR-10 Batch 2:  loss: 0.811287
accuracy: 0.650000
Epoch 470, CIFAR-10 Batch 3:  loss: 0.869426
accuracy: 0.775000
Epoch 470, CIFAR-10 Batch 4:  loss: 1.194938
accuracy: 0.550000
Epoch 470, CIFAR-10 Batch 5:  loss: 1.064345
accuracy: 0.650000
Epoch 471, CIFAR-10 Batch 1:  loss: 0.834208
accuracy: 0.725000
Epoch 471, CIFAR-10 Batch 2:  loss: 0.790871
accuracy: 0.700000
Epoch 471, CIFAR-10 Batch 3:  loss: 0.846222
accuracy: 0.750000
Epoch 471, CIFAR-10 Batch 4:  loss: 1.244173
accuracy: 0.500000
Epoch 471, CIFAR-10 Batch 5:  loss: 1.081257
accuracy: 0.650000
Epoch 472, CIFAR-10 Batch 1:  loss: 0.836567
accuracy: 0.700000
Epoch 472, CIFAR-10 Batch 2:  loss: 0.826157
accuracy: 0.725000
Epoch 472, CIFAR-10 Batch 3:  loss: 0.858711
accuracy: 0.775000
Epoch 472, CIFAR-10 Batch 4:  loss: 1.284828
accuracy: 0.475000
Epoch 472, CIFAR-10 Batch 5:  loss: 1.065015
accuracy: 0.675000
Epoch 473, CIFAR-10 Batch 1:  loss: 0.843668
accuracy: 0.675000
Epoch 473, CIFAR-10 Batch 2:  loss: 0.782013
accuracy: 0.725000
Epoch 473, CIFAR-10 Batch 3:  loss: 0.854445
accuracy: 0.775000
Epoch 473, CIFAR-10 Batch 4:  loss: 1.239684
accuracy: 0.525000
Epoch 473, CIFAR-10 Batch 5:  loss: 1.067321
accuracy: 0.625000
Epoch 474, CIFAR-10 Batch 1:  loss: 0.816956
accuracy: 0.750000
Epoch 474, CIFAR-10 Batch 2:  loss: 0.795787
accuracy: 0.700000
Epoch 474, CIFAR-10 Batch 3:  loss: 0.878497
accuracy: 0.775000
Epoch 474, CIFAR-10 Batch 4:  loss: 1.205737
accuracy: 0.550000
Epoch 474, CIFAR-10 Batch 5:  loss: 1.022245
accuracy: 0.675000
Epoch 475, CIFAR-10 Batch 1:  loss: 0.840331
accuracy: 0.700000
Epoch 475, CIFAR-10 Batch 2:  loss: 0.802707
accuracy: 0.725000
Epoch 475, CIFAR-10 Batch 3:  loss: 0.817933
accuracy: 0.800000
Epoch 475, CIFAR-10 Batch 4:  loss: 1.229108
accuracy: 0.500000
Epoch 475, CIFAR-10 Batch 5:  loss: 1.079246
accuracy: 0.675000
Epoch 476, CIFAR-10 Batch 1:  loss: 0.844341
accuracy: 0.725000
Epoch 476, CIFAR-10 Batch 2:  loss: 0.840693
accuracy: 0.675000
Epoch 476, CIFAR-10 Batch 3:  loss: 0.841685
accuracy: 0.775000
Epoch 476, CIFAR-10 Batch 4:  loss: 1.240711
accuracy: 0.500000
Epoch 476, CIFAR-10 Batch 5:  loss: 1.083175
accuracy: 0.650000
Epoch 477, CIFAR-10 Batch 1:  loss: 0.870190
accuracy: 0.700000
Epoch 477, CIFAR-10 Batch 2:  loss: 0.796679
accuracy: 0.725000
Epoch 477, CIFAR-10 Batch 3:  loss: 0.820964
accuracy: 0.775000
Epoch 477, CIFAR-10 Batch 4:  loss: 1.209227
accuracy: 0.550000
Epoch 477, CIFAR-10 Batch 5:  loss: 1.033374
accuracy: 0.700000
Epoch 478, CIFAR-10 Batch 1:  loss: 0.864833
accuracy: 0.675000
Epoch 478, CIFAR-10 Batch 2:  loss: 0.856204
accuracy: 0.675000
Epoch 478, CIFAR-10 Batch 3:  loss: 0.849160
accuracy: 0.800000
Epoch 478, CIFAR-10 Batch 4:  loss: 1.213812
accuracy: 0.575000
Epoch 478, CIFAR-10 Batch 5:  loss: 1.071921
accuracy: 0.675000
Epoch 479, CIFAR-10 Batch 1:  loss: 0.829313
accuracy: 0.725000
Epoch 479, CIFAR-10 Batch 2:  loss: 0.790234
accuracy: 0.700000
Epoch 479, CIFAR-10 Batch 3:  loss: 0.810664
accuracy: 0.775000
Epoch 479, CIFAR-10 Batch 4:  loss: 1.246691
accuracy: 0.500000
Epoch 479, CIFAR-10 Batch 5:  loss: 1.038951
accuracy: 0.700000
Epoch 480, CIFAR-10 Batch 1:  loss: 0.813303
accuracy: 0.725000
Epoch 480, CIFAR-10 Batch 2:  loss: 0.829183
accuracy: 0.700000
Epoch 480, CIFAR-10 Batch 3:  loss: 0.805330
accuracy: 0.750000
Epoch 480, CIFAR-10 Batch 4:  loss: 1.240950
accuracy: 0.500000
Epoch 480, CIFAR-10 Batch 5:  loss: 1.096071
accuracy: 0.675000
Epoch 481, CIFAR-10 Batch 1:  loss: 0.817664
accuracy: 0.700000
Epoch 481, CIFAR-10 Batch 2:  loss: 0.790273
accuracy: 0.750000
Epoch 481, CIFAR-10 Batch 3:  loss: 0.816876
accuracy: 0.775000
Epoch 481, CIFAR-10 Batch 4:  loss: 1.191314
accuracy: 0.550000
Epoch 481, CIFAR-10 Batch 5:  loss: 1.072900
accuracy: 0.650000
Epoch 482, CIFAR-10 Batch 1:  loss: 0.831962
accuracy: 0.725000
Epoch 482, CIFAR-10 Batch 2:  loss: 0.787684
accuracy: 0.675000
Epoch 482, CIFAR-10 Batch 3:  loss: 0.865113
accuracy: 0.750000
Epoch 482, CIFAR-10 Batch 4:  loss: 1.209235
accuracy: 0.550000
Epoch 482, CIFAR-10 Batch 5:  loss: 1.034581
accuracy: 0.700000
Epoch 483, CIFAR-10 Batch 1:  loss: 0.826499
accuracy: 0.725000
Epoch 483, CIFAR-10 Batch 2:  loss: 0.872566
accuracy: 0.650000
Epoch 483, CIFAR-10 Batch 3:  loss: 0.853443
accuracy: 0.750000
Epoch 483, CIFAR-10 Batch 4:  loss: 1.213933
accuracy: 0.500000
Epoch 483, CIFAR-10 Batch 5:  loss: 1.039975
accuracy: 0.675000
Epoch 484, CIFAR-10 Batch 1:  loss: 0.841611
accuracy: 0.700000
Epoch 484, CIFAR-10 Batch 2:  loss: 0.877705
accuracy: 0.675000
Epoch 484, CIFAR-10 Batch 3:  loss: 0.835423
accuracy: 0.800000
Epoch 484, CIFAR-10 Batch 4:  loss: 1.208302
accuracy: 0.550000
Epoch 484, CIFAR-10 Batch 5:  loss: 1.075968
accuracy: 0.650000
Epoch 485, CIFAR-10 Batch 1:  loss: 0.828951
accuracy: 0.750000
Epoch 485, CIFAR-10 Batch 2:  loss: 0.789309
accuracy: 0.675000
Epoch 485, CIFAR-10 Batch 3:  loss: 0.800401
accuracy: 0.800000
Epoch 485, CIFAR-10 Batch 4:  loss: 1.240357
accuracy: 0.525000
Epoch 485, CIFAR-10 Batch 5:  loss: 1.060619
accuracy: 0.700000
Epoch 486, CIFAR-10 Batch 1:  loss: 0.838654
accuracy: 0.700000
Epoch 486, CIFAR-10 Batch 2:  loss: 0.827971
accuracy: 0.700000
Epoch 486, CIFAR-10 Batch 3:  loss: 0.822785
accuracy: 0.775000
Epoch 486, CIFAR-10 Batch 4:  loss: 1.651271
accuracy: 0.475000
Epoch 486, CIFAR-10 Batch 5:  loss: 1.160467
accuracy: 0.575000
Epoch 487, CIFAR-10 Batch 1:  loss: 0.840041
accuracy: 0.700000
Epoch 487, CIFAR-10 Batch 2:  loss: 0.795254
accuracy: 0.725000
Epoch 487, CIFAR-10 Batch 3:  loss: 0.848468
accuracy: 0.800000
Epoch 487, CIFAR-10 Batch 4:  loss: 2.395282
accuracy: 0.500000
Epoch 487, CIFAR-10 Batch 5:  loss: 1.093014
accuracy: 0.675000
Epoch 488, CIFAR-10 Batch 1:  loss: 0.821780
accuracy: 0.750000
Epoch 488, CIFAR-10 Batch 2:  loss: 0.785468
accuracy: 0.725000
Epoch 488, CIFAR-10 Batch 3:  loss: 0.798561
accuracy: 0.800000
Epoch 488, CIFAR-10 Batch 4:  loss: 1.615258
accuracy: 0.500000
Epoch 488, CIFAR-10 Batch 5:  loss: 1.047823
accuracy: 0.700000
Epoch 489, CIFAR-10 Batch 1:  loss: 0.805164
accuracy: 0.725000
Epoch 489, CIFAR-10 Batch 2:  loss: 0.786348
accuracy: 0.700000
Epoch 489, CIFAR-10 Batch 3:  loss: 0.831236
accuracy: 0.750000
Epoch 489, CIFAR-10 Batch 4:  loss: 1.214541
accuracy: 0.475000
Epoch 489, CIFAR-10 Batch 5:  loss: 1.065285
accuracy: 0.700000
Epoch 490, CIFAR-10 Batch 1:  loss: 0.853650
accuracy: 0.725000
Epoch 490, CIFAR-10 Batch 2:  loss: 0.792162
accuracy: 0.725000
Epoch 490, CIFAR-10 Batch 3:  loss: 0.795267
accuracy: 0.775000
Epoch 490, CIFAR-10 Batch 4:  loss: 1.207142
accuracy: 0.575000
Epoch 490, CIFAR-10 Batch 5:  loss: 1.067841
accuracy: 0.700000
Epoch 491, CIFAR-10 Batch 1:  loss: 0.830833
accuracy: 0.700000
Epoch 491, CIFAR-10 Batch 2:  loss: 0.776388
accuracy: 0.700000
Epoch 491, CIFAR-10 Batch 3:  loss: 0.835174
accuracy: 0.775000
Epoch 491, CIFAR-10 Batch 4:  loss: 1.250289
accuracy: 0.500000
Epoch 491, CIFAR-10 Batch 5:  loss: 1.023925
accuracy: 0.725000
Epoch 492, CIFAR-10 Batch 1:  loss: 0.796654
accuracy: 0.775000
Epoch 492, CIFAR-10 Batch 2:  loss: 0.807056
accuracy: 0.750000
Epoch 492, CIFAR-10 Batch 3:  loss: 0.820563
accuracy: 0.750000
Epoch 492, CIFAR-10 Batch 4:  loss: 1.211828
accuracy: 0.550000
Epoch 492, CIFAR-10 Batch 5:  loss: 1.025941
accuracy: 0.700000
Epoch 493, CIFAR-10 Batch 1:  loss: 0.801703
accuracy: 0.775000
Epoch 493, CIFAR-10 Batch 2:  loss: 0.807844
accuracy: 0.700000
Epoch 493, CIFAR-10 Batch 3:  loss: 0.813398
accuracy: 0.775000
Epoch 493, CIFAR-10 Batch 4:  loss: 1.235624
accuracy: 0.550000
Epoch 493, CIFAR-10 Batch 5:  loss: 1.040541
accuracy: 0.675000
Epoch 494, CIFAR-10 Batch 1:  loss: 0.833194
accuracy: 0.725000
Epoch 494, CIFAR-10 Batch 2:  loss: 0.798906
accuracy: 0.750000
Epoch 494, CIFAR-10 Batch 3:  loss: 0.819641
accuracy: 0.750000
Epoch 494, CIFAR-10 Batch 4:  loss: 1.202755
accuracy: 0.550000
Epoch 494, CIFAR-10 Batch 5:  loss: 1.105362
accuracy: 0.650000
Epoch 495, CIFAR-10 Batch 1:  loss: 0.765288
accuracy: 0.775000
Epoch 495, CIFAR-10 Batch 2:  loss: 0.804023
accuracy: 0.700000
Epoch 495, CIFAR-10 Batch 3:  loss: 0.839045
accuracy: 0.775000
Epoch 495, CIFAR-10 Batch 4:  loss: 1.205272
accuracy: 0.550000
Epoch 495, CIFAR-10 Batch 5:  loss: 1.015765
accuracy: 0.725000
Epoch 496, CIFAR-10 Batch 1:  loss: 0.805510
accuracy: 0.750000
Epoch 496, CIFAR-10 Batch 2:  loss: 0.797875
accuracy: 0.675000
Epoch 496, CIFAR-10 Batch 3:  loss: 0.820567
accuracy: 0.750000
Epoch 496, CIFAR-10 Batch 4:  loss: 1.253696
accuracy: 0.550000
Epoch 496, CIFAR-10 Batch 5:  loss: 1.014138
accuracy: 0.725000
Epoch 497, CIFAR-10 Batch 1:  loss: 0.805898
accuracy: 0.775000
Epoch 497, CIFAR-10 Batch 2:  loss: 0.841123
accuracy: 0.700000
Epoch 497, CIFAR-10 Batch 3:  loss: 0.808145
accuracy: 0.750000
Epoch 497, CIFAR-10 Batch 4:  loss: 1.202975
accuracy: 0.525000
Epoch 497, CIFAR-10 Batch 5:  loss: 1.038481
accuracy: 0.700000
Epoch 498, CIFAR-10 Batch 1:  loss: 0.777793
accuracy: 0.800000
Epoch 498, CIFAR-10 Batch 2:  loss: 0.786676
accuracy: 0.700000
Epoch 498, CIFAR-10 Batch 3:  loss: 0.829092
accuracy: 0.775000
Epoch 498, CIFAR-10 Batch 4:  loss: 1.201018
accuracy: 0.525000
Epoch 498, CIFAR-10 Batch 5:  loss: 1.014217
accuracy: 0.700000
Epoch 499, CIFAR-10 Batch 1:  loss: 0.782592
accuracy: 0.725000
Epoch 499, CIFAR-10 Batch 2:  loss: 0.796938
accuracy: 0.675000
Epoch 499, CIFAR-10 Batch 3:  loss: 0.813485
accuracy: 0.775000
Epoch 499, CIFAR-10 Batch 4:  loss: 1.184811
accuracy: 0.625000
Epoch 499, CIFAR-10 Batch 5:  loss: 0.991086
accuracy: 0.725000
Epoch 500, CIFAR-10 Batch 1:  loss: 0.784499
accuracy: 0.775000
Epoch 500, CIFAR-10 Batch 2:  loss: 0.832575
accuracy: 0.700000
Epoch 500, CIFAR-10 Batch 3:  loss: 0.806205
accuracy: 0.775000
Epoch 500, CIFAR-10 Batch 4:  loss: 1.233940
accuracy: 0.525000
Epoch 500, CIFAR-10 Batch 5:  loss: 1.030485
accuracy: 0.700000
Epoch 501, CIFAR-10 Batch 1:  loss: 0.784304
accuracy: 0.750000
Epoch 501, CIFAR-10 Batch 2:  loss: 0.808088
accuracy: 0.750000
Epoch 501, CIFAR-10 Batch 3:  loss: 0.796268
accuracy: 0.775000
Epoch 501, CIFAR-10 Batch 4:  loss: 1.206828
accuracy: 0.525000
Epoch 501, CIFAR-10 Batch 5:  loss: 1.014726
accuracy: 0.725000
Epoch 502, CIFAR-10 Batch 1:  loss: 0.816492
accuracy: 0.700000
Epoch 502, CIFAR-10 Batch 2:  loss: 0.820615
accuracy: 0.675000
Epoch 502, CIFAR-10 Batch 3:  loss: 0.799113
accuracy: 0.800000
Epoch 502, CIFAR-10 Batch 4:  loss: 1.157505
accuracy: 0.550000
Epoch 502, CIFAR-10 Batch 5:  loss: 1.047950
accuracy: 0.650000
Epoch 503, CIFAR-10 Batch 1:  loss: 0.821712
accuracy: 0.700000
Epoch 503, CIFAR-10 Batch 2:  loss: 0.824989
accuracy: 0.700000
Epoch 503, CIFAR-10 Batch 3:  loss: 0.812407
accuracy: 0.775000
Epoch 503, CIFAR-10 Batch 4:  loss: 1.205324
accuracy: 0.575000
Epoch 503, CIFAR-10 Batch 5:  loss: 1.001276
accuracy: 0.700000
Epoch 504, CIFAR-10 Batch 1:  loss: 0.817136
accuracy: 0.675000
Epoch 504, CIFAR-10 Batch 2:  loss: 0.823437
accuracy: 0.700000
Epoch 504, CIFAR-10 Batch 3:  loss: 0.832492
accuracy: 0.750000
Epoch 504, CIFAR-10 Batch 4:  loss: 1.230077
accuracy: 0.525000
Epoch 504, CIFAR-10 Batch 5:  loss: 1.060589
accuracy: 0.650000
Epoch 505, CIFAR-10 Batch 1:  loss: 0.831637
accuracy: 0.725000
Epoch 505, CIFAR-10 Batch 2:  loss: 0.814621
accuracy: 0.700000
Epoch 505, CIFAR-10 Batch 3:  loss: 0.810020
accuracy: 0.800000
Epoch 505, CIFAR-10 Batch 4:  loss: 1.245360
accuracy: 0.500000
Epoch 505, CIFAR-10 Batch 5:  loss: 1.028396
accuracy: 0.675000
Epoch 506, CIFAR-10 Batch 1:  loss: 0.806926
accuracy: 0.725000
Epoch 506, CIFAR-10 Batch 2:  loss: 0.780073
accuracy: 0.725000
Epoch 506, CIFAR-10 Batch 3:  loss: 0.908871
accuracy: 0.750000
Epoch 506, CIFAR-10 Batch 4:  loss: 1.226334
accuracy: 0.525000
Epoch 506, CIFAR-10 Batch 5:  loss: 1.089995
accuracy: 0.700000
Epoch 507, CIFAR-10 Batch 1:  loss: 0.845076
accuracy: 0.725000
Epoch 507, CIFAR-10 Batch 2:  loss: 0.826753
accuracy: 0.675000
Epoch 507, CIFAR-10 Batch 3:  loss: 1.113248
accuracy: 0.750000
Epoch 507, CIFAR-10 Batch 4:  loss: 1.167615
accuracy: 0.600000
Epoch 507, CIFAR-10 Batch 5:  loss: 1.044926
accuracy: 0.700000
Epoch 508, CIFAR-10 Batch 1:  loss: 0.797440
accuracy: 0.725000
Epoch 508, CIFAR-10 Batch 2:  loss: 0.826258
accuracy: 0.700000
Epoch 508, CIFAR-10 Batch 3:  loss: 1.077906
accuracy: 0.800000
Epoch 508, CIFAR-10 Batch 4:  loss: 1.203840
accuracy: 0.550000
Epoch 508, CIFAR-10 Batch 5:  loss: 1.074017
accuracy: 0.700000
Epoch 509, CIFAR-10 Batch 1:  loss: 0.799393
accuracy: 0.775000
Epoch 509, CIFAR-10 Batch 2:  loss: 0.807120
accuracy: 0.700000
Epoch 509, CIFAR-10 Batch 3:  loss: 0.832717
accuracy: 0.725000
Epoch 509, CIFAR-10 Batch 4:  loss: 1.196563
accuracy: 0.550000
Epoch 509, CIFAR-10 Batch 5:  loss: 1.083241
accuracy: 0.675000
Epoch 510, CIFAR-10 Batch 1:  loss: 0.786226
accuracy: 0.725000
Epoch 510, CIFAR-10 Batch 2:  loss: 0.837756
accuracy: 0.650000
Epoch 510, CIFAR-10 Batch 3:  loss: 0.791860
accuracy: 0.825000
Epoch 510, CIFAR-10 Batch 4:  loss: 1.172069
accuracy: 0.575000
Epoch 510, CIFAR-10 Batch 5:  loss: 1.066455
accuracy: 0.650000
Epoch 511, CIFAR-10 Batch 1:  loss: 0.802890
accuracy: 0.750000
Epoch 511, CIFAR-10 Batch 2:  loss: 0.808634
accuracy: 0.725000
Epoch 511, CIFAR-10 Batch 3:  loss: 0.840457
accuracy: 0.750000
Epoch 511, CIFAR-10 Batch 4:  loss: 1.218338
accuracy: 0.575000
Epoch 511, CIFAR-10 Batch 5:  loss: 1.050762
accuracy: 0.650000
Epoch 512, CIFAR-10 Batch 1:  loss: 0.848913
accuracy: 0.700000
Epoch 512, CIFAR-10 Batch 2:  loss: 0.793949
accuracy: 0.675000
Epoch 512, CIFAR-10 Batch 3:  loss: 0.843714
accuracy: 0.800000
Epoch 512, CIFAR-10 Batch 4:  loss: 1.214602
accuracy: 0.500000
Epoch 512, CIFAR-10 Batch 5:  loss: 1.045221
accuracy: 0.725000
Epoch 513, CIFAR-10 Batch 1:  loss: 0.823017
accuracy: 0.725000
Epoch 513, CIFAR-10 Batch 2:  loss: 0.855295
accuracy: 0.650000
Epoch 513, CIFAR-10 Batch 3:  loss: 0.835979
accuracy: 0.775000
Epoch 513, CIFAR-10 Batch 4:  loss: 1.188392
accuracy: 0.575000
Epoch 513, CIFAR-10 Batch 5:  loss: 1.102536
accuracy: 0.650000
Epoch 514, CIFAR-10 Batch 1:  loss: 0.795586
accuracy: 0.725000
Epoch 514, CIFAR-10 Batch 2:  loss: 0.798139
accuracy: 0.650000
Epoch 514, CIFAR-10 Batch 3:  loss: 0.864519
accuracy: 0.775000
Epoch 514, CIFAR-10 Batch 4:  loss: 1.118339
accuracy: 0.600000
Epoch 514, CIFAR-10 Batch 5:  loss: 1.047710
accuracy: 0.700000
Epoch 515, CIFAR-10 Batch 1:  loss: 0.829612
accuracy: 0.675000
Epoch 515, CIFAR-10 Batch 2:  loss: 0.839823
accuracy: 0.675000
Epoch 515, CIFAR-10 Batch 3:  loss: 0.825596
accuracy: 0.825000
Epoch 515, CIFAR-10 Batch 4:  loss: 1.193794
accuracy: 0.525000
Epoch 515, CIFAR-10 Batch 5:  loss: 1.053596
accuracy: 0.700000
Epoch 516, CIFAR-10 Batch 1:  loss: 0.808261
accuracy: 0.775000
Epoch 516, CIFAR-10 Batch 2:  loss: 0.819702
accuracy: 0.700000
Epoch 516, CIFAR-10 Batch 3:  loss: 0.886355
accuracy: 0.750000
Epoch 516, CIFAR-10 Batch 4:  loss: 1.171358
accuracy: 0.550000
Epoch 516, CIFAR-10 Batch 5:  loss: 1.079342
accuracy: 0.700000
Epoch 517, CIFAR-10 Batch 1:  loss: 0.813313
accuracy: 0.725000
Epoch 517, CIFAR-10 Batch 2:  loss: 2.343413
accuracy: 0.675000
Epoch 517, CIFAR-10 Batch 3:  loss: 0.849404
accuracy: 0.775000
Epoch 517, CIFAR-10 Batch 4:  loss: 1.215087
accuracy: 0.550000
Epoch 517, CIFAR-10 Batch 5:  loss: 1.143101
accuracy: 0.650000
Epoch 518, CIFAR-10 Batch 1:  loss: 0.827924
accuracy: 0.700000
Epoch 518, CIFAR-10 Batch 2:  loss: 2.108164
accuracy: 0.650000
Epoch 518, CIFAR-10 Batch 3:  loss: 0.904427
accuracy: 0.775000
Epoch 518, CIFAR-10 Batch 4:  loss: 1.160693
accuracy: 0.575000
Epoch 518, CIFAR-10 Batch 5:  loss: 1.031754
accuracy: 0.700000
Epoch 519, CIFAR-10 Batch 1:  loss: 0.817475
accuracy: 0.700000
Epoch 519, CIFAR-10 Batch 2:  loss: 1.677237
accuracy: 0.675000
Epoch 519, CIFAR-10 Batch 3:  loss: 0.863647
accuracy: 0.775000
Epoch 519, CIFAR-10 Batch 4:  loss: 1.178044
accuracy: 0.550000
Epoch 519, CIFAR-10 Batch 5:  loss: 1.034236
accuracy: 0.725000
Epoch 520, CIFAR-10 Batch 1:  loss: 0.798647
accuracy: 0.725000
Epoch 520, CIFAR-10 Batch 2:  loss: 0.777637
accuracy: 0.675000
Epoch 520, CIFAR-10 Batch 3:  loss: 0.859526
accuracy: 0.750000
Epoch 520, CIFAR-10 Batch 4:  loss: 1.147243
accuracy: 0.600000
Epoch 520, CIFAR-10 Batch 5:  loss: 1.036546
accuracy: 0.700000
Epoch 521, CIFAR-10 Batch 1:  loss: 0.822040
accuracy: 0.700000
Epoch 521, CIFAR-10 Batch 2:  loss: 0.808891
accuracy: 0.700000
Epoch 521, CIFAR-10 Batch 3:  loss: 0.815794
accuracy: 0.800000
Epoch 521, CIFAR-10 Batch 4:  loss: 1.164022
accuracy: 0.575000
Epoch 521, CIFAR-10 Batch 5:  loss: 1.003594
accuracy: 0.700000
Epoch 522, CIFAR-10 Batch 1:  loss: 0.839790
accuracy: 0.700000
Epoch 522, CIFAR-10 Batch 2:  loss: 0.824243
accuracy: 0.675000
Epoch 522, CIFAR-10 Batch 3:  loss: 0.853719
accuracy: 0.800000
Epoch 522, CIFAR-10 Batch 4:  loss: 1.163010
accuracy: 0.575000
Epoch 522, CIFAR-10 Batch 5:  loss: 1.011688
accuracy: 0.700000
Epoch 523, CIFAR-10 Batch 1:  loss: 0.805860
accuracy: 0.725000
Epoch 523, CIFAR-10 Batch 2:  loss: 0.769663
accuracy: 0.700000
Epoch 523, CIFAR-10 Batch 3:  loss: 0.876269
accuracy: 0.775000
Epoch 523, CIFAR-10 Batch 4:  loss: 1.132339
accuracy: 0.575000
Epoch 523, CIFAR-10 Batch 5:  loss: 1.011843
accuracy: 0.700000
Epoch 524, CIFAR-10 Batch 1:  loss: 0.822967
accuracy: 0.700000
Epoch 524, CIFAR-10 Batch 2:  loss: 1.733285
accuracy: 0.675000
Epoch 524, CIFAR-10 Batch 3:  loss: 0.859199
accuracy: 0.750000
Epoch 524, CIFAR-10 Batch 4:  loss: 1.134922
accuracy: 0.600000
Epoch 524, CIFAR-10 Batch 5:  loss: 1.026639
accuracy: 0.675000
Epoch 525, CIFAR-10 Batch 1:  loss: 0.844247
accuracy: 0.675000
Epoch 525, CIFAR-10 Batch 2:  loss: 0.805356
accuracy: 0.700000
Epoch 525, CIFAR-10 Batch 3:  loss: 0.838429
accuracy: 0.800000
Epoch 525, CIFAR-10 Batch 4:  loss: 1.113316
accuracy: 0.600000
Epoch 525, CIFAR-10 Batch 5:  loss: 1.014293
accuracy: 0.700000
Epoch 526, CIFAR-10 Batch 1:  loss: 0.814075
accuracy: 0.725000
Epoch 526, CIFAR-10 Batch 2:  loss: 0.782840
accuracy: 0.700000
Epoch 526, CIFAR-10 Batch 3:  loss: 0.859200
accuracy: 0.725000
Epoch 526, CIFAR-10 Batch 4:  loss: 1.134860
accuracy: 0.550000
Epoch 526, CIFAR-10 Batch 5:  loss: 1.052425
accuracy: 0.700000
Epoch 527, CIFAR-10 Batch 1:  loss: 0.844257
accuracy: 0.675000
Epoch 527, CIFAR-10 Batch 2:  loss: 0.786223
accuracy: 0.700000
Epoch 527, CIFAR-10 Batch 3:  loss: 0.870765
accuracy: 0.825000
Epoch 527, CIFAR-10 Batch 4:  loss: 1.197597
accuracy: 0.600000
Epoch 527, CIFAR-10 Batch 5:  loss: 1.040042
accuracy: 0.700000
Epoch 528, CIFAR-10 Batch 1:  loss: 0.842130
accuracy: 0.700000
Epoch 528, CIFAR-10 Batch 2:  loss: 0.778005
accuracy: 0.725000
Epoch 528, CIFAR-10 Batch 3:  loss: 0.811590
accuracy: 0.825000
Epoch 528, CIFAR-10 Batch 4:  loss: 1.101570
accuracy: 0.625000
Epoch 528, CIFAR-10 Batch 5:  loss: 1.048606
accuracy: 0.700000
Epoch 529, CIFAR-10 Batch 1:  loss: 0.796723
accuracy: 0.750000
Epoch 529, CIFAR-10 Batch 2:  loss: 0.767204
accuracy: 0.725000
Epoch 529, CIFAR-10 Batch 3:  loss: 0.851550
accuracy: 0.800000
Epoch 529, CIFAR-10 Batch 4:  loss: 1.102985
accuracy: 0.600000
Epoch 529, CIFAR-10 Batch 5:  loss: 1.077714
accuracy: 0.725000
Epoch 530, CIFAR-10 Batch 1:  loss: 0.798527
accuracy: 0.725000
Epoch 530, CIFAR-10 Batch 2:  loss: 0.781429
accuracy: 0.700000
Epoch 530, CIFAR-10 Batch 3:  loss: 0.847848
accuracy: 0.775000
Epoch 530, CIFAR-10 Batch 4:  loss: 1.122869
accuracy: 0.575000
Epoch 530, CIFAR-10 Batch 5:  loss: 1.042205
accuracy: 0.675000
Epoch 531, CIFAR-10 Batch 1:  loss: 0.846382
accuracy: 0.675000
Epoch 531, CIFAR-10 Batch 2:  loss: 0.778461
accuracy: 0.725000
Epoch 531, CIFAR-10 Batch 3:  loss: 0.845861
accuracy: 0.800000
Epoch 531, CIFAR-10 Batch 4:  loss: 1.131512
accuracy: 0.575000
Epoch 531, CIFAR-10 Batch 5:  loss: 1.083503
accuracy: 0.675000
Epoch 532, CIFAR-10 Batch 1:  loss: 0.826919
accuracy: 0.675000
Epoch 532, CIFAR-10 Batch 2:  loss: 0.762178
accuracy: 0.700000
Epoch 532, CIFAR-10 Batch 3:  loss: 0.807645
accuracy: 0.800000
Epoch 532, CIFAR-10 Batch 4:  loss: 1.124452
accuracy: 0.575000
Epoch 532, CIFAR-10 Batch 5:  loss: 1.048904
accuracy: 0.675000
Epoch 533, CIFAR-10 Batch 1:  loss: 0.804417
accuracy: 0.725000
Epoch 533, CIFAR-10 Batch 2:  loss: 0.796645
accuracy: 0.700000
Epoch 533, CIFAR-10 Batch 3:  loss: 0.852789
accuracy: 0.775000
Epoch 533, CIFAR-10 Batch 4:  loss: 1.109827
accuracy: 0.650000
Epoch 533, CIFAR-10 Batch 5:  loss: 1.050199
accuracy: 0.650000
Epoch 534, CIFAR-10 Batch 1:  loss: 0.798807
accuracy: 0.725000
Epoch 534, CIFAR-10 Batch 2:  loss: 0.787308
accuracy: 0.750000
Epoch 534, CIFAR-10 Batch 3:  loss: 0.827791
accuracy: 0.775000
Epoch 534, CIFAR-10 Batch 4:  loss: 1.116393
accuracy: 0.575000
Epoch 534, CIFAR-10 Batch 5:  loss: 1.078028
accuracy: 0.650000
Epoch 535, CIFAR-10 Batch 1:  loss: 0.816344
accuracy: 0.725000
Epoch 535, CIFAR-10 Batch 2:  loss: 0.830853
accuracy: 0.650000
Epoch 535, CIFAR-10 Batch 3:  loss: 0.805696
accuracy: 0.775000
Epoch 535, CIFAR-10 Batch 4:  loss: 1.122071
accuracy: 0.600000
Epoch 535, CIFAR-10 Batch 5:  loss: 1.089995
accuracy: 0.675000
Epoch 536, CIFAR-10 Batch 1:  loss: 0.819444
accuracy: 0.725000
Epoch 536, CIFAR-10 Batch 2:  loss: 0.820574
accuracy: 0.675000
Epoch 536, CIFAR-10 Batch 3:  loss: 0.868838
accuracy: 0.800000
Epoch 536, CIFAR-10 Batch 4:  loss: 1.118635
accuracy: 0.600000
Epoch 536, CIFAR-10 Batch 5:  loss: 1.026505
accuracy: 0.725000
Epoch 537, CIFAR-10 Batch 1:  loss: 0.828498
accuracy: 0.725000
Epoch 537, CIFAR-10 Batch 2:  loss: 0.777952
accuracy: 0.700000
Epoch 537, CIFAR-10 Batch 3:  loss: 0.848434
accuracy: 0.825000
Epoch 537, CIFAR-10 Batch 4:  loss: 1.127055
accuracy: 0.575000
Epoch 537, CIFAR-10 Batch 5:  loss: 1.032796
accuracy: 0.725000
Epoch 538, CIFAR-10 Batch 1:  loss: 0.801697
accuracy: 0.750000
Epoch 538, CIFAR-10 Batch 2:  loss: 0.772113
accuracy: 0.725000
Epoch 538, CIFAR-10 Batch 3:  loss: 0.842209
accuracy: 0.825000
Epoch 538, CIFAR-10 Batch 4:  loss: 1.119356
accuracy: 0.600000
Epoch 538, CIFAR-10 Batch 5:  loss: 1.041717
accuracy: 0.725000
Epoch 539, CIFAR-10 Batch 1:  loss: 0.803662
accuracy: 0.725000
Epoch 539, CIFAR-10 Batch 2:  loss: 0.760119
accuracy: 0.700000
Epoch 539, CIFAR-10 Batch 3:  loss: 0.880210
accuracy: 0.800000
Epoch 539, CIFAR-10 Batch 4:  loss: 1.120187
accuracy: 0.600000
Epoch 539, CIFAR-10 Batch 5:  loss: 1.054066
accuracy: 0.725000
Epoch 540, CIFAR-10 Batch 1:  loss: 0.813873
accuracy: 0.725000
Epoch 540, CIFAR-10 Batch 2:  loss: 0.772720
accuracy: 0.675000
Epoch 540, CIFAR-10 Batch 3:  loss: 0.846494
accuracy: 0.775000
Epoch 540, CIFAR-10 Batch 4:  loss: 1.102265
accuracy: 0.575000
Epoch 540, CIFAR-10 Batch 5:  loss: 1.044623
accuracy: 0.725000
Epoch 541, CIFAR-10 Batch 1:  loss: 0.815026
accuracy: 0.725000
Epoch 541, CIFAR-10 Batch 2:  loss: 0.796701
accuracy: 0.725000
Epoch 541, CIFAR-10 Batch 3:  loss: 0.837602
accuracy: 0.775000
Epoch 541, CIFAR-10 Batch 4:  loss: 1.119573
accuracy: 0.600000
Epoch 541, CIFAR-10 Batch 5:  loss: 1.073314
accuracy: 0.650000
Epoch 542, CIFAR-10 Batch 1:  loss: 0.805831
accuracy: 0.725000
Epoch 542, CIFAR-10 Batch 2:  loss: 0.770040
accuracy: 0.675000
Epoch 542, CIFAR-10 Batch 3:  loss: 0.815915
accuracy: 0.800000
Epoch 542, CIFAR-10 Batch 4:  loss: 1.127081
accuracy: 0.600000
Epoch 542, CIFAR-10 Batch 5:  loss: 1.074471
accuracy: 0.700000
Epoch 543, CIFAR-10 Batch 1:  loss: 0.795123
accuracy: 0.750000
Epoch 543, CIFAR-10 Batch 2:  loss: 0.751309
accuracy: 0.725000
Epoch 543, CIFAR-10 Batch 3:  loss: 0.836364
accuracy: 0.825000
Epoch 543, CIFAR-10 Batch 4:  loss: 1.121060
accuracy: 0.575000
Epoch 543, CIFAR-10 Batch 5:  loss: 1.033916
accuracy: 0.700000
Epoch 544, CIFAR-10 Batch 1:  loss: 0.803414
accuracy: 0.775000
Epoch 544, CIFAR-10 Batch 2:  loss: 0.797952
accuracy: 0.700000
Epoch 544, CIFAR-10 Batch 3:  loss: 0.866735
accuracy: 0.800000
Epoch 544, CIFAR-10 Batch 4:  loss: 1.121969
accuracy: 0.625000
Epoch 544, CIFAR-10 Batch 5:  loss: 1.012825
accuracy: 0.675000
Epoch 545, CIFAR-10 Batch 1:  loss: 0.821255
accuracy: 0.700000
Epoch 545, CIFAR-10 Batch 2:  loss: 0.760369
accuracy: 0.700000
Epoch 545, CIFAR-10 Batch 3:  loss: 0.796547
accuracy: 0.775000
Epoch 545, CIFAR-10 Batch 4:  loss: 1.149613
accuracy: 0.550000
Epoch 545, CIFAR-10 Batch 5:  loss: 1.024649
accuracy: 0.750000
Epoch 546, CIFAR-10 Batch 1:  loss: 0.815523
accuracy: 0.675000
Epoch 546, CIFAR-10 Batch 2:  loss: 0.794968
accuracy: 0.700000
Epoch 546, CIFAR-10 Batch 3:  loss: 0.807720
accuracy: 0.775000
Epoch 546, CIFAR-10 Batch 4:  loss: 1.133660
accuracy: 0.550000
Epoch 546, CIFAR-10 Batch 5:  loss: 1.016125
accuracy: 0.675000
Epoch 547, CIFAR-10 Batch 1:  loss: 0.825026
accuracy: 0.700000
Epoch 547, CIFAR-10 Batch 2:  loss: 0.831394
accuracy: 0.650000
Epoch 547, CIFAR-10 Batch 3:  loss: 0.856039
accuracy: 0.725000
Epoch 547, CIFAR-10 Batch 4:  loss: 1.146330
accuracy: 0.625000
Epoch 547, CIFAR-10 Batch 5:  loss: 1.028657
accuracy: 0.675000
Epoch 548, CIFAR-10 Batch 1:  loss: 0.813194
accuracy: 0.725000
Epoch 548, CIFAR-10 Batch 2:  loss: 0.832539
accuracy: 0.650000
Epoch 548, CIFAR-10 Batch 3:  loss: 0.859818
accuracy: 0.750000
Epoch 548, CIFAR-10 Batch 4:  loss: 1.159390
accuracy: 0.625000
Epoch 548, CIFAR-10 Batch 5:  loss: 1.014300
accuracy: 0.700000
Epoch 549, CIFAR-10 Batch 1:  loss: 0.819918
accuracy: 0.775000
Epoch 549, CIFAR-10 Batch 2:  loss: 0.789410
accuracy: 0.650000
Epoch 549, CIFAR-10 Batch 3:  loss: 0.858132
accuracy: 0.750000
Epoch 549, CIFAR-10 Batch 4:  loss: 1.107262
accuracy: 0.650000
Epoch 549, CIFAR-10 Batch 5:  loss: 1.083979
accuracy: 0.625000
Epoch 550, CIFAR-10 Batch 1:  loss: 0.819809
accuracy: 0.725000
Epoch 550, CIFAR-10 Batch 2:  loss: 0.777047
accuracy: 0.700000
Epoch 550, CIFAR-10 Batch 3:  loss: 0.843537
accuracy: 0.750000
Epoch 550, CIFAR-10 Batch 4:  loss: 1.122069
accuracy: 0.550000
Epoch 550, CIFAR-10 Batch 5:  loss: 1.049120
accuracy: 0.675000
Epoch 551, CIFAR-10 Batch 1:  loss: 0.811482
accuracy: 0.700000
Epoch 551, CIFAR-10 Batch 2:  loss: 0.794183
accuracy: 0.650000
Epoch 551, CIFAR-10 Batch 3:  loss: 0.837195
accuracy: 0.750000
Epoch 551, CIFAR-10 Batch 4:  loss: 1.121085
accuracy: 0.600000
Epoch 551, CIFAR-10 Batch 5:  loss: 1.032446
accuracy: 0.700000
Epoch 552, CIFAR-10 Batch 1:  loss: 0.820862
accuracy: 0.700000
Epoch 552, CIFAR-10 Batch 2:  loss: 0.769467
accuracy: 0.675000
Epoch 552, CIFAR-10 Batch 3:  loss: 0.811722
accuracy: 0.775000
Epoch 552, CIFAR-10 Batch 4:  loss: 1.104412
accuracy: 0.625000
Epoch 552, CIFAR-10 Batch 5:  loss: 1.028451
accuracy: 0.700000
Epoch 553, CIFAR-10 Batch 1:  loss: 0.834857
accuracy: 0.725000
Epoch 553, CIFAR-10 Batch 2:  loss: 0.792056
accuracy: 0.725000
Epoch 553, CIFAR-10 Batch 3:  loss: 0.838060
accuracy: 0.825000
Epoch 553, CIFAR-10 Batch 4:  loss: 1.150695
accuracy: 0.600000
Epoch 553, CIFAR-10 Batch 5:  loss: 1.063900
accuracy: 0.725000
Epoch 554, CIFAR-10 Batch 1:  loss: 0.809847
accuracy: 0.750000
Epoch 554, CIFAR-10 Batch 2:  loss: 0.775711
accuracy: 0.700000
Epoch 554, CIFAR-10 Batch 3:  loss: 0.869350
accuracy: 0.725000
Epoch 554, CIFAR-10 Batch 4:  loss: 1.133893
accuracy: 0.650000
Epoch 554, CIFAR-10 Batch 5:  loss: 1.046803
accuracy: 0.675000
Epoch 555, CIFAR-10 Batch 1:  loss: 0.811001
accuracy: 0.750000
Epoch 555, CIFAR-10 Batch 2:  loss: 0.787212
accuracy: 0.700000
Epoch 555, CIFAR-10 Batch 3:  loss: 0.836913
accuracy: 0.750000
Epoch 555, CIFAR-10 Batch 4:  loss: 1.133147
accuracy: 0.600000
Epoch 555, CIFAR-10 Batch 5:  loss: 0.991199
accuracy: 0.675000
Epoch 556, CIFAR-10 Batch 1:  loss: 0.813760
accuracy: 0.750000
Epoch 556, CIFAR-10 Batch 2:  loss: 0.739459
accuracy: 0.700000
Epoch 556, CIFAR-10 Batch 3:  loss: 0.801654
accuracy: 0.825000
Epoch 556, CIFAR-10 Batch 4:  loss: 1.194154
accuracy: 0.625000
Epoch 556, CIFAR-10 Batch 5:  loss: 1.026828
accuracy: 0.700000
Epoch 557, CIFAR-10 Batch 1:  loss: 0.800583
accuracy: 0.775000
Epoch 557, CIFAR-10 Batch 2:  loss: 0.748474
accuracy: 0.725000
Epoch 557, CIFAR-10 Batch 3:  loss: 0.821406
accuracy: 0.750000
Epoch 557, CIFAR-10 Batch 4:  loss: 1.125224
accuracy: 0.600000
Epoch 557, CIFAR-10 Batch 5:  loss: 1.017700
accuracy: 0.675000
Epoch 558, CIFAR-10 Batch 1:  loss: 0.807724
accuracy: 0.775000
Epoch 558, CIFAR-10 Batch 2:  loss: 0.751409
accuracy: 0.700000
Epoch 558, CIFAR-10 Batch 3:  loss: 0.872440
accuracy: 0.700000
Epoch 558, CIFAR-10 Batch 4:  loss: 1.155271
accuracy: 0.600000
Epoch 558, CIFAR-10 Batch 5:  loss: 1.046422
accuracy: 0.700000
Epoch 559, CIFAR-10 Batch 1:  loss: 0.851547
accuracy: 0.725000
Epoch 559, CIFAR-10 Batch 2:  loss: 0.771829
accuracy: 0.700000
Epoch 559, CIFAR-10 Batch 3:  loss: 0.875716
accuracy: 0.750000
Epoch 559, CIFAR-10 Batch 4:  loss: 1.124692
accuracy: 0.575000
Epoch 559, CIFAR-10 Batch 5:  loss: 1.026718
accuracy: 0.650000
Epoch 560, CIFAR-10 Batch 1:  loss: 0.825970
accuracy: 0.700000
Epoch 560, CIFAR-10 Batch 2:  loss: 0.767446
accuracy: 0.700000
Epoch 560, CIFAR-10 Batch 3:  loss: 0.850191
accuracy: 0.775000
Epoch 560, CIFAR-10 Batch 4:  loss: 1.209508
accuracy: 0.550000
Epoch 560, CIFAR-10 Batch 5:  loss: 1.039554
accuracy: 0.725000
Epoch 561, CIFAR-10 Batch 1:  loss: 0.814833
accuracy: 0.750000
Epoch 561, CIFAR-10 Batch 2:  loss: 0.752685
accuracy: 0.700000
Epoch 561, CIFAR-10 Batch 3:  loss: 0.773946
accuracy: 0.800000
Epoch 561, CIFAR-10 Batch 4:  loss: 1.186525
accuracy: 0.500000
Epoch 561, CIFAR-10 Batch 5:  loss: 1.027824
accuracy: 0.725000
Epoch 562, CIFAR-10 Batch 1:  loss: 0.827032
accuracy: 0.725000
Epoch 562, CIFAR-10 Batch 2:  loss: 0.770611
accuracy: 0.700000
Epoch 562, CIFAR-10 Batch 3:  loss: 0.855052
accuracy: 0.750000
Epoch 562, CIFAR-10 Batch 4:  loss: 1.233450
accuracy: 0.550000
Epoch 562, CIFAR-10 Batch 5:  loss: 0.979647
accuracy: 0.725000
Epoch 563, CIFAR-10 Batch 1:  loss: 0.833318
accuracy: 0.725000
Epoch 563, CIFAR-10 Batch 2:  loss: 0.789161
accuracy: 0.700000
Epoch 563, CIFAR-10 Batch 3:  loss: 0.779137
accuracy: 0.800000
Epoch 563, CIFAR-10 Batch 4:  loss: 1.160740
accuracy: 0.550000
Epoch 563, CIFAR-10 Batch 5:  loss: 0.975431
accuracy: 0.725000
Epoch 564, CIFAR-10 Batch 1:  loss: 0.831394
accuracy: 0.725000
Epoch 564, CIFAR-10 Batch 2:  loss: 0.757735
accuracy: 0.750000
Epoch 564, CIFAR-10 Batch 3:  loss: 0.799811
accuracy: 0.775000
Epoch 564, CIFAR-10 Batch 4:  loss: 1.142909
accuracy: 0.575000
Epoch 564, CIFAR-10 Batch 5:  loss: 1.029954
accuracy: 0.675000
Epoch 565, CIFAR-10 Batch 1:  loss: 0.836507
accuracy: 0.750000
Epoch 565, CIFAR-10 Batch 2:  loss: 0.784062
accuracy: 0.725000
Epoch 565, CIFAR-10 Batch 3:  loss: 0.827789
accuracy: 0.700000
Epoch 565, CIFAR-10 Batch 4:  loss: 1.162683
accuracy: 0.575000
Epoch 565, CIFAR-10 Batch 5:  loss: 0.972901
accuracy: 0.700000
Epoch 566, CIFAR-10 Batch 1:  loss: 0.838164
accuracy: 0.700000
Epoch 566, CIFAR-10 Batch 2:  loss: 0.771455
accuracy: 0.725000
Epoch 566, CIFAR-10 Batch 3:  loss: 0.788257
accuracy: 0.775000
Epoch 566, CIFAR-10 Batch 4:  loss: 1.173381
accuracy: 0.575000
Epoch 566, CIFAR-10 Batch 5:  loss: 1.022897
accuracy: 0.675000
Epoch 567, CIFAR-10 Batch 1:  loss: 1.011724
accuracy: 0.675000
Epoch 567, CIFAR-10 Batch 2:  loss: 0.766373
accuracy: 0.750000
Epoch 567, CIFAR-10 Batch 3:  loss: 0.867907
accuracy: 0.750000
Epoch 567, CIFAR-10 Batch 4:  loss: 1.205695
accuracy: 0.550000
Epoch 567, CIFAR-10 Batch 5:  loss: 1.041415
accuracy: 0.650000
Epoch 568, CIFAR-10 Batch 1:  loss: 0.845244
accuracy: 0.750000
Epoch 568, CIFAR-10 Batch 2:  loss: 0.781921
accuracy: 0.675000
Epoch 568, CIFAR-10 Batch 3:  loss: 0.820281
accuracy: 0.750000
Epoch 568, CIFAR-10 Batch 4:  loss: 1.152732
accuracy: 0.600000
Epoch 568, CIFAR-10 Batch 5:  loss: 1.027519
accuracy: 0.700000
Epoch 569, CIFAR-10 Batch 1:  loss: 0.856035
accuracy: 0.700000
Epoch 569, CIFAR-10 Batch 2:  loss: 0.755832
accuracy: 0.700000
Epoch 569, CIFAR-10 Batch 3:  loss: 0.811038
accuracy: 0.800000
Epoch 569, CIFAR-10 Batch 4:  loss: 1.192915
accuracy: 0.550000
Epoch 569, CIFAR-10 Batch 5:  loss: 1.065533
accuracy: 0.650000
Epoch 570, CIFAR-10 Batch 1:  loss: 0.812561
accuracy: 0.750000
Epoch 570, CIFAR-10 Batch 2:  loss: 0.773686
accuracy: 0.700000
Epoch 570, CIFAR-10 Batch 3:  loss: 0.838074
accuracy: 0.700000
Epoch 570, CIFAR-10 Batch 4:  loss: 1.161808
accuracy: 0.625000
Epoch 570, CIFAR-10 Batch 5:  loss: 1.046293
accuracy: 0.675000
Epoch 571, CIFAR-10 Batch 1:  loss: 0.841078
accuracy: 0.700000
Epoch 571, CIFAR-10 Batch 2:  loss: 0.777188
accuracy: 0.725000
Epoch 571, CIFAR-10 Batch 3:  loss: 0.802890
accuracy: 0.800000
Epoch 571, CIFAR-10 Batch 4:  loss: 1.191046
accuracy: 0.625000
Epoch 571, CIFAR-10 Batch 5:  loss: 1.036381
accuracy: 0.675000
Epoch 572, CIFAR-10 Batch 1:  loss: 0.827103
accuracy: 0.725000
Epoch 572, CIFAR-10 Batch 2:  loss: 0.763711
accuracy: 0.775000
Epoch 572, CIFAR-10 Batch 3:  loss: 0.795322
accuracy: 0.800000
Epoch 572, CIFAR-10 Batch 4:  loss: 1.159105
accuracy: 0.525000
Epoch 572, CIFAR-10 Batch 5:  loss: 0.996045
accuracy: 0.675000
Epoch 573, CIFAR-10 Batch 1:  loss: 0.842806
accuracy: 0.675000
Epoch 573, CIFAR-10 Batch 2:  loss: 0.778195
accuracy: 0.700000
Epoch 573, CIFAR-10 Batch 3:  loss: 0.820058
accuracy: 0.750000
Epoch 573, CIFAR-10 Batch 4:  loss: 1.192546
accuracy: 0.600000
Epoch 573, CIFAR-10 Batch 5:  loss: 0.992307
accuracy: 0.750000
Epoch 574, CIFAR-10 Batch 1:  loss: 0.828676
accuracy: 0.725000
Epoch 574, CIFAR-10 Batch 2:  loss: 0.772088
accuracy: 0.725000
Epoch 574, CIFAR-10 Batch 3:  loss: 0.786988
accuracy: 0.825000
Epoch 574, CIFAR-10 Batch 4:  loss: 1.221161
accuracy: 0.525000
Epoch 574, CIFAR-10 Batch 5:  loss: 1.017422
accuracy: 0.700000
Epoch 575, CIFAR-10 Batch 1:  loss: 0.839974
accuracy: 0.700000
Epoch 575, CIFAR-10 Batch 2:  loss: 0.813412
accuracy: 0.725000
Epoch 575, CIFAR-10 Batch 3:  loss: 0.802841
accuracy: 0.750000
Epoch 575, CIFAR-10 Batch 4:  loss: 1.208338
accuracy: 0.525000
Epoch 575, CIFAR-10 Batch 5:  loss: 1.051500
accuracy: 0.650000
Epoch 576, CIFAR-10 Batch 1:  loss: 0.865737
accuracy: 0.675000
Epoch 576, CIFAR-10 Batch 2:  loss: 0.749048
accuracy: 0.725000
Epoch 576, CIFAR-10 Batch 3:  loss: 0.867580
accuracy: 0.775000
Epoch 576, CIFAR-10 Batch 4:  loss: 1.171333
accuracy: 0.550000
Epoch 576, CIFAR-10 Batch 5:  loss: 1.018536
accuracy: 0.700000
Epoch 577, CIFAR-10 Batch 1:  loss: 0.835928
accuracy: 0.750000
Epoch 577, CIFAR-10 Batch 2:  loss: 0.754973
accuracy: 0.725000
Epoch 577, CIFAR-10 Batch 3:  loss: 0.824994
accuracy: 0.775000
Epoch 577, CIFAR-10 Batch 4:  loss: 1.158178
accuracy: 0.550000
Epoch 577, CIFAR-10 Batch 5:  loss: 1.021966
accuracy: 0.675000
Epoch 578, CIFAR-10 Batch 1:  loss: 0.846491
accuracy: 0.725000
Epoch 578, CIFAR-10 Batch 2:  loss: 0.777997
accuracy: 0.725000
Epoch 578, CIFAR-10 Batch 3:  loss: 0.793023
accuracy: 0.775000
Epoch 578, CIFAR-10 Batch 4:  loss: 1.175668
accuracy: 0.525000
Epoch 578, CIFAR-10 Batch 5:  loss: 1.040284
accuracy: 0.700000
Epoch 579, CIFAR-10 Batch 1:  loss: 0.843309
accuracy: 0.725000
Epoch 579, CIFAR-10 Batch 2:  loss: 0.776977
accuracy: 0.675000
Epoch 579, CIFAR-10 Batch 3:  loss: 0.835927
accuracy: 0.775000
Epoch 579, CIFAR-10 Batch 4:  loss: 1.184276
accuracy: 0.550000
Epoch 579, CIFAR-10 Batch 5:  loss: 1.016446
accuracy: 0.725000
Epoch 580, CIFAR-10 Batch 1:  loss: 0.854263
accuracy: 0.675000
Epoch 580, CIFAR-10 Batch 2:  loss: 0.786000
accuracy: 0.675000
Epoch 580, CIFAR-10 Batch 3:  loss: 0.800576
accuracy: 0.800000
Epoch 580, CIFAR-10 Batch 4:  loss: 1.174719
accuracy: 0.600000
Epoch 580, CIFAR-10 Batch 5:  loss: 1.022313
accuracy: 0.700000
Epoch 581, CIFAR-10 Batch 1:  loss: 0.845414
accuracy: 0.725000
Epoch 581, CIFAR-10 Batch 2:  loss: 0.793199
accuracy: 0.700000
Epoch 581, CIFAR-10 Batch 3:  loss: 0.811383
accuracy: 0.800000
Epoch 581, CIFAR-10 Batch 4:  loss: 1.151683
accuracy: 0.575000
Epoch 581, CIFAR-10 Batch 5:  loss: 0.998523
accuracy: 0.700000
Epoch 582, CIFAR-10 Batch 1:  loss: 0.847997
accuracy: 0.675000
Epoch 582, CIFAR-10 Batch 2:  loss: 0.764361
accuracy: 0.725000
Epoch 582, CIFAR-10 Batch 3:  loss: 0.846513
accuracy: 0.750000
Epoch 582, CIFAR-10 Batch 4:  loss: 1.224207
accuracy: 0.525000
Epoch 582, CIFAR-10 Batch 5:  loss: 1.028827
accuracy: 0.675000
Epoch 583, CIFAR-10 Batch 1:  loss: 0.853987
accuracy: 0.700000
Epoch 583, CIFAR-10 Batch 2:  loss: 0.786024
accuracy: 0.750000
Epoch 583, CIFAR-10 Batch 3:  loss: 0.853894
accuracy: 0.775000
Epoch 583, CIFAR-10 Batch 4:  loss: 1.196823
accuracy: 0.575000
Epoch 583, CIFAR-10 Batch 5:  loss: 1.024993
accuracy: 0.750000
Epoch 584, CIFAR-10 Batch 1:  loss: 0.864650
accuracy: 0.675000
Epoch 584, CIFAR-10 Batch 2:  loss: 0.788488
accuracy: 0.700000
Epoch 584, CIFAR-10 Batch 3:  loss: 0.836808
accuracy: 0.700000
Epoch 584, CIFAR-10 Batch 4:  loss: 1.216931
accuracy: 0.525000
Epoch 584, CIFAR-10 Batch 5:  loss: 1.008282
accuracy: 0.750000
Epoch 585, CIFAR-10 Batch 1:  loss: 0.858826
accuracy: 0.675000
Epoch 585, CIFAR-10 Batch 2:  loss: 0.777636
accuracy: 0.700000
Epoch 585, CIFAR-10 Batch 3:  loss: 0.849322
accuracy: 0.725000
Epoch 585, CIFAR-10 Batch 4:  loss: 1.233175
accuracy: 0.525000
Epoch 585, CIFAR-10 Batch 5:  loss: 1.007744
accuracy: 0.650000
Epoch 586, CIFAR-10 Batch 1:  loss: 0.850344
accuracy: 0.700000
Epoch 586, CIFAR-10 Batch 2:  loss: 0.793506
accuracy: 0.725000
Epoch 586, CIFAR-10 Batch 3:  loss: 0.807543
accuracy: 0.750000
Epoch 586, CIFAR-10 Batch 4:  loss: 1.267180
accuracy: 0.525000
Epoch 586, CIFAR-10 Batch 5:  loss: 0.992181
accuracy: 0.725000
Epoch 587, CIFAR-10 Batch 1:  loss: 0.852127
accuracy: 0.650000
Epoch 587, CIFAR-10 Batch 2:  loss: 0.827232
accuracy: 0.675000
Epoch 587, CIFAR-10 Batch 3:  loss: 0.806330
accuracy: 0.775000
Epoch 587, CIFAR-10 Batch 4:  loss: 1.279479
accuracy: 0.475000
Epoch 587, CIFAR-10 Batch 5:  loss: 0.997620
accuracy: 0.675000
Epoch 588, CIFAR-10 Batch 1:  loss: 0.851443
accuracy: 0.725000
Epoch 588, CIFAR-10 Batch 2:  loss: 0.788573
accuracy: 0.700000
Epoch 588, CIFAR-10 Batch 3:  loss: 0.838533
accuracy: 0.775000
Epoch 588, CIFAR-10 Batch 4:  loss: 1.295796
accuracy: 0.500000
Epoch 588, CIFAR-10 Batch 5:  loss: 0.975228
accuracy: 0.750000
Epoch 589, CIFAR-10 Batch 1:  loss: 0.854517
accuracy: 0.725000
Epoch 589, CIFAR-10 Batch 2:  loss: 0.800216
accuracy: 0.725000
Epoch 589, CIFAR-10 Batch 3:  loss: 0.859712
accuracy: 0.750000
Epoch 589, CIFAR-10 Batch 4:  loss: 1.303356
accuracy: 0.450000
Epoch 589, CIFAR-10 Batch 5:  loss: 0.979357
accuracy: 0.675000
Epoch 590, CIFAR-10 Batch 1:  loss: 0.883165
accuracy: 0.700000
Epoch 590, CIFAR-10 Batch 2:  loss: 0.769798
accuracy: 0.725000
Epoch 590, CIFAR-10 Batch 3:  loss: 0.797492
accuracy: 0.825000
Epoch 590, CIFAR-10 Batch 4:  loss: 1.277554
accuracy: 0.500000
Epoch 590, CIFAR-10 Batch 5:  loss: 0.979371
accuracy: 0.700000
Epoch 591, CIFAR-10 Batch 1:  loss: 0.866269
accuracy: 0.675000
Epoch 591, CIFAR-10 Batch 2:  loss: 0.778244
accuracy: 0.700000
Epoch 591, CIFAR-10 Batch 3:  loss: 0.787439
accuracy: 0.800000
Epoch 591, CIFAR-10 Batch 4:  loss: 1.296934
accuracy: 0.475000
Epoch 591, CIFAR-10 Batch 5:  loss: 1.000295
accuracy: 0.700000
Epoch 592, CIFAR-10 Batch 1:  loss: 0.873682
accuracy: 0.675000
Epoch 592, CIFAR-10 Batch 2:  loss: 0.811735
accuracy: 0.650000
Epoch 592, CIFAR-10 Batch 3:  loss: 0.815667
accuracy: 0.800000
Epoch 592, CIFAR-10 Batch 4:  loss: 1.297116
accuracy: 0.500000
Epoch 592, CIFAR-10 Batch 5:  loss: 0.979391
accuracy: 0.675000
Epoch 593, CIFAR-10 Batch 1:  loss: 0.840722
accuracy: 0.700000
Epoch 593, CIFAR-10 Batch 2:  loss: 0.769877
accuracy: 0.725000
Epoch 593, CIFAR-10 Batch 3:  loss: 0.816093
accuracy: 0.800000
Epoch 593, CIFAR-10 Batch 4:  loss: 1.279032
accuracy: 0.500000
Epoch 593, CIFAR-10 Batch 5:  loss: 0.988292
accuracy: 0.750000
Epoch 594, CIFAR-10 Batch 1:  loss: 0.868993
accuracy: 0.700000
Epoch 594, CIFAR-10 Batch 2:  loss: 0.778252
accuracy: 0.725000
Epoch 594, CIFAR-10 Batch 3:  loss: 0.853212
accuracy: 0.750000
Epoch 594, CIFAR-10 Batch 4:  loss: 1.278250
accuracy: 0.500000
Epoch 594, CIFAR-10 Batch 5:  loss: 1.022918
accuracy: 0.700000
Epoch 595, CIFAR-10 Batch 1:  loss: 0.860241
accuracy: 0.725000
Epoch 595, CIFAR-10 Batch 2:  loss: 0.787415
accuracy: 0.700000
Epoch 595, CIFAR-10 Batch 3:  loss: 0.807747
accuracy: 0.725000
Epoch 595, CIFAR-10 Batch 4:  loss: 1.269101
accuracy: 0.550000
Epoch 595, CIFAR-10 Batch 5:  loss: 0.998685
accuracy: 0.725000
Epoch 596, CIFAR-10 Batch 1:  loss: 0.880369
accuracy: 0.675000
Epoch 596, CIFAR-10 Batch 2:  loss: 0.769109
accuracy: 0.725000
Epoch 596, CIFAR-10 Batch 3:  loss: 0.793941
accuracy: 0.800000
Epoch 596, CIFAR-10 Batch 4:  loss: 1.271485
accuracy: 0.550000
Epoch 596, CIFAR-10 Batch 5:  loss: 0.993332
accuracy: 0.700000
Epoch 597, CIFAR-10 Batch 1:  loss: 0.865875
accuracy: 0.700000
Epoch 597, CIFAR-10 Batch 2:  loss: 0.777896
accuracy: 0.725000
Epoch 597, CIFAR-10 Batch 3:  loss: 0.819681
accuracy: 0.775000
Epoch 597, CIFAR-10 Batch 4:  loss: 3.084612
accuracy: 0.500000
Epoch 597, CIFAR-10 Batch 5:  loss: 1.000239
accuracy: 0.675000
Epoch 598, CIFAR-10 Batch 1:  loss: 0.834275
accuracy: 0.725000
Epoch 598, CIFAR-10 Batch 2:  loss: 0.785965
accuracy: 0.700000
Epoch 598, CIFAR-10 Batch 3:  loss: 0.856104
accuracy: 0.650000
Epoch 598, CIFAR-10 Batch 4:  loss: 1.434003
accuracy: 0.525000
Epoch 598, CIFAR-10 Batch 5:  loss: 0.945402
accuracy: 0.750000
Epoch 599, CIFAR-10 Batch 1:  loss: 0.844865
accuracy: 0.675000
Epoch 599, CIFAR-10 Batch 2:  loss: 0.777854
accuracy: 0.700000
Epoch 599, CIFAR-10 Batch 3:  loss: 0.841608
accuracy: 0.750000
Epoch 599, CIFAR-10 Batch 4:  loss: 1.245287
accuracy: 0.475000
Epoch 599, CIFAR-10 Batch 5:  loss: 0.959297
accuracy: 0.700000
Epoch 600, CIFAR-10 Batch 1:  loss: 0.861825
accuracy: 0.725000
Epoch 600, CIFAR-10 Batch 2:  loss: 0.778124
accuracy: 0.700000
Epoch 600, CIFAR-10 Batch 3:  loss: 0.821754
accuracy: 0.775000
Epoch 600, CIFAR-10 Batch 4:  loss: 1.283785
accuracy: 0.500000
Epoch 600, CIFAR-10 Batch 5:  loss: 0.954276
accuracy: 0.675000
Epoch 601, CIFAR-10 Batch 1:  loss: 0.874878
accuracy: 0.625000
Epoch 601, CIFAR-10 Batch 2:  loss: 0.764363
accuracy: 0.700000
Epoch 601, CIFAR-10 Batch 3:  loss: 0.857084
accuracy: 0.700000
Epoch 601, CIFAR-10 Batch 4:  loss: 1.275942
accuracy: 0.500000
Epoch 601, CIFAR-10 Batch 5:  loss: 0.980245
accuracy: 0.675000
Epoch 602, CIFAR-10 Batch 1:  loss: 0.854618
accuracy: 0.675000
Epoch 602, CIFAR-10 Batch 2:  loss: 0.760406
accuracy: 0.775000
Epoch 602, CIFAR-10 Batch 3:  loss: 0.805497
accuracy: 0.775000
Epoch 602, CIFAR-10 Batch 4:  loss: 1.280334
accuracy: 0.475000
Epoch 602, CIFAR-10 Batch 5:  loss: 0.962165
accuracy: 0.700000
Epoch 603, CIFAR-10 Batch 1:  loss: 0.849328
accuracy: 0.700000
Epoch 603, CIFAR-10 Batch 2:  loss: 0.767025
accuracy: 0.800000
Epoch 603, CIFAR-10 Batch 3:  loss: 0.832635
accuracy: 0.750000
Epoch 603, CIFAR-10 Batch 4:  loss: 1.259064
accuracy: 0.500000
Epoch 603, CIFAR-10 Batch 5:  loss: 0.988099
accuracy: 0.725000
Epoch 604, CIFAR-10 Batch 1:  loss: 0.852284
accuracy: 0.675000
Epoch 604, CIFAR-10 Batch 2:  loss: 0.784269
accuracy: 0.700000
Epoch 604, CIFAR-10 Batch 3:  loss: 0.795807
accuracy: 0.775000
Epoch 604, CIFAR-10 Batch 4:  loss: 1.279365
accuracy: 0.500000
Epoch 604, CIFAR-10 Batch 5:  loss: 0.985081
accuracy: 0.675000
Epoch 605, CIFAR-10 Batch 1:  loss: 0.829870
accuracy: 0.650000
Epoch 605, CIFAR-10 Batch 2:  loss: 0.802946
accuracy: 0.725000
Epoch 605, CIFAR-10 Batch 3:  loss: 0.858224
accuracy: 0.725000
Epoch 605, CIFAR-10 Batch 4:  loss: 1.282642
accuracy: 0.475000
Epoch 605, CIFAR-10 Batch 5:  loss: 0.980637
accuracy: 0.700000
Epoch 606, CIFAR-10 Batch 1:  loss: 0.857576
accuracy: 0.675000
Epoch 606, CIFAR-10 Batch 2:  loss: 0.763207
accuracy: 0.725000
Epoch 606, CIFAR-10 Batch 3:  loss: 0.851695
accuracy: 0.725000
Epoch 606, CIFAR-10 Batch 4:  loss: 1.274584
accuracy: 0.575000
Epoch 606, CIFAR-10 Batch 5:  loss: 0.980486
accuracy: 0.700000
Epoch 607, CIFAR-10 Batch 1:  loss: 0.866873
accuracy: 0.700000
Epoch 607, CIFAR-10 Batch 2:  loss: 0.771603
accuracy: 0.725000
Epoch 607, CIFAR-10 Batch 3:  loss: 0.829524
accuracy: 0.775000
Epoch 607, CIFAR-10 Batch 4:  loss: 1.278947
accuracy: 0.550000
Epoch 607, CIFAR-10 Batch 5:  loss: 0.969524
accuracy: 0.700000
Epoch 608, CIFAR-10 Batch 1:  loss: 0.857461
accuracy: 0.725000
Epoch 608, CIFAR-10 Batch 2:  loss: 0.757803
accuracy: 0.725000
Epoch 608, CIFAR-10 Batch 3:  loss: 0.799795
accuracy: 0.750000
Epoch 608, CIFAR-10 Batch 4:  loss: 1.280890
accuracy: 0.550000
Epoch 608, CIFAR-10 Batch 5:  loss: 0.938917
accuracy: 0.700000
Epoch 609, CIFAR-10 Batch 1:  loss: 0.859346
accuracy: 0.725000
Epoch 609, CIFAR-10 Batch 2:  loss: 0.795507
accuracy: 0.700000
Epoch 609, CIFAR-10 Batch 3:  loss: 0.840290
accuracy: 0.750000
Epoch 609, CIFAR-10 Batch 4:  loss: 1.274748
accuracy: 0.550000
Epoch 609, CIFAR-10 Batch 5:  loss: 0.963372
accuracy: 0.675000
Epoch 610, CIFAR-10 Batch 1:  loss: 0.864235
accuracy: 0.700000
Epoch 610, CIFAR-10 Batch 2:  loss: 0.798825
accuracy: 0.700000
Epoch 610, CIFAR-10 Batch 3:  loss: 0.858676
accuracy: 0.750000
Epoch 610, CIFAR-10 Batch 4:  loss: 1.286680
accuracy: 0.525000
Epoch 610, CIFAR-10 Batch 5:  loss: 0.961553
accuracy: 0.675000
Epoch 611, CIFAR-10 Batch 1:  loss: 0.848603
accuracy: 0.750000
Epoch 611, CIFAR-10 Batch 2:  loss: 0.776328
accuracy: 0.750000
Epoch 611, CIFAR-10 Batch 3:  loss: 0.814232
accuracy: 0.800000
Epoch 611, CIFAR-10 Batch 4:  loss: 1.298190
accuracy: 0.500000
Epoch 611, CIFAR-10 Batch 5:  loss: 0.937523
accuracy: 0.650000
Epoch 612, CIFAR-10 Batch 1:  loss: 0.849715
accuracy: 0.725000
Epoch 612, CIFAR-10 Batch 2:  loss: 0.766852
accuracy: 0.700000
Epoch 612, CIFAR-10 Batch 3:  loss: 0.786313
accuracy: 0.775000
Epoch 612, CIFAR-10 Batch 4:  loss: 1.326049
accuracy: 0.525000
Epoch 612, CIFAR-10 Batch 5:  loss: 0.936988
accuracy: 0.725000
Epoch 613, CIFAR-10 Batch 1:  loss: 0.846683
accuracy: 0.750000
Epoch 613, CIFAR-10 Batch 2:  loss: 0.789278
accuracy: 0.750000
Epoch 613, CIFAR-10 Batch 3:  loss: 0.805487
accuracy: 0.775000
Epoch 613, CIFAR-10 Batch 4:  loss: 1.299877
accuracy: 0.525000
Epoch 613, CIFAR-10 Batch 5:  loss: 0.956870
accuracy: 0.650000
Epoch 614, CIFAR-10 Batch 1:  loss: 0.849173
accuracy: 0.675000
Epoch 614, CIFAR-10 Batch 2:  loss: 0.794096
accuracy: 0.675000
Epoch 614, CIFAR-10 Batch 3:  loss: 0.782298
accuracy: 0.750000
Epoch 614, CIFAR-10 Batch 4:  loss: 1.283733
accuracy: 0.500000
Epoch 614, CIFAR-10 Batch 5:  loss: 0.958817
accuracy: 0.675000
Epoch 615, CIFAR-10 Batch 1:  loss: 0.863669
accuracy: 0.675000
Epoch 615, CIFAR-10 Batch 2:  loss: 0.806601
accuracy: 0.750000
Epoch 615, CIFAR-10 Batch 3:  loss: 0.801926
accuracy: 0.750000
Epoch 615, CIFAR-10 Batch 4:  loss: 1.278820
accuracy: 0.550000
Epoch 615, CIFAR-10 Batch 5:  loss: 0.954517
accuracy: 0.650000
Epoch 616, CIFAR-10 Batch 1:  loss: 0.875694
accuracy: 0.675000
Epoch 616, CIFAR-10 Batch 2:  loss: 0.803968
accuracy: 0.700000
Epoch 616, CIFAR-10 Batch 3:  loss: 0.804685
accuracy: 0.750000
Epoch 616, CIFAR-10 Batch 4:  loss: 1.227086
accuracy: 0.525000
Epoch 616, CIFAR-10 Batch 5:  loss: 0.959241
accuracy: 0.625000
Epoch 617, CIFAR-10 Batch 1:  loss: 0.880029
accuracy: 0.625000
Epoch 617, CIFAR-10 Batch 2:  loss: 0.809158
accuracy: 0.675000
Epoch 617, CIFAR-10 Batch 3:  loss: 0.805308
accuracy: 0.775000
Epoch 617, CIFAR-10 Batch 4:  loss: 1.238374
accuracy: 0.525000
Epoch 617, CIFAR-10 Batch 5:  loss: 0.943659
accuracy: 0.700000
Epoch 618, CIFAR-10 Batch 1:  loss: 0.873827
accuracy: 0.675000
Epoch 618, CIFAR-10 Batch 2:  loss: 0.767191
accuracy: 0.700000
Epoch 618, CIFAR-10 Batch 3:  loss: 0.808896
accuracy: 0.750000
Epoch 618, CIFAR-10 Batch 4:  loss: 1.201804
accuracy: 0.600000
Epoch 618, CIFAR-10 Batch 5:  loss: 0.920291
accuracy: 0.675000
Epoch 619, CIFAR-10 Batch 1:  loss: 0.858339
accuracy: 0.675000
Epoch 619, CIFAR-10 Batch 2:  loss: 0.748166
accuracy: 0.700000
Epoch 619, CIFAR-10 Batch 3:  loss: 0.803307
accuracy: 0.775000
Epoch 619, CIFAR-10 Batch 4:  loss: 1.236455
accuracy: 0.550000
Epoch 619, CIFAR-10 Batch 5:  loss: 0.946765
accuracy: 0.650000
Epoch 620, CIFAR-10 Batch 1:  loss: 0.864355
accuracy: 0.675000
Epoch 620, CIFAR-10 Batch 2:  loss: 0.780139
accuracy: 0.725000
Epoch 620, CIFAR-10 Batch 3:  loss: 0.845466
accuracy: 0.750000
Epoch 620, CIFAR-10 Batch 4:  loss: 1.241705
accuracy: 0.550000
Epoch 620, CIFAR-10 Batch 5:  loss: 0.937872
accuracy: 0.675000
Epoch 621, CIFAR-10 Batch 1:  loss: 0.853659
accuracy: 0.725000
Epoch 621, CIFAR-10 Batch 2:  loss: 0.765672
accuracy: 0.700000
Epoch 621, CIFAR-10 Batch 3:  loss: 0.793901
accuracy: 0.825000
Epoch 621, CIFAR-10 Batch 4:  loss: 1.239651
accuracy: 0.525000
Epoch 621, CIFAR-10 Batch 5:  loss: 0.949064
accuracy: 0.650000
Epoch 622, CIFAR-10 Batch 1:  loss: 0.855469
accuracy: 0.675000
Epoch 622, CIFAR-10 Batch 2:  loss: 0.781232
accuracy: 0.675000
Epoch 622, CIFAR-10 Batch 3:  loss: 0.782759
accuracy: 0.825000
Epoch 622, CIFAR-10 Batch 4:  loss: 1.240349
accuracy: 0.500000
Epoch 622, CIFAR-10 Batch 5:  loss: 0.973178
accuracy: 0.700000
Epoch 623, CIFAR-10 Batch 1:  loss: 0.866989
accuracy: 0.675000
Epoch 623, CIFAR-10 Batch 2:  loss: 0.778741
accuracy: 0.725000
Epoch 623, CIFAR-10 Batch 3:  loss: 0.783067
accuracy: 0.825000
Epoch 623, CIFAR-10 Batch 4:  loss: 1.191186
accuracy: 0.575000
Epoch 623, CIFAR-10 Batch 5:  loss: 1.000755
accuracy: 0.650000
Epoch 624, CIFAR-10 Batch 1:  loss: 0.866499
accuracy: 0.700000
Epoch 624, CIFAR-10 Batch 2:  loss: 0.773363
accuracy: 0.725000
Epoch 624, CIFAR-10 Batch 3:  loss: 0.770168
accuracy: 0.775000
Epoch 624, CIFAR-10 Batch 4:  loss: 1.225522
accuracy: 0.625000
Epoch 624, CIFAR-10 Batch 5:  loss: 0.962703
accuracy: 0.675000
Epoch 625, CIFAR-10 Batch 1:  loss: 0.849597
accuracy: 0.700000
Epoch 625, CIFAR-10 Batch 2:  loss: 0.777051
accuracy: 0.725000
Epoch 625, CIFAR-10 Batch 3:  loss: 0.832900
accuracy: 0.725000
Epoch 625, CIFAR-10 Batch 4:  loss: 1.223877
accuracy: 0.500000
Epoch 625, CIFAR-10 Batch 5:  loss: 0.955379
accuracy: 0.725000
Epoch 626, CIFAR-10 Batch 1:  loss: 0.868296
accuracy: 0.650000
Epoch 626, CIFAR-10 Batch 2:  loss: 0.771060
accuracy: 0.775000
Epoch 626, CIFAR-10 Batch 3:  loss: 0.801111
accuracy: 0.775000
Epoch 626, CIFAR-10 Batch 4:  loss: 1.229125
accuracy: 0.575000
Epoch 626, CIFAR-10 Batch 5:  loss: 0.955025
accuracy: 0.700000
Epoch 627, CIFAR-10 Batch 1:  loss: 0.867532
accuracy: 0.650000
Epoch 627, CIFAR-10 Batch 2:  loss: 0.785752
accuracy: 0.775000
Epoch 627, CIFAR-10 Batch 3:  loss: 0.817951
accuracy: 0.825000
Epoch 627, CIFAR-10 Batch 4:  loss: 1.192093
accuracy: 0.600000
Epoch 627, CIFAR-10 Batch 5:  loss: 0.946514
accuracy: 0.725000
Epoch 628, CIFAR-10 Batch 1:  loss: 0.880354
accuracy: 0.650000
Epoch 628, CIFAR-10 Batch 2:  loss: 0.754920
accuracy: 0.725000
Epoch 628, CIFAR-10 Batch 3:  loss: 0.787855
accuracy: 0.800000
Epoch 628, CIFAR-10 Batch 4:  loss: 1.206938
accuracy: 0.550000
Epoch 628, CIFAR-10 Batch 5:  loss: 0.931954
accuracy: 0.725000
Epoch 629, CIFAR-10 Batch 1:  loss: 0.877015
accuracy: 0.725000
Epoch 629, CIFAR-10 Batch 2:  loss: 0.769932
accuracy: 0.725000
Epoch 629, CIFAR-10 Batch 3:  loss: 0.778469
accuracy: 0.825000
Epoch 629, CIFAR-10 Batch 4:  loss: 1.204305
accuracy: 0.575000
Epoch 629, CIFAR-10 Batch 5:  loss: 0.958849
accuracy: 0.700000
Epoch 630, CIFAR-10 Batch 1:  loss: 0.860193
accuracy: 0.650000
Epoch 630, CIFAR-10 Batch 2:  loss: 0.765821
accuracy: 0.750000
Epoch 630, CIFAR-10 Batch 3:  loss: 0.827221
accuracy: 0.775000
Epoch 630, CIFAR-10 Batch 4:  loss: 1.196990
accuracy: 0.575000
Epoch 630, CIFAR-10 Batch 5:  loss: 0.951380
accuracy: 0.725000
Epoch 631, CIFAR-10 Batch 1:  loss: 0.893909
accuracy: 0.650000
Epoch 631, CIFAR-10 Batch 2:  loss: 0.806674
accuracy: 0.725000
Epoch 631, CIFAR-10 Batch 3:  loss: 0.816825
accuracy: 0.750000
Epoch 631, CIFAR-10 Batch 4:  loss: 1.222701
accuracy: 0.600000
Epoch 631, CIFAR-10 Batch 5:  loss: 0.947144
accuracy: 0.675000
Epoch 632, CIFAR-10 Batch 1:  loss: 0.870908
accuracy: 0.675000
Epoch 632, CIFAR-10 Batch 2:  loss: 0.785031
accuracy: 0.750000
Epoch 632, CIFAR-10 Batch 3:  loss: 0.782951
accuracy: 0.775000
Epoch 632, CIFAR-10 Batch 4:  loss: 1.226181
accuracy: 0.575000
Epoch 632, CIFAR-10 Batch 5:  loss: 0.943234
accuracy: 0.725000
Epoch 633, CIFAR-10 Batch 1:  loss: 0.863385
accuracy: 0.675000
Epoch 633, CIFAR-10 Batch 2:  loss: 0.795381
accuracy: 0.725000
Epoch 633, CIFAR-10 Batch 3:  loss: 0.812053
accuracy: 0.825000
Epoch 633, CIFAR-10 Batch 4:  loss: 1.199014
accuracy: 0.575000
Epoch 633, CIFAR-10 Batch 5:  loss: 0.961907
accuracy: 0.700000
Epoch 634, CIFAR-10 Batch 1:  loss: 0.847915
accuracy: 0.725000
Epoch 634, CIFAR-10 Batch 2:  loss: 0.794700
accuracy: 0.700000
Epoch 634, CIFAR-10 Batch 3:  loss: 0.774759
accuracy: 0.850000
Epoch 634, CIFAR-10 Batch 4:  loss: 1.238991
accuracy: 0.575000
Epoch 634, CIFAR-10 Batch 5:  loss: 0.959233
accuracy: 0.700000
Epoch 635, CIFAR-10 Batch 1:  loss: 0.863831
accuracy: 0.675000
Epoch 635, CIFAR-10 Batch 2:  loss: 0.798296
accuracy: 0.775000
Epoch 635, CIFAR-10 Batch 3:  loss: 0.795727
accuracy: 0.750000
Epoch 635, CIFAR-10 Batch 4:  loss: 1.202857
accuracy: 0.600000
Epoch 635, CIFAR-10 Batch 5:  loss: 0.932801
accuracy: 0.725000
Epoch 636, CIFAR-10 Batch 1:  loss: 0.844815
accuracy: 0.700000
Epoch 636, CIFAR-10 Batch 2:  loss: 0.771135
accuracy: 0.700000
Epoch 636, CIFAR-10 Batch 3:  loss: 0.770063
accuracy: 0.850000
Epoch 636, CIFAR-10 Batch 4:  loss: 1.181889
accuracy: 0.600000
Epoch 636, CIFAR-10 Batch 5:  loss: 0.955311
accuracy: 0.675000
Epoch 637, CIFAR-10 Batch 1:  loss: 0.858540
accuracy: 0.700000
Epoch 637, CIFAR-10 Batch 2:  loss: 0.772065
accuracy: 0.700000
Epoch 637, CIFAR-10 Batch 3:  loss: 0.765837
accuracy: 0.800000
Epoch 637, CIFAR-10 Batch 4:  loss: 1.202876
accuracy: 0.575000
Epoch 637, CIFAR-10 Batch 5:  loss: 0.949510
accuracy: 0.675000
Epoch 638, CIFAR-10 Batch 1:  loss: 0.862066
accuracy: 0.675000
Epoch 638, CIFAR-10 Batch 2:  loss: 0.783148
accuracy: 0.725000
Epoch 638, CIFAR-10 Batch 3:  loss: 0.777678
accuracy: 0.800000
Epoch 638, CIFAR-10 Batch 4:  loss: 1.223687
accuracy: 0.600000
Epoch 638, CIFAR-10 Batch 5:  loss: 0.958728
accuracy: 0.675000
Epoch 639, CIFAR-10 Batch 1:  loss: 0.843115
accuracy: 0.750000
Epoch 639, CIFAR-10 Batch 2:  loss: 0.758358
accuracy: 0.700000
Epoch 639, CIFAR-10 Batch 3:  loss: 0.782629
accuracy: 0.825000
Epoch 639, CIFAR-10 Batch 4:  loss: 1.200114
accuracy: 0.525000
Epoch 639, CIFAR-10 Batch 5:  loss: 0.954118
accuracy: 0.675000
Epoch 640, CIFAR-10 Batch 1:  loss: 0.846226
accuracy: 0.675000
Epoch 640, CIFAR-10 Batch 2:  loss: 0.789927
accuracy: 0.675000
Epoch 640, CIFAR-10 Batch 3:  loss: 0.816831
accuracy: 0.800000
Epoch 640, CIFAR-10 Batch 4:  loss: 1.168507
accuracy: 0.625000
Epoch 640, CIFAR-10 Batch 5:  loss: 0.941702
accuracy: 0.675000
Epoch 641, CIFAR-10 Batch 1:  loss: 0.856130
accuracy: 0.675000
Epoch 641, CIFAR-10 Batch 2:  loss: 0.780428
accuracy: 0.775000
Epoch 641, CIFAR-10 Batch 3:  loss: 0.777546
accuracy: 0.875000
Epoch 641, CIFAR-10 Batch 4:  loss: 1.169210
accuracy: 0.575000
Epoch 641, CIFAR-10 Batch 5:  loss: 0.951895
accuracy: 0.700000
Epoch 642, CIFAR-10 Batch 1:  loss: 0.843263
accuracy: 0.650000
Epoch 642, CIFAR-10 Batch 2:  loss: 0.786144
accuracy: 0.725000
Epoch 642, CIFAR-10 Batch 3:  loss: 0.829702
accuracy: 0.775000
Epoch 642, CIFAR-10 Batch 4:  loss: 1.196009
accuracy: 0.575000
Epoch 642, CIFAR-10 Batch 5:  loss: 0.975275
accuracy: 0.625000
Epoch 643, CIFAR-10 Batch 1:  loss: 0.824977
accuracy: 0.725000
Epoch 643, CIFAR-10 Batch 2:  loss: 0.777636
accuracy: 0.750000
Epoch 643, CIFAR-10 Batch 3:  loss: 0.820230
accuracy: 0.800000
Epoch 643, CIFAR-10 Batch 4:  loss: 1.206901
accuracy: 0.525000
Epoch 643, CIFAR-10 Batch 5:  loss: 0.970396
accuracy: 0.675000
Epoch 644, CIFAR-10 Batch 1:  loss: 0.847496
accuracy: 0.675000
Epoch 644, CIFAR-10 Batch 2:  loss: 0.790752
accuracy: 0.750000
Epoch 644, CIFAR-10 Batch 3:  loss: 0.803695
accuracy: 0.800000
Epoch 644, CIFAR-10 Batch 4:  loss: 1.221582
accuracy: 0.550000
Epoch 644, CIFAR-10 Batch 5:  loss: 0.949760
accuracy: 0.675000
Epoch 645, CIFAR-10 Batch 1:  loss: 0.841443
accuracy: 0.650000
Epoch 645, CIFAR-10 Batch 2:  loss: 0.767899
accuracy: 0.775000
Epoch 645, CIFAR-10 Batch 3:  loss: 0.788594
accuracy: 0.825000
Epoch 645, CIFAR-10 Batch 4:  loss: 1.189571
accuracy: 0.575000
Epoch 645, CIFAR-10 Batch 5:  loss: 0.962951
accuracy: 0.650000
Epoch 646, CIFAR-10 Batch 1:  loss: 0.847073
accuracy: 0.650000
Epoch 646, CIFAR-10 Batch 2:  loss: 0.794748
accuracy: 0.700000
Epoch 646, CIFAR-10 Batch 3:  loss: 0.794661
accuracy: 0.800000
Epoch 646, CIFAR-10 Batch 4:  loss: 1.184984
accuracy: 0.575000
Epoch 646, CIFAR-10 Batch 5:  loss: 0.960467
accuracy: 0.700000
Epoch 647, CIFAR-10 Batch 1:  loss: 0.845033
accuracy: 0.700000
Epoch 647, CIFAR-10 Batch 2:  loss: 0.817392
accuracy: 0.750000
Epoch 647, CIFAR-10 Batch 3:  loss: 0.796884
accuracy: 0.800000
Epoch 647, CIFAR-10 Batch 4:  loss: 1.188857
accuracy: 0.575000
Epoch 647, CIFAR-10 Batch 5:  loss: 0.967405
accuracy: 0.700000
Epoch 648, CIFAR-10 Batch 1:  loss: 0.852897
accuracy: 0.650000
Epoch 648, CIFAR-10 Batch 2:  loss: 0.805007
accuracy: 0.725000
Epoch 648, CIFAR-10 Batch 3:  loss: 0.811203
accuracy: 0.775000
Epoch 648, CIFAR-10 Batch 4:  loss: 1.195244
accuracy: 0.575000
Epoch 648, CIFAR-10 Batch 5:  loss: 0.981210
accuracy: 0.675000
Epoch 649, CIFAR-10 Batch 1:  loss: 0.830069
accuracy: 0.650000
Epoch 649, CIFAR-10 Batch 2:  loss: 0.788927
accuracy: 0.750000
Epoch 649, CIFAR-10 Batch 3:  loss: 0.797406
accuracy: 0.825000
Epoch 649, CIFAR-10 Batch 4:  loss: 1.216758
accuracy: 0.525000
Epoch 649, CIFAR-10 Batch 5:  loss: 0.942313
accuracy: 0.675000
Epoch 650, CIFAR-10 Batch 1:  loss: 0.834288
accuracy: 0.700000
Epoch 650, CIFAR-10 Batch 2:  loss: 0.774540
accuracy: 0.750000
Epoch 650, CIFAR-10 Batch 3:  loss: 0.798791
accuracy: 0.775000
Epoch 650, CIFAR-10 Batch 4:  loss: 1.230615
accuracy: 0.550000
Epoch 650, CIFAR-10 Batch 5:  loss: 0.931339
accuracy: 0.675000
Epoch 651, CIFAR-10 Batch 1:  loss: 0.836591
accuracy: 0.700000
Epoch 651, CIFAR-10 Batch 2:  loss: 0.795287
accuracy: 0.775000
Epoch 651, CIFAR-10 Batch 3:  loss: 0.771516
accuracy: 0.775000
Epoch 651, CIFAR-10 Batch 4:  loss: 1.177585
accuracy: 0.625000
Epoch 651, CIFAR-10 Batch 5:  loss: 0.990726
accuracy: 0.650000
Epoch 652, CIFAR-10 Batch 1:  loss: 0.811693
accuracy: 0.750000
Epoch 652, CIFAR-10 Batch 2:  loss: 0.809752
accuracy: 0.750000
Epoch 652, CIFAR-10 Batch 3:  loss: 0.830972
accuracy: 0.825000
Epoch 652, CIFAR-10 Batch 4:  loss: 1.202235
accuracy: 0.575000
Epoch 652, CIFAR-10 Batch 5:  loss: 0.936078
accuracy: 0.700000
Epoch 653, CIFAR-10 Batch 1:  loss: 0.835262
accuracy: 0.750000
Epoch 653, CIFAR-10 Batch 2:  loss: 0.793939
accuracy: 0.725000
Epoch 653, CIFAR-10 Batch 3:  loss: 0.777964
accuracy: 0.850000
Epoch 653, CIFAR-10 Batch 4:  loss: 1.253618
accuracy: 0.525000
Epoch 653, CIFAR-10 Batch 5:  loss: 0.976934
accuracy: 0.675000
Epoch 654, CIFAR-10 Batch 1:  loss: 0.815155
accuracy: 0.675000
Epoch 654, CIFAR-10 Batch 2:  loss: 0.827108
accuracy: 0.725000
Epoch 654, CIFAR-10 Batch 3:  loss: 0.777442
accuracy: 0.775000
Epoch 654, CIFAR-10 Batch 4:  loss: 1.220902
accuracy: 0.550000
Epoch 654, CIFAR-10 Batch 5:  loss: 0.993349
accuracy: 0.625000
Epoch 655, CIFAR-10 Batch 1:  loss: 0.815294
accuracy: 0.725000
Epoch 655, CIFAR-10 Batch 2:  loss: 0.783211
accuracy: 0.800000
Epoch 655, CIFAR-10 Batch 3:  loss: 0.810515
accuracy: 0.825000
Epoch 655, CIFAR-10 Batch 4:  loss: 1.198551
accuracy: 0.550000
Epoch 655, CIFAR-10 Batch 5:  loss: 0.991635
accuracy: 0.650000
Epoch 656, CIFAR-10 Batch 1:  loss: 0.830960
accuracy: 0.725000
Epoch 656, CIFAR-10 Batch 2:  loss: 0.778252
accuracy: 0.775000
Epoch 656, CIFAR-10 Batch 3:  loss: 0.832796
accuracy: 0.800000
Epoch 656, CIFAR-10 Batch 4:  loss: 1.201317
accuracy: 0.600000
Epoch 656, CIFAR-10 Batch 5:  loss: 1.038157
accuracy: 0.625000
Epoch 657, CIFAR-10 Batch 1:  loss: 0.849753
accuracy: 0.675000
Epoch 657, CIFAR-10 Batch 2:  loss: 0.838483
accuracy: 0.750000
Epoch 657, CIFAR-10 Batch 3:  loss: 0.866019
accuracy: 0.800000
Epoch 657, CIFAR-10 Batch 4:  loss: 1.193832
accuracy: 0.550000
Epoch 657, CIFAR-10 Batch 5:  loss: 1.005030
accuracy: 0.625000
Epoch 658, CIFAR-10 Batch 1:  loss: 0.833094
accuracy: 0.700000
Epoch 658, CIFAR-10 Batch 2:  loss: 0.799686
accuracy: 0.725000
Epoch 658, CIFAR-10 Batch 3:  loss: 0.815675
accuracy: 0.800000
Epoch 658, CIFAR-10 Batch 4:  loss: 1.174638
accuracy: 0.575000
Epoch 658, CIFAR-10 Batch 5:  loss: 1.015607
accuracy: 0.675000
Epoch 659, CIFAR-10 Batch 1:  loss: 0.828119
accuracy: 0.700000
Epoch 659, CIFAR-10 Batch 2:  loss: 0.809698
accuracy: 0.750000
Epoch 659, CIFAR-10 Batch 3:  loss: 0.800334
accuracy: 0.800000
Epoch 659, CIFAR-10 Batch 4:  loss: 1.230809
accuracy: 0.525000
Epoch 659, CIFAR-10 Batch 5:  loss: 0.998204
accuracy: 0.675000
Epoch 660, CIFAR-10 Batch 1:  loss: 0.821684
accuracy: 0.700000
Epoch 660, CIFAR-10 Batch 2:  loss: 0.784097
accuracy: 0.750000
Epoch 660, CIFAR-10 Batch 3:  loss: 0.787396
accuracy: 0.850000
Epoch 660, CIFAR-10 Batch 4:  loss: 1.248499
accuracy: 0.525000
Epoch 660, CIFAR-10 Batch 5:  loss: 1.001727
accuracy: 0.700000
Epoch 661, CIFAR-10 Batch 1:  loss: 0.816673
accuracy: 0.700000
Epoch 661, CIFAR-10 Batch 2:  loss: 0.778646
accuracy: 0.750000
Epoch 661, CIFAR-10 Batch 3:  loss: 0.801360
accuracy: 0.825000
Epoch 661, CIFAR-10 Batch 4:  loss: 1.212237
accuracy: 0.575000
Epoch 661, CIFAR-10 Batch 5:  loss: 0.972926
accuracy: 0.650000
Epoch 662, CIFAR-10 Batch 1:  loss: 0.818458
accuracy: 0.725000
Epoch 662, CIFAR-10 Batch 2:  loss: 0.781255
accuracy: 0.725000
Epoch 662, CIFAR-10 Batch 3:  loss: 0.968052
accuracy: 0.800000
Epoch 662, CIFAR-10 Batch 4:  loss: 1.193336
accuracy: 0.525000
Epoch 662, CIFAR-10 Batch 5:  loss: 0.984839
accuracy: 0.725000
Epoch 663, CIFAR-10 Batch 1:  loss: 0.820685
accuracy: 0.750000
Epoch 663, CIFAR-10 Batch 2:  loss: 0.797894
accuracy: 0.750000
Epoch 663, CIFAR-10 Batch 3:  loss: 1.037655
accuracy: 0.750000
Epoch 663, CIFAR-10 Batch 4:  loss: 1.270942
accuracy: 0.500000
Epoch 663, CIFAR-10 Batch 5:  loss: 0.995143
accuracy: 0.725000
Epoch 664, CIFAR-10 Batch 1:  loss: 0.815192
accuracy: 0.700000
Epoch 664, CIFAR-10 Batch 2:  loss: 0.778473
accuracy: 0.750000
Epoch 664, CIFAR-10 Batch 3:  loss: 1.011868
accuracy: 0.775000
Epoch 664, CIFAR-10 Batch 4:  loss: 1.218348
accuracy: 0.575000
Epoch 664, CIFAR-10 Batch 5:  loss: 0.961873
accuracy: 0.725000
Epoch 665, CIFAR-10 Batch 1:  loss: 0.813279
accuracy: 0.700000
Epoch 665, CIFAR-10 Batch 2:  loss: 0.800623
accuracy: 0.775000
Epoch 665, CIFAR-10 Batch 3:  loss: 0.988982
accuracy: 0.725000
Epoch 665, CIFAR-10 Batch 4:  loss: 1.196151
accuracy: 0.550000
Epoch 665, CIFAR-10 Batch 5:  loss: 1.013808
accuracy: 0.675000
Epoch 666, CIFAR-10 Batch 1:  loss: 0.826869
accuracy: 0.700000
Epoch 666, CIFAR-10 Batch 2:  loss: 0.770692
accuracy: 0.725000
Epoch 666, CIFAR-10 Batch 3:  loss: 0.789273
accuracy: 0.825000
Epoch 666, CIFAR-10 Batch 4:  loss: 1.248169
accuracy: 0.475000
Epoch 666, CIFAR-10 Batch 5:  loss: 1.033799
accuracy: 0.625000
Epoch 667, CIFAR-10 Batch 1:  loss: 0.806626
accuracy: 0.750000
Epoch 667, CIFAR-10 Batch 2:  loss: 0.792875
accuracy: 0.725000
Epoch 667, CIFAR-10 Batch 3:  loss: 0.781827
accuracy: 0.850000
Epoch 667, CIFAR-10 Batch 4:  loss: 1.206016
accuracy: 0.525000
Epoch 667, CIFAR-10 Batch 5:  loss: 0.983090
accuracy: 0.700000
Epoch 668, CIFAR-10 Batch 1:  loss: 0.829081
accuracy: 0.725000
Epoch 668, CIFAR-10 Batch 2:  loss: 0.810087
accuracy: 0.725000
Epoch 668, CIFAR-10 Batch 3:  loss: 0.795424
accuracy: 0.800000
Epoch 668, CIFAR-10 Batch 4:  loss: 1.188476
accuracy: 0.600000
Epoch 668, CIFAR-10 Batch 5:  loss: 1.006885
accuracy: 0.650000
Epoch 669, CIFAR-10 Batch 1:  loss: 0.831696
accuracy: 0.700000
Epoch 669, CIFAR-10 Batch 2:  loss: 0.793971
accuracy: 0.750000
Epoch 669, CIFAR-10 Batch 3:  loss: 0.813778
accuracy: 0.775000
Epoch 669, CIFAR-10 Batch 4:  loss: 1.221419
accuracy: 0.550000
Epoch 669, CIFAR-10 Batch 5:  loss: 1.052502
accuracy: 0.675000
Epoch 670, CIFAR-10 Batch 1:  loss: 0.822777
accuracy: 0.700000
Epoch 670, CIFAR-10 Batch 2:  loss: 0.801037
accuracy: 0.750000
Epoch 670, CIFAR-10 Batch 3:  loss: 0.797244
accuracy: 0.825000
Epoch 670, CIFAR-10 Batch 4:  loss: 1.222592
accuracy: 0.575000
Epoch 670, CIFAR-10 Batch 5:  loss: 1.058464
accuracy: 0.675000
Epoch 671, CIFAR-10 Batch 1:  loss: 0.846008
accuracy: 0.725000
Epoch 671, CIFAR-10 Batch 2:  loss: 0.794112
accuracy: 0.725000
Epoch 671, CIFAR-10 Batch 3:  loss: 0.808358
accuracy: 0.775000
Epoch 671, CIFAR-10 Batch 4:  loss: 1.203393
accuracy: 0.600000
Epoch 671, CIFAR-10 Batch 5:  loss: 1.045657
accuracy: 0.650000
Epoch 672, CIFAR-10 Batch 1:  loss: 0.854049
accuracy: 0.725000
Epoch 672, CIFAR-10 Batch 2:  loss: 0.784876
accuracy: 0.775000
Epoch 672, CIFAR-10 Batch 3:  loss: 0.809794
accuracy: 0.750000
Epoch 672, CIFAR-10 Batch 4:  loss: 1.216353
accuracy: 0.600000
Epoch 672, CIFAR-10 Batch 5:  loss: 0.980992
accuracy: 0.625000
Epoch 673, CIFAR-10 Batch 1:  loss: 0.827207
accuracy: 0.675000
Epoch 673, CIFAR-10 Batch 2:  loss: 0.789860
accuracy: 0.750000
Epoch 673, CIFAR-10 Batch 3:  loss: 0.804949
accuracy: 0.825000
Epoch 673, CIFAR-10 Batch 4:  loss: 1.203771
accuracy: 0.575000
Epoch 673, CIFAR-10 Batch 5:  loss: 1.023325
accuracy: 0.650000
Epoch 674, CIFAR-10 Batch 1:  loss: 0.833002
accuracy: 0.725000
Epoch 674, CIFAR-10 Batch 2:  loss: 0.797289
accuracy: 0.750000
Epoch 674, CIFAR-10 Batch 3:  loss: 0.850211
accuracy: 0.700000
Epoch 674, CIFAR-10 Batch 4:  loss: 1.165018
accuracy: 0.600000
Epoch 674, CIFAR-10 Batch 5:  loss: 1.007357
accuracy: 0.700000
Epoch 675, CIFAR-10 Batch 1:  loss: 0.809689
accuracy: 0.725000
Epoch 675, CIFAR-10 Batch 2:  loss: 0.759351
accuracy: 0.800000
Epoch 675, CIFAR-10 Batch 3:  loss: 0.803924
accuracy: 0.750000
Epoch 675, CIFAR-10 Batch 4:  loss: 1.238718
accuracy: 0.575000
Epoch 675, CIFAR-10 Batch 5:  loss: 1.037785
accuracy: 0.650000
Epoch 676, CIFAR-10 Batch 1:  loss: 0.815632
accuracy: 0.700000
Epoch 676, CIFAR-10 Batch 2:  loss: 0.788733
accuracy: 0.750000
Epoch 676, CIFAR-10 Batch 3:  loss: 0.792013
accuracy: 0.825000
Epoch 676, CIFAR-10 Batch 4:  loss: 1.205317
accuracy: 0.575000
Epoch 676, CIFAR-10 Batch 5:  loss: 0.977781
accuracy: 0.750000
Epoch 677, CIFAR-10 Batch 1:  loss: 0.830266
accuracy: 0.700000
Epoch 677, CIFAR-10 Batch 2:  loss: 0.803778
accuracy: 0.800000
Epoch 677, CIFAR-10 Batch 3:  loss: 0.788010
accuracy: 0.850000
Epoch 677, CIFAR-10 Batch 4:  loss: 1.202888
accuracy: 0.550000
Epoch 677, CIFAR-10 Batch 5:  loss: 1.012683
accuracy: 0.725000
Epoch 678, CIFAR-10 Batch 1:  loss: 0.820073
accuracy: 0.725000
Epoch 678, CIFAR-10 Batch 2:  loss: 0.789153
accuracy: 0.750000
Epoch 678, CIFAR-10 Batch 3:  loss: 0.806232
accuracy: 0.825000
Epoch 678, CIFAR-10 Batch 4:  loss: 1.246674
accuracy: 0.525000
Epoch 678, CIFAR-10 Batch 5:  loss: 1.016991
accuracy: 0.600000
Epoch 679, CIFAR-10 Batch 1:  loss: 0.842528
accuracy: 0.675000
Epoch 679, CIFAR-10 Batch 2:  loss: 0.797872
accuracy: 0.750000
Epoch 679, CIFAR-10 Batch 3:  loss: 0.783481
accuracy: 0.800000
Epoch 679, CIFAR-10 Batch 4:  loss: 1.222622
accuracy: 0.575000
Epoch 679, CIFAR-10 Batch 5:  loss: 1.014241
accuracy: 0.700000
Epoch 680, CIFAR-10 Batch 1:  loss: 0.819118
accuracy: 0.725000
Epoch 680, CIFAR-10 Batch 2:  loss: 0.781910
accuracy: 0.775000
Epoch 680, CIFAR-10 Batch 3:  loss: 0.807160
accuracy: 0.800000
Epoch 680, CIFAR-10 Batch 4:  loss: 1.216732
accuracy: 0.575000
Epoch 680, CIFAR-10 Batch 5:  loss: 1.035227
accuracy: 0.700000
Epoch 681, CIFAR-10 Batch 1:  loss: 0.818038
accuracy: 0.700000
Epoch 681, CIFAR-10 Batch 2:  loss: 0.782714
accuracy: 0.775000
Epoch 681, CIFAR-10 Batch 3:  loss: 0.917594
accuracy: 0.775000
Epoch 681, CIFAR-10 Batch 4:  loss: 1.213694
accuracy: 0.550000
Epoch 681, CIFAR-10 Batch 5:  loss: 1.059862
accuracy: 0.675000
Epoch 682, CIFAR-10 Batch 1:  loss: 0.816402
accuracy: 0.725000
Epoch 682, CIFAR-10 Batch 2:  loss: 0.783561
accuracy: 0.825000
Epoch 682, CIFAR-10 Batch 3:  loss: 0.914649
accuracy: 0.850000
Epoch 682, CIFAR-10 Batch 4:  loss: 1.184887
accuracy: 0.575000
Epoch 682, CIFAR-10 Batch 5:  loss: 1.001158
accuracy: 0.650000
Epoch 683, CIFAR-10 Batch 1:  loss: 0.823604
accuracy: 0.700000
Epoch 683, CIFAR-10 Batch 2:  loss: 0.776219
accuracy: 0.775000
Epoch 683, CIFAR-10 Batch 3:  loss: 0.809039
accuracy: 0.750000
Epoch 683, CIFAR-10 Batch 4:  loss: 1.236745
accuracy: 0.575000
Epoch 683, CIFAR-10 Batch 5:  loss: 1.010317
accuracy: 0.650000
Epoch 684, CIFAR-10 Batch 1:  loss: 0.814969
accuracy: 0.675000
Epoch 684, CIFAR-10 Batch 2:  loss: 0.802089
accuracy: 0.800000
Epoch 684, CIFAR-10 Batch 3:  loss: 0.839392
accuracy: 0.700000
Epoch 684, CIFAR-10 Batch 4:  loss: 1.232508
accuracy: 0.500000
Epoch 684, CIFAR-10 Batch 5:  loss: 1.025008
accuracy: 0.650000
Epoch 685, CIFAR-10 Batch 1:  loss: 0.824757
accuracy: 0.725000
Epoch 685, CIFAR-10 Batch 2:  loss: 0.774142
accuracy: 0.750000
Epoch 685, CIFAR-10 Batch 3:  loss: 0.814268
accuracy: 0.800000
Epoch 685, CIFAR-10 Batch 4:  loss: 1.161677
accuracy: 0.575000
Epoch 685, CIFAR-10 Batch 5:  loss: 1.020623
accuracy: 0.675000
Epoch 686, CIFAR-10 Batch 1:  loss: 0.838598
accuracy: 0.700000
Epoch 686, CIFAR-10 Batch 2:  loss: 0.804864
accuracy: 0.750000
Epoch 686, CIFAR-10 Batch 3:  loss: 0.829078
accuracy: 0.825000
Epoch 686, CIFAR-10 Batch 4:  loss: 1.192867
accuracy: 0.575000
Epoch 686, CIFAR-10 Batch 5:  loss: 1.019765
accuracy: 0.625000
Epoch 687, CIFAR-10 Batch 1:  loss: 0.820365
accuracy: 0.700000
Epoch 687, CIFAR-10 Batch 2:  loss: 0.759432
accuracy: 0.775000
Epoch 687, CIFAR-10 Batch 3:  loss: 0.815841
accuracy: 0.800000
Epoch 687, CIFAR-10 Batch 4:  loss: 1.194560
accuracy: 0.575000
Epoch 687, CIFAR-10 Batch 5:  loss: 0.980218
accuracy: 0.725000
Epoch 688, CIFAR-10 Batch 1:  loss: 0.957178
accuracy: 0.725000
Epoch 688, CIFAR-10 Batch 2:  loss: 0.794567
accuracy: 0.775000
Epoch 688, CIFAR-10 Batch 3:  loss: 0.783996
accuracy: 0.825000
Epoch 688, CIFAR-10 Batch 4:  loss: 1.179973
accuracy: 0.575000
Epoch 688, CIFAR-10 Batch 5:  loss: 1.022602
accuracy: 0.675000
Epoch 689, CIFAR-10 Batch 1:  loss: 0.816691
accuracy: 0.725000
Epoch 689, CIFAR-10 Batch 2:  loss: 0.795955
accuracy: 0.775000
Epoch 689, CIFAR-10 Batch 3:  loss: 0.840665
accuracy: 0.800000
Epoch 689, CIFAR-10 Batch 4:  loss: 1.188455
accuracy: 0.575000
Epoch 689, CIFAR-10 Batch 5:  loss: 0.988213
accuracy: 0.700000
Epoch 690, CIFAR-10 Batch 1:  loss: 0.817591
accuracy: 0.725000
Epoch 690, CIFAR-10 Batch 2:  loss: 0.775569
accuracy: 0.775000
Epoch 690, CIFAR-10 Batch 3:  loss: 0.779252
accuracy: 0.800000
Epoch 690, CIFAR-10 Batch 4:  loss: 1.196472
accuracy: 0.500000
Epoch 690, CIFAR-10 Batch 5:  loss: 0.980322
accuracy: 0.700000
Epoch 691, CIFAR-10 Batch 1:  loss: 0.819453
accuracy: 0.700000
Epoch 691, CIFAR-10 Batch 2:  loss: 0.773780
accuracy: 0.750000
Epoch 691, CIFAR-10 Batch 3:  loss: 0.800104
accuracy: 0.825000
Epoch 691, CIFAR-10 Batch 4:  loss: 1.194533
accuracy: 0.600000
Epoch 691, CIFAR-10 Batch 5:  loss: 1.020685
accuracy: 0.675000
Epoch 692, CIFAR-10 Batch 1:  loss: 0.813924
accuracy: 0.700000
Epoch 692, CIFAR-10 Batch 2:  loss: 0.777319
accuracy: 0.750000
Epoch 692, CIFAR-10 Batch 3:  loss: 0.796800
accuracy: 0.775000
Epoch 692, CIFAR-10 Batch 4:  loss: 1.205186
accuracy: 0.525000
Epoch 692, CIFAR-10 Batch 5:  loss: 1.082008
accuracy: 0.625000
Epoch 693, CIFAR-10 Batch 1:  loss: 0.805263
accuracy: 0.700000
Epoch 693, CIFAR-10 Batch 2:  loss: 0.785526
accuracy: 0.775000
Epoch 693, CIFAR-10 Batch 3:  loss: 0.804776
accuracy: 0.750000
Epoch 693, CIFAR-10 Batch 4:  loss: 1.203598
accuracy: 0.575000
Epoch 693, CIFAR-10 Batch 5:  loss: 1.047559
accuracy: 0.600000
Epoch 694, CIFAR-10 Batch 1:  loss: 0.824273
accuracy: 0.725000
Epoch 694, CIFAR-10 Batch 2:  loss: 0.769012
accuracy: 0.800000
Epoch 694, CIFAR-10 Batch 3:  loss: 0.801073
accuracy: 0.775000
Epoch 694, CIFAR-10 Batch 4:  loss: 1.202507
accuracy: 0.575000
Epoch 694, CIFAR-10 Batch 5:  loss: 1.010639
accuracy: 0.675000
Epoch 695, CIFAR-10 Batch 1:  loss: 0.831649
accuracy: 0.700000
Epoch 695, CIFAR-10 Batch 2:  loss: 0.769837
accuracy: 0.750000
Epoch 695, CIFAR-10 Batch 3:  loss: 0.822306
accuracy: 0.750000
Epoch 695, CIFAR-10 Batch 4:  loss: 1.192595
accuracy: 0.575000
Epoch 695, CIFAR-10 Batch 5:  loss: 1.021279
accuracy: 0.700000
Epoch 696, CIFAR-10 Batch 1:  loss: 0.818214
accuracy: 0.700000
Epoch 696, CIFAR-10 Batch 2:  loss: 0.771909
accuracy: 0.825000
Epoch 696, CIFAR-10 Batch 3:  loss: 0.759654
accuracy: 0.850000
Epoch 696, CIFAR-10 Batch 4:  loss: 1.186640
accuracy: 0.600000
Epoch 696, CIFAR-10 Batch 5:  loss: 1.003814
accuracy: 0.675000
Epoch 697, CIFAR-10 Batch 1:  loss: 0.824715
accuracy: 0.725000
Epoch 697, CIFAR-10 Batch 2:  loss: 0.777951
accuracy: 0.725000
Epoch 697, CIFAR-10 Batch 3:  loss: 0.819661
accuracy: 0.800000
Epoch 697, CIFAR-10 Batch 4:  loss: 1.204960
accuracy: 0.600000
Epoch 697, CIFAR-10 Batch 5:  loss: 1.018341
accuracy: 0.650000
Epoch 698, CIFAR-10 Batch 1:  loss: 0.819864
accuracy: 0.700000
Epoch 698, CIFAR-10 Batch 2:  loss: 0.766787
accuracy: 0.775000
Epoch 698, CIFAR-10 Batch 3:  loss: 0.793602
accuracy: 0.775000
Epoch 698, CIFAR-10 Batch 4:  loss: 1.163328
accuracy: 0.575000
Epoch 698, CIFAR-10 Batch 5:  loss: 0.999113
accuracy: 0.675000
Epoch 699, CIFAR-10 Batch 1:  loss: 0.804211
accuracy: 0.725000
Epoch 699, CIFAR-10 Batch 2:  loss: 0.742069
accuracy: 0.800000
Epoch 699, CIFAR-10 Batch 3:  loss: 0.800225
accuracy: 0.800000
Epoch 699, CIFAR-10 Batch 4:  loss: 1.172745
accuracy: 0.575000
Epoch 699, CIFAR-10 Batch 5:  loss: 1.035326
accuracy: 0.675000
Epoch 700, CIFAR-10 Batch 1:  loss: 0.829242
accuracy: 0.750000
Epoch 700, CIFAR-10 Batch 2:  loss: 0.749507
accuracy: 0.750000
Epoch 700, CIFAR-10 Batch 3:  loss: 0.817005
accuracy: 0.800000
Epoch 700, CIFAR-10 Batch 4:  loss: 1.147224
accuracy: 0.550000
Epoch 700, CIFAR-10 Batch 5:  loss: 1.009447
accuracy: 0.675000
Epoch 701, CIFAR-10 Batch 1:  loss: 0.821965
accuracy: 0.750000
Epoch 701, CIFAR-10 Batch 2:  loss: 0.769832
accuracy: 0.775000
Epoch 701, CIFAR-10 Batch 3:  loss: 0.766157
accuracy: 0.800000
Epoch 701, CIFAR-10 Batch 4:  loss: 1.211508
accuracy: 0.550000
Epoch 701, CIFAR-10 Batch 5:  loss: 1.024955
accuracy: 0.650000
Epoch 702, CIFAR-10 Batch 1:  loss: 0.825591
accuracy: 0.725000
Epoch 702, CIFAR-10 Batch 2:  loss: 0.787089
accuracy: 0.775000
Epoch 702, CIFAR-10 Batch 3:  loss: 0.808131
accuracy: 0.750000
Epoch 702, CIFAR-10 Batch 4:  loss: 1.204257
accuracy: 0.525000
Epoch 702, CIFAR-10 Batch 5:  loss: 1.031512
accuracy: 0.675000
Epoch 703, CIFAR-10 Batch 1:  loss: 0.821585
accuracy: 0.725000
Epoch 703, CIFAR-10 Batch 2:  loss: 0.797889
accuracy: 0.750000
Epoch 703, CIFAR-10 Batch 3:  loss: 0.820297
accuracy: 0.775000
Epoch 703, CIFAR-10 Batch 4:  loss: 1.201208
accuracy: 0.550000
Epoch 703, CIFAR-10 Batch 5:  loss: 1.027966
accuracy: 0.600000
Epoch 704, CIFAR-10 Batch 1:  loss: 0.800114
accuracy: 0.775000
Epoch 704, CIFAR-10 Batch 2:  loss: 0.738528
accuracy: 0.825000
Epoch 704, CIFAR-10 Batch 3:  loss: 0.826078
accuracy: 0.825000
Epoch 704, CIFAR-10 Batch 4:  loss: 1.215475
accuracy: 0.525000
Epoch 704, CIFAR-10 Batch 5:  loss: 1.012723
accuracy: 0.625000
Epoch 705, CIFAR-10 Batch 1:  loss: 0.813727
accuracy: 0.700000
Epoch 705, CIFAR-10 Batch 2:  loss: 0.765865
accuracy: 0.725000
Epoch 705, CIFAR-10 Batch 3:  loss: 0.816363
accuracy: 0.850000
Epoch 705, CIFAR-10 Batch 4:  loss: 1.212964
accuracy: 0.550000
Epoch 705, CIFAR-10 Batch 5:  loss: 1.023647
accuracy: 0.650000
Epoch 706, CIFAR-10 Batch 1:  loss: 0.819517
accuracy: 0.675000
Epoch 706, CIFAR-10 Batch 2:  loss: 0.747724
accuracy: 0.800000
Epoch 706, CIFAR-10 Batch 3:  loss: 0.831372
accuracy: 0.750000
Epoch 706, CIFAR-10 Batch 4:  loss: 1.173780
accuracy: 0.550000
Epoch 706, CIFAR-10 Batch 5:  loss: 0.993026
accuracy: 0.650000
Epoch 707, CIFAR-10 Batch 1:  loss: 0.808928
accuracy: 0.700000
Epoch 707, CIFAR-10 Batch 2:  loss: 0.769943
accuracy: 0.775000
Epoch 707, CIFAR-10 Batch 3:  loss: 0.799172
accuracy: 0.775000
Epoch 707, CIFAR-10 Batch 4:  loss: 1.185941
accuracy: 0.575000
Epoch 707, CIFAR-10 Batch 5:  loss: 0.990323
accuracy: 0.650000
Epoch 708, CIFAR-10 Batch 1:  loss: 0.836365
accuracy: 0.675000
Epoch 708, CIFAR-10 Batch 2:  loss: 0.739566
accuracy: 0.800000
Epoch 708, CIFAR-10 Batch 3:  loss: 0.819933
accuracy: 0.775000
Epoch 708, CIFAR-10 Batch 4:  loss: 1.212783
accuracy: 0.475000
Epoch 708, CIFAR-10 Batch 5:  loss: 1.007431
accuracy: 0.650000
Epoch 709, CIFAR-10 Batch 1:  loss: 0.837869
accuracy: 0.725000
Epoch 709, CIFAR-10 Batch 2:  loss: 0.757298
accuracy: 0.800000
Epoch 709, CIFAR-10 Batch 3:  loss: 0.831289
accuracy: 0.775000
Epoch 709, CIFAR-10 Batch 4:  loss: 1.202094
accuracy: 0.525000
Epoch 709, CIFAR-10 Batch 5:  loss: 1.052224
accuracy: 0.650000
Epoch 710, CIFAR-10 Batch 1:  loss: 0.793076
accuracy: 0.750000
Epoch 710, CIFAR-10 Batch 2:  loss: 0.749660
accuracy: 0.775000
Epoch 710, CIFAR-10 Batch 3:  loss: 0.815197
accuracy: 0.800000
Epoch 710, CIFAR-10 Batch 4:  loss: 1.186248
accuracy: 0.550000
Epoch 710, CIFAR-10 Batch 5:  loss: 0.983354
accuracy: 0.675000
Epoch 711, CIFAR-10 Batch 1:  loss: 0.822669
accuracy: 0.725000
Epoch 711, CIFAR-10 Batch 2:  loss: 0.742027
accuracy: 0.750000
Epoch 711, CIFAR-10 Batch 3:  loss: 0.810106
accuracy: 0.775000
Epoch 711, CIFAR-10 Batch 4:  loss: 1.188664
accuracy: 0.500000
Epoch 711, CIFAR-10 Batch 5:  loss: 0.989776
accuracy: 0.675000
Epoch 712, CIFAR-10 Batch 1:  loss: 0.834453
accuracy: 0.750000
Epoch 712, CIFAR-10 Batch 2:  loss: 0.770491
accuracy: 0.775000
Epoch 712, CIFAR-10 Batch 3:  loss: 0.792499
accuracy: 0.800000
Epoch 712, CIFAR-10 Batch 4:  loss: 1.201412
accuracy: 0.525000
Epoch 712, CIFAR-10 Batch 5:  loss: 0.999220
accuracy: 0.675000
Epoch 713, CIFAR-10 Batch 1:  loss: 0.835555
accuracy: 0.725000
Epoch 713, CIFAR-10 Batch 2:  loss: 0.738876
accuracy: 0.800000
Epoch 713, CIFAR-10 Batch 3:  loss: 0.788218
accuracy: 0.800000
Epoch 713, CIFAR-10 Batch 4:  loss: 1.199739
accuracy: 0.575000
Epoch 713, CIFAR-10 Batch 5:  loss: 1.005139
accuracy: 0.675000
Epoch 714, CIFAR-10 Batch 1:  loss: 0.840441
accuracy: 0.700000
Epoch 714, CIFAR-10 Batch 2:  loss: 0.735266
accuracy: 0.725000
Epoch 714, CIFAR-10 Batch 3:  loss: 0.793769
accuracy: 0.800000
Epoch 714, CIFAR-10 Batch 4:  loss: 1.207930
accuracy: 0.550000
Epoch 714, CIFAR-10 Batch 5:  loss: 1.022755
accuracy: 0.675000
Epoch 715, CIFAR-10 Batch 1:  loss: 0.817928
accuracy: 0.750000
Epoch 715, CIFAR-10 Batch 2:  loss: 0.773611
accuracy: 0.775000
Epoch 715, CIFAR-10 Batch 3:  loss: 0.788683
accuracy: 0.850000
Epoch 715, CIFAR-10 Batch 4:  loss: 1.233991
accuracy: 0.500000
Epoch 715, CIFAR-10 Batch 5:  loss: 1.019716
accuracy: 0.600000
Epoch 716, CIFAR-10 Batch 1:  loss: 0.822838
accuracy: 0.750000
Epoch 716, CIFAR-10 Batch 2:  loss: 0.787531
accuracy: 0.750000
Epoch 716, CIFAR-10 Batch 3:  loss: 0.848811
accuracy: 0.675000
Epoch 716, CIFAR-10 Batch 4:  loss: 1.186523
accuracy: 0.525000
Epoch 716, CIFAR-10 Batch 5:  loss: 1.029182
accuracy: 0.650000
Epoch 717, CIFAR-10 Batch 1:  loss: 0.833571
accuracy: 0.700000
Epoch 717, CIFAR-10 Batch 2:  loss: 0.788283
accuracy: 0.775000
Epoch 717, CIFAR-10 Batch 3:  loss: 0.819546
accuracy: 0.825000
Epoch 717, CIFAR-10 Batch 4:  loss: 1.180146
accuracy: 0.575000
Epoch 717, CIFAR-10 Batch 5:  loss: 1.007175
accuracy: 0.700000
Epoch 718, CIFAR-10 Batch 1:  loss: 0.838420
accuracy: 0.700000
Epoch 718, CIFAR-10 Batch 2:  loss: 0.740075
accuracy: 0.800000
Epoch 718, CIFAR-10 Batch 3:  loss: 0.828461
accuracy: 0.750000
Epoch 718, CIFAR-10 Batch 4:  loss: 1.167686
accuracy: 0.575000
Epoch 718, CIFAR-10 Batch 5:  loss: 1.039595
accuracy: 0.650000
Epoch 719, CIFAR-10 Batch 1:  loss: 0.841973
accuracy: 0.725000
Epoch 719, CIFAR-10 Batch 2:  loss: 0.770687
accuracy: 0.800000
Epoch 719, CIFAR-10 Batch 3:  loss: 0.831983
accuracy: 0.825000
Epoch 719, CIFAR-10 Batch 4:  loss: 1.208765
accuracy: 0.550000
Epoch 719, CIFAR-10 Batch 5:  loss: 1.014348
accuracy: 0.675000
Epoch 720, CIFAR-10 Batch 1:  loss: 0.835855
accuracy: 0.700000
Epoch 720, CIFAR-10 Batch 2:  loss: 0.771353
accuracy: 0.800000
Epoch 720, CIFAR-10 Batch 3:  loss: 0.803178
accuracy: 0.825000
Epoch 720, CIFAR-10 Batch 4:  loss: 1.177248
accuracy: 0.600000
Epoch 720, CIFAR-10 Batch 5:  loss: 1.012959
accuracy: 0.700000
Epoch 721, CIFAR-10 Batch 1:  loss: 0.839574
accuracy: 0.725000
Epoch 721, CIFAR-10 Batch 2:  loss: 0.757677
accuracy: 0.750000
Epoch 721, CIFAR-10 Batch 3:  loss: 0.828043
accuracy: 0.750000
Epoch 721, CIFAR-10 Batch 4:  loss: 1.166687
accuracy: 0.575000
Epoch 721, CIFAR-10 Batch 5:  loss: 1.048024
accuracy: 0.675000
Epoch 722, CIFAR-10 Batch 1:  loss: 0.849152
accuracy: 0.750000
Epoch 722, CIFAR-10 Batch 2:  loss: 0.763223
accuracy: 0.800000
Epoch 722, CIFAR-10 Batch 3:  loss: 0.795517
accuracy: 0.775000
Epoch 722, CIFAR-10 Batch 4:  loss: 1.149821
accuracy: 0.550000
Epoch 722, CIFAR-10 Batch 5:  loss: 1.062846
accuracy: 0.600000
Epoch 723, CIFAR-10 Batch 1:  loss: 0.820078
accuracy: 0.750000
Epoch 723, CIFAR-10 Batch 2:  loss: 0.799763
accuracy: 0.775000
Epoch 723, CIFAR-10 Batch 3:  loss: 0.806111
accuracy: 0.800000
Epoch 723, CIFAR-10 Batch 4:  loss: 1.153791
accuracy: 0.625000
Epoch 723, CIFAR-10 Batch 5:  loss: 1.022944
accuracy: 0.650000
Epoch 724, CIFAR-10 Batch 1:  loss: 0.829891
accuracy: 0.775000
Epoch 724, CIFAR-10 Batch 2:  loss: 0.778070
accuracy: 0.800000
Epoch 724, CIFAR-10 Batch 3:  loss: 0.808070
accuracy: 0.825000
Epoch 724, CIFAR-10 Batch 4:  loss: 1.177298
accuracy: 0.575000
Epoch 724, CIFAR-10 Batch 5:  loss: 1.006532
accuracy: 0.650000
Epoch 725, CIFAR-10 Batch 1:  loss: 0.843404
accuracy: 0.725000
Epoch 725, CIFAR-10 Batch 2:  loss: 0.786688
accuracy: 0.800000
Epoch 725, CIFAR-10 Batch 3:  loss: 0.817554
accuracy: 0.750000
Epoch 725, CIFAR-10 Batch 4:  loss: 1.160549
accuracy: 0.625000
Epoch 725, CIFAR-10 Batch 5:  loss: 1.033916
accuracy: 0.675000
Epoch 726, CIFAR-10 Batch 1:  loss: 0.835237
accuracy: 0.725000
Epoch 726, CIFAR-10 Batch 2:  loss: 0.776747
accuracy: 0.775000
Epoch 726, CIFAR-10 Batch 3:  loss: 0.791047
accuracy: 0.800000
Epoch 726, CIFAR-10 Batch 4:  loss: 1.167615
accuracy: 0.575000
Epoch 726, CIFAR-10 Batch 5:  loss: 1.002505
accuracy: 0.675000
Epoch 727, CIFAR-10 Batch 1:  loss: 0.829671
accuracy: 0.750000
Epoch 727, CIFAR-10 Batch 2:  loss: 0.810946
accuracy: 0.800000
Epoch 727, CIFAR-10 Batch 3:  loss: 0.826132
accuracy: 0.725000
Epoch 727, CIFAR-10 Batch 4:  loss: 1.161756
accuracy: 0.575000
Epoch 727, CIFAR-10 Batch 5:  loss: 1.025767
accuracy: 0.650000
Epoch 728, CIFAR-10 Batch 1:  loss: 0.827405
accuracy: 0.700000
Epoch 728, CIFAR-10 Batch 2:  loss: 0.787611
accuracy: 0.800000
Epoch 728, CIFAR-10 Batch 3:  loss: 0.808489
accuracy: 0.800000
Epoch 728, CIFAR-10 Batch 4:  loss: 1.159649
accuracy: 0.625000
Epoch 728, CIFAR-10 Batch 5:  loss: 1.004403
accuracy: 0.675000
Epoch 729, CIFAR-10 Batch 1:  loss: 0.824270
accuracy: 0.725000
Epoch 729, CIFAR-10 Batch 2:  loss: 0.761283
accuracy: 0.825000
Epoch 729, CIFAR-10 Batch 3:  loss: 0.830198
accuracy: 0.800000
Epoch 729, CIFAR-10 Batch 4:  loss: 1.221520
accuracy: 0.550000
Epoch 729, CIFAR-10 Batch 5:  loss: 0.964316
accuracy: 0.725000
Epoch 730, CIFAR-10 Batch 1:  loss: 0.815862
accuracy: 0.750000
Epoch 730, CIFAR-10 Batch 2:  loss: 0.770062
accuracy: 0.800000
Epoch 730, CIFAR-10 Batch 3:  loss: 0.804399
accuracy: 0.750000
Epoch 730, CIFAR-10 Batch 4:  loss: 1.204772
accuracy: 0.600000
Epoch 730, CIFAR-10 Batch 5:  loss: 1.015445
accuracy: 0.650000
Epoch 731, CIFAR-10 Batch 1:  loss: 0.804937
accuracy: 0.775000
Epoch 731, CIFAR-10 Batch 2:  loss: 0.760526
accuracy: 0.775000
Epoch 731, CIFAR-10 Batch 3:  loss: 0.776873
accuracy: 0.800000
Epoch 731, CIFAR-10 Batch 4:  loss: 1.208924
accuracy: 0.550000
Epoch 731, CIFAR-10 Batch 5:  loss: 1.022722
accuracy: 0.675000
Epoch 732, CIFAR-10 Batch 1:  loss: 0.838478
accuracy: 0.675000
Epoch 732, CIFAR-10 Batch 2:  loss: 0.791184
accuracy: 0.775000
Epoch 732, CIFAR-10 Batch 3:  loss: 0.838622
accuracy: 0.750000
Epoch 732, CIFAR-10 Batch 4:  loss: 1.202168
accuracy: 0.600000
Epoch 732, CIFAR-10 Batch 5:  loss: 1.036837
accuracy: 0.650000
Epoch 733, CIFAR-10 Batch 1:  loss: 0.826381
accuracy: 0.700000
Epoch 733, CIFAR-10 Batch 2:  loss: 0.792609
accuracy: 0.725000
Epoch 733, CIFAR-10 Batch 3:  loss: 0.810136
accuracy: 0.700000
Epoch 733, CIFAR-10 Batch 4:  loss: 1.180146
accuracy: 0.650000
Epoch 733, CIFAR-10 Batch 5:  loss: 1.034852
accuracy: 0.625000
Epoch 734, CIFAR-10 Batch 1:  loss: 0.814768
accuracy: 0.775000
Epoch 734, CIFAR-10 Batch 2:  loss: 0.780460
accuracy: 0.750000
Epoch 734, CIFAR-10 Batch 3:  loss: 0.796114
accuracy: 0.800000
Epoch 734, CIFAR-10 Batch 4:  loss: 1.175592
accuracy: 0.600000
Epoch 734, CIFAR-10 Batch 5:  loss: 1.014428
accuracy: 0.625000
Epoch 735, CIFAR-10 Batch 1:  loss: 0.816228
accuracy: 0.700000
Epoch 735, CIFAR-10 Batch 2:  loss: 0.772202
accuracy: 0.775000
Epoch 735, CIFAR-10 Batch 3:  loss: 0.818130
accuracy: 0.800000
Epoch 735, CIFAR-10 Batch 4:  loss: 1.172369
accuracy: 0.550000
Epoch 735, CIFAR-10 Batch 5:  loss: 1.019943
accuracy: 0.675000
Epoch 736, CIFAR-10 Batch 1:  loss: 0.839398
accuracy: 0.700000
Epoch 736, CIFAR-10 Batch 2:  loss: 0.799853
accuracy: 0.700000
Epoch 736, CIFAR-10 Batch 3:  loss: 0.795201
accuracy: 0.775000
Epoch 736, CIFAR-10 Batch 4:  loss: 1.166813
accuracy: 0.625000
Epoch 736, CIFAR-10 Batch 5:  loss: 1.006795
accuracy: 0.675000
Epoch 737, CIFAR-10 Batch 1:  loss: 0.831246
accuracy: 0.700000
Epoch 737, CIFAR-10 Batch 2:  loss: 0.758385
accuracy: 0.775000
Epoch 737, CIFAR-10 Batch 3:  loss: 0.763709
accuracy: 0.775000
Epoch 737, CIFAR-10 Batch 4:  loss: 1.162860
accuracy: 0.625000
Epoch 737, CIFAR-10 Batch 5:  loss: 1.011125
accuracy: 0.675000
Epoch 738, CIFAR-10 Batch 1:  loss: 0.822069
accuracy: 0.725000
Epoch 738, CIFAR-10 Batch 2:  loss: 0.747044
accuracy: 0.775000
Epoch 738, CIFAR-10 Batch 3:  loss: 0.789414
accuracy: 0.825000
Epoch 738, CIFAR-10 Batch 4:  loss: 1.182038
accuracy: 0.625000
Epoch 738, CIFAR-10 Batch 5:  loss: 1.018086
accuracy: 0.675000
Epoch 739, CIFAR-10 Batch 1:  loss: 0.817294
accuracy: 0.725000
Epoch 739, CIFAR-10 Batch 2:  loss: 0.750382
accuracy: 0.775000
Epoch 739, CIFAR-10 Batch 3:  loss: 0.803839
accuracy: 0.825000
Epoch 739, CIFAR-10 Batch 4:  loss: 1.200959
accuracy: 0.625000
Epoch 739, CIFAR-10 Batch 5:  loss: 0.996353
accuracy: 0.700000
Epoch 740, CIFAR-10 Batch 1:  loss: 0.836555
accuracy: 0.700000
Epoch 740, CIFAR-10 Batch 2:  loss: 0.776682
accuracy: 0.825000
Epoch 740, CIFAR-10 Batch 3:  loss: 0.846389
accuracy: 0.725000
Epoch 740, CIFAR-10 Batch 4:  loss: 1.171071
accuracy: 0.625000
Epoch 740, CIFAR-10 Batch 5:  loss: 1.018882
accuracy: 0.650000
Epoch 741, CIFAR-10 Batch 1:  loss: 0.840441
accuracy: 0.725000
Epoch 741, CIFAR-10 Batch 2:  loss: 0.758197
accuracy: 0.800000
Epoch 741, CIFAR-10 Batch 3:  loss: 0.814373
accuracy: 0.775000
Epoch 741, CIFAR-10 Batch 4:  loss: 1.212795
accuracy: 0.600000
Epoch 741, CIFAR-10 Batch 5:  loss: 1.015415
accuracy: 0.650000
Epoch 742, CIFAR-10 Batch 1:  loss: 0.841353
accuracy: 0.675000
Epoch 742, CIFAR-10 Batch 2:  loss: 0.775491
accuracy: 0.750000
Epoch 742, CIFAR-10 Batch 3:  loss: 0.816050
accuracy: 0.800000
Epoch 742, CIFAR-10 Batch 4:  loss: 1.202116
accuracy: 0.575000
Epoch 742, CIFAR-10 Batch 5:  loss: 0.996204
accuracy: 0.675000
Epoch 743, CIFAR-10 Batch 1:  loss: 0.838422
accuracy: 0.725000
Epoch 743, CIFAR-10 Batch 2:  loss: 0.762881
accuracy: 0.750000
Epoch 743, CIFAR-10 Batch 3:  loss: 0.813302
accuracy: 0.750000
Epoch 743, CIFAR-10 Batch 4:  loss: 1.225135
accuracy: 0.525000
Epoch 743, CIFAR-10 Batch 5:  loss: 1.060338
accuracy: 0.625000
Epoch 744, CIFAR-10 Batch 1:  loss: 0.824751
accuracy: 0.725000
Epoch 744, CIFAR-10 Batch 2:  loss: 0.731145
accuracy: 0.800000
Epoch 744, CIFAR-10 Batch 3:  loss: 0.837579
accuracy: 0.725000
Epoch 744, CIFAR-10 Batch 4:  loss: 1.229623
accuracy: 0.575000
Epoch 744, CIFAR-10 Batch 5:  loss: 1.009404
accuracy: 0.700000
Epoch 745, CIFAR-10 Batch 1:  loss: 0.834816
accuracy: 0.725000
Epoch 745, CIFAR-10 Batch 2:  loss: 0.793105
accuracy: 0.750000
Epoch 745, CIFAR-10 Batch 3:  loss: 0.829192
accuracy: 0.775000
Epoch 745, CIFAR-10 Batch 4:  loss: 1.258943
accuracy: 0.500000
Epoch 745, CIFAR-10 Batch 5:  loss: 1.036418
accuracy: 0.650000
Epoch 746, CIFAR-10 Batch 1:  loss: 0.852439
accuracy: 0.700000
Epoch 746, CIFAR-10 Batch 2:  loss: 0.797564
accuracy: 0.750000
Epoch 746, CIFAR-10 Batch 3:  loss: 0.821243
accuracy: 0.750000
Epoch 746, CIFAR-10 Batch 4:  loss: 1.191389
accuracy: 0.575000
Epoch 746, CIFAR-10 Batch 5:  loss: 1.052081
accuracy: 0.650000
Epoch 747, CIFAR-10 Batch 1:  loss: 0.818274
accuracy: 0.675000
Epoch 747, CIFAR-10 Batch 2:  loss: 0.802600
accuracy: 0.775000
Epoch 747, CIFAR-10 Batch 3:  loss: 0.772071
accuracy: 0.775000
Epoch 747, CIFAR-10 Batch 4:  loss: 1.241290
accuracy: 0.525000
Epoch 747, CIFAR-10 Batch 5:  loss: 1.014372
accuracy: 0.675000
Epoch 748, CIFAR-10 Batch 1:  loss: 0.809653
accuracy: 0.800000
Epoch 748, CIFAR-10 Batch 2:  loss: 0.765121
accuracy: 0.775000
Epoch 748, CIFAR-10 Batch 3:  loss: 0.825985
accuracy: 0.725000
Epoch 748, CIFAR-10 Batch 4:  loss: 1.190190
accuracy: 0.575000
Epoch 748, CIFAR-10 Batch 5:  loss: 1.032917
accuracy: 0.650000
Epoch 749, CIFAR-10 Batch 1:  loss: 0.830762
accuracy: 0.725000
Epoch 749, CIFAR-10 Batch 2:  loss: 0.786088
accuracy: 0.725000
Epoch 749, CIFAR-10 Batch 3:  loss: 0.790711
accuracy: 0.775000
Epoch 749, CIFAR-10 Batch 4:  loss: 1.229385
accuracy: 0.475000
Epoch 749, CIFAR-10 Batch 5:  loss: 1.026572
accuracy: 0.650000
Epoch 750, CIFAR-10 Batch 1:  loss: 0.815518
accuracy: 0.725000
Epoch 750, CIFAR-10 Batch 2:  loss: 0.778635
accuracy: 0.825000
Epoch 750, CIFAR-10 Batch 3:  loss: 0.804968
accuracy: 0.725000
Epoch 750, CIFAR-10 Batch 4:  loss: 1.280309
accuracy: 0.475000
Epoch 750, CIFAR-10 Batch 5:  loss: 1.003141
accuracy: 0.675000
Epoch 751, CIFAR-10 Batch 1:  loss: 0.832201
accuracy: 0.725000
Epoch 751, CIFAR-10 Batch 2:  loss: 0.752578
accuracy: 0.825000
Epoch 751, CIFAR-10 Batch 3:  loss: 0.779269
accuracy: 0.750000
Epoch 751, CIFAR-10 Batch 4:  loss: 1.244777
accuracy: 0.550000
Epoch 751, CIFAR-10 Batch 5:  loss: 1.030771
accuracy: 0.675000
Epoch 752, CIFAR-10 Batch 1:  loss: 0.828180
accuracy: 0.750000
Epoch 752, CIFAR-10 Batch 2:  loss: 0.764842
accuracy: 0.775000
Epoch 752, CIFAR-10 Batch 3:  loss: 0.808065
accuracy: 0.725000
Epoch 752, CIFAR-10 Batch 4:  loss: 1.222626
accuracy: 0.550000
Epoch 752, CIFAR-10 Batch 5:  loss: 1.028355
accuracy: 0.650000
Epoch 753, CIFAR-10 Batch 1:  loss: 0.893411
accuracy: 0.725000
Epoch 753, CIFAR-10 Batch 2:  loss: 0.796795
accuracy: 0.750000
Epoch 753, CIFAR-10 Batch 3:  loss: 0.792745
accuracy: 0.775000
Epoch 753, CIFAR-10 Batch 4:  loss: 1.255955
accuracy: 0.500000
Epoch 753, CIFAR-10 Batch 5:  loss: 1.041032
accuracy: 0.625000
Epoch 754, CIFAR-10 Batch 1:  loss: 0.822651
accuracy: 0.725000
Epoch 754, CIFAR-10 Batch 2:  loss: 0.766982
accuracy: 0.800000
Epoch 754, CIFAR-10 Batch 3:  loss: 0.793705
accuracy: 0.775000
Epoch 754, CIFAR-10 Batch 4:  loss: 1.256097
accuracy: 0.500000
Epoch 754, CIFAR-10 Batch 5:  loss: 1.028299
accuracy: 0.675000
Epoch 755, CIFAR-10 Batch 1:  loss: 0.812523
accuracy: 0.725000
Epoch 755, CIFAR-10 Batch 2:  loss: 0.762727
accuracy: 0.775000
Epoch 755, CIFAR-10 Batch 3:  loss: 0.801076
accuracy: 0.750000
Epoch 755, CIFAR-10 Batch 4:  loss: 1.269615
accuracy: 0.450000
Epoch 755, CIFAR-10 Batch 5:  loss: 1.015326
accuracy: 0.675000
Epoch 756, CIFAR-10 Batch 1:  loss: 0.819515
accuracy: 0.700000
Epoch 756, CIFAR-10 Batch 2:  loss: 0.798441
accuracy: 0.750000
Epoch 756, CIFAR-10 Batch 3:  loss: 0.804343
accuracy: 0.775000
Epoch 756, CIFAR-10 Batch 4:  loss: 1.222665
accuracy: 0.550000
Epoch 756, CIFAR-10 Batch 5:  loss: 1.013062
accuracy: 0.675000
Epoch 757, CIFAR-10 Batch 1:  loss: 0.820553
accuracy: 0.750000
Epoch 757, CIFAR-10 Batch 2:  loss: 0.810125
accuracy: 0.750000
Epoch 757, CIFAR-10 Batch 3:  loss: 0.774747
accuracy: 0.775000
Epoch 757, CIFAR-10 Batch 4:  loss: 1.243527
accuracy: 0.475000
Epoch 757, CIFAR-10 Batch 5:  loss: 1.014691
accuracy: 0.675000
Epoch 758, CIFAR-10 Batch 1:  loss: 0.821424
accuracy: 0.725000
Epoch 758, CIFAR-10 Batch 2:  loss: 0.804568
accuracy: 0.750000
Epoch 758, CIFAR-10 Batch 3:  loss: 0.802517
accuracy: 0.775000
Epoch 758, CIFAR-10 Batch 4:  loss: 1.201460
accuracy: 0.625000
Epoch 758, CIFAR-10 Batch 5:  loss: 0.982259
accuracy: 0.675000
Epoch 759, CIFAR-10 Batch 1:  loss: 0.811110
accuracy: 0.725000
Epoch 759, CIFAR-10 Batch 2:  loss: 0.841849
accuracy: 0.750000
Epoch 759, CIFAR-10 Batch 3:  loss: 0.783021
accuracy: 0.850000
Epoch 759, CIFAR-10 Batch 4:  loss: 1.247374
accuracy: 0.450000
Epoch 759, CIFAR-10 Batch 5:  loss: 0.960163
accuracy: 0.675000
Epoch 760, CIFAR-10 Batch 1:  loss: 0.818775
accuracy: 0.725000
Epoch 760, CIFAR-10 Batch 2:  loss: 0.798246
accuracy: 0.775000
Epoch 760, CIFAR-10 Batch 3:  loss: 0.808758
accuracy: 0.775000
Epoch 760, CIFAR-10 Batch 4:  loss: 1.234122
accuracy: 0.525000
Epoch 760, CIFAR-10 Batch 5:  loss: 1.010769
accuracy: 0.650000
Epoch 761, CIFAR-10 Batch 1:  loss: 0.813394
accuracy: 0.725000
Epoch 761, CIFAR-10 Batch 2:  loss: 0.840497
accuracy: 0.700000
Epoch 761, CIFAR-10 Batch 3:  loss: 0.790210
accuracy: 0.775000
Epoch 761, CIFAR-10 Batch 4:  loss: 1.221806
accuracy: 0.575000
Epoch 761, CIFAR-10 Batch 5:  loss: 1.020657
accuracy: 0.675000
Epoch 762, CIFAR-10 Batch 1:  loss: 0.800998
accuracy: 0.750000
Epoch 762, CIFAR-10 Batch 2:  loss: 0.795953
accuracy: 0.825000
Epoch 762, CIFAR-10 Batch 3:  loss: 0.759049
accuracy: 0.800000
Epoch 762, CIFAR-10 Batch 4:  loss: 1.261100
accuracy: 0.550000
Epoch 762, CIFAR-10 Batch 5:  loss: 1.045588
accuracy: 0.650000
Epoch 763, CIFAR-10 Batch 1:  loss: 0.808289
accuracy: 0.725000
Epoch 763, CIFAR-10 Batch 2:  loss: 0.843067
accuracy: 0.700000
Epoch 763, CIFAR-10 Batch 3:  loss: 0.781618
accuracy: 0.750000
Epoch 763, CIFAR-10 Batch 4:  loss: 1.231797
accuracy: 0.550000
Epoch 763, CIFAR-10 Batch 5:  loss: 0.961730
accuracy: 0.700000
Epoch 764, CIFAR-10 Batch 1:  loss: 0.818856
accuracy: 0.725000
Epoch 764, CIFAR-10 Batch 2:  loss: 0.785282
accuracy: 0.750000
Epoch 764, CIFAR-10 Batch 3:  loss: 0.792477
accuracy: 0.750000
Epoch 764, CIFAR-10 Batch 4:  loss: 1.224615
accuracy: 0.550000
Epoch 764, CIFAR-10 Batch 5:  loss: 1.000742
accuracy: 0.650000
Epoch 765, CIFAR-10 Batch 1:  loss: 0.816800
accuracy: 0.750000
Epoch 765, CIFAR-10 Batch 2:  loss: 0.815885
accuracy: 0.725000
Epoch 765, CIFAR-10 Batch 3:  loss: 0.756273
accuracy: 0.800000
Epoch 765, CIFAR-10 Batch 4:  loss: 1.248300
accuracy: 0.550000
Epoch 765, CIFAR-10 Batch 5:  loss: 0.993865
accuracy: 0.675000
Epoch 766, CIFAR-10 Batch 1:  loss: 0.796280
accuracy: 0.750000
Epoch 766, CIFAR-10 Batch 2:  loss: 0.774944
accuracy: 0.750000
Epoch 766, CIFAR-10 Batch 3:  loss: 0.785640
accuracy: 0.800000
Epoch 766, CIFAR-10 Batch 4:  loss: 1.226713
accuracy: 0.550000
Epoch 766, CIFAR-10 Batch 5:  loss: 0.984001
accuracy: 0.675000
Epoch 767, CIFAR-10 Batch 1:  loss: 0.827056
accuracy: 0.725000
Epoch 767, CIFAR-10 Batch 2:  loss: 0.833501
accuracy: 0.800000
Epoch 767, CIFAR-10 Batch 3:  loss: 0.800310
accuracy: 0.775000
Epoch 767, CIFAR-10 Batch 4:  loss: 1.245835
accuracy: 0.500000
Epoch 767, CIFAR-10 Batch 5:  loss: 0.995154
accuracy: 0.700000
Epoch 768, CIFAR-10 Batch 1:  loss: 0.865428
accuracy: 0.700000
Epoch 768, CIFAR-10 Batch 2:  loss: 0.833429
accuracy: 0.725000
Epoch 768, CIFAR-10 Batch 3:  loss: 0.812763
accuracy: 0.750000
Epoch 768, CIFAR-10 Batch 4:  loss: 1.259564
accuracy: 0.475000
Epoch 768, CIFAR-10 Batch 5:  loss: 0.994508
accuracy: 0.675000
Epoch 769, CIFAR-10 Batch 1:  loss: 0.849341
accuracy: 0.700000
Epoch 769, CIFAR-10 Batch 2:  loss: 0.875949
accuracy: 0.725000
Epoch 769, CIFAR-10 Batch 3:  loss: 0.823843
accuracy: 0.775000
Epoch 769, CIFAR-10 Batch 4:  loss: 1.246163
accuracy: 0.500000
Epoch 769, CIFAR-10 Batch 5:  loss: 1.058293
accuracy: 0.675000
Epoch 770, CIFAR-10 Batch 1:  loss: 0.803250
accuracy: 0.725000
Epoch 770, CIFAR-10 Batch 2:  loss: 0.821715
accuracy: 0.700000
Epoch 770, CIFAR-10 Batch 3:  loss: 0.739373
accuracy: 0.800000
Epoch 770, CIFAR-10 Batch 4:  loss: 1.196448
accuracy: 0.525000
Epoch 770, CIFAR-10 Batch 5:  loss: 1.023946
accuracy: 0.650000
Epoch 771, CIFAR-10 Batch 1:  loss: 0.876345
accuracy: 0.700000
Epoch 771, CIFAR-10 Batch 2:  loss: 0.811969
accuracy: 0.750000
Epoch 771, CIFAR-10 Batch 3:  loss: 0.788588
accuracy: 0.750000
Epoch 771, CIFAR-10 Batch 4:  loss: 1.205074
accuracy: 0.525000
Epoch 771, CIFAR-10 Batch 5:  loss: 1.014819
accuracy: 0.625000
Epoch 772, CIFAR-10 Batch 1:  loss: 0.837413
accuracy: 0.725000
Epoch 772, CIFAR-10 Batch 2:  loss: 0.831152
accuracy: 0.750000
Epoch 772, CIFAR-10 Batch 3:  loss: 0.837052
accuracy: 0.725000
Epoch 772, CIFAR-10 Batch 4:  loss: 1.224718
accuracy: 0.550000
Epoch 772, CIFAR-10 Batch 5:  loss: 1.001934
accuracy: 0.650000
Epoch 773, CIFAR-10 Batch 1:  loss: 0.824473
accuracy: 0.700000
Epoch 773, CIFAR-10 Batch 2:  loss: 0.834908
accuracy: 0.725000
Epoch 773, CIFAR-10 Batch 3:  loss: 0.788640
accuracy: 0.800000
Epoch 773, CIFAR-10 Batch 4:  loss: 1.229250
accuracy: 0.500000
Epoch 773, CIFAR-10 Batch 5:  loss: 0.982253
accuracy: 0.700000
Epoch 774, CIFAR-10 Batch 1:  loss: 0.805741
accuracy: 0.750000
Epoch 774, CIFAR-10 Batch 2:  loss: 0.841532
accuracy: 0.725000
Epoch 774, CIFAR-10 Batch 3:  loss: 0.789776
accuracy: 0.800000
Epoch 774, CIFAR-10 Batch 4:  loss: 1.225401
accuracy: 0.575000
Epoch 774, CIFAR-10 Batch 5:  loss: 0.977373
accuracy: 0.725000
Epoch 775, CIFAR-10 Batch 1:  loss: 0.832869
accuracy: 0.725000
Epoch 775, CIFAR-10 Batch 2:  loss: 0.820765
accuracy: 0.750000
Epoch 775, CIFAR-10 Batch 3:  loss: 0.789320
accuracy: 0.875000
Epoch 775, CIFAR-10 Batch 4:  loss: 1.221555
accuracy: 0.525000
Epoch 775, CIFAR-10 Batch 5:  loss: 0.994844
accuracy: 0.700000
Epoch 776, CIFAR-10 Batch 1:  loss: 0.814177
accuracy: 0.750000
Epoch 776, CIFAR-10 Batch 2:  loss: 0.838737
accuracy: 0.700000
Epoch 776, CIFAR-10 Batch 3:  loss: 0.822544
accuracy: 0.775000
Epoch 776, CIFAR-10 Batch 4:  loss: 1.223222
accuracy: 0.550000
Epoch 776, CIFAR-10 Batch 5:  loss: 0.997495
accuracy: 0.725000
Epoch 777, CIFAR-10 Batch 1:  loss: 0.819899
accuracy: 0.725000
Epoch 777, CIFAR-10 Batch 2:  loss: 0.848044
accuracy: 0.700000
Epoch 777, CIFAR-10 Batch 3:  loss: 0.806973
accuracy: 0.750000
Epoch 777, CIFAR-10 Batch 4:  loss: 1.231556
accuracy: 0.525000
Epoch 777, CIFAR-10 Batch 5:  loss: 0.986995
accuracy: 0.700000
Epoch 778, CIFAR-10 Batch 1:  loss: 0.795882
accuracy: 0.700000
Epoch 778, CIFAR-10 Batch 2:  loss: 0.850249
accuracy: 0.700000
Epoch 778, CIFAR-10 Batch 3:  loss: 0.791573
accuracy: 0.800000
Epoch 778, CIFAR-10 Batch 4:  loss: 1.201453
accuracy: 0.550000
Epoch 778, CIFAR-10 Batch 5:  loss: 0.985896
accuracy: 0.700000
Epoch 779, CIFAR-10 Batch 1:  loss: 0.804639
accuracy: 0.750000
Epoch 779, CIFAR-10 Batch 2:  loss: 0.838481
accuracy: 0.675000
Epoch 779, CIFAR-10 Batch 3:  loss: 0.870649
accuracy: 0.775000
Epoch 779, CIFAR-10 Batch 4:  loss: 1.251025
accuracy: 0.550000
Epoch 779, CIFAR-10 Batch 5:  loss: 0.973679
accuracy: 0.725000
Epoch 780, CIFAR-10 Batch 1:  loss: 0.794899
accuracy: 0.725000
Epoch 780, CIFAR-10 Batch 2:  loss: 0.840975
accuracy: 0.675000
Epoch 780, CIFAR-10 Batch 3:  loss: 0.862884
accuracy: 0.775000
Epoch 780, CIFAR-10 Batch 4:  loss: 1.222287
accuracy: 0.525000
Epoch 780, CIFAR-10 Batch 5:  loss: 1.018498
accuracy: 0.675000
Epoch 781, CIFAR-10 Batch 1:  loss: 0.810942
accuracy: 0.750000
Epoch 781, CIFAR-10 Batch 2:  loss: 0.844495
accuracy: 0.700000
Epoch 781, CIFAR-10 Batch 3:  loss: 0.878136
accuracy: 0.700000
Epoch 781, CIFAR-10 Batch 4:  loss: 1.276845
accuracy: 0.500000
Epoch 781, CIFAR-10 Batch 5:  loss: 0.984417
accuracy: 0.700000
Epoch 782, CIFAR-10 Batch 1:  loss: 0.792815
accuracy: 0.750000
Epoch 782, CIFAR-10 Batch 2:  loss: 0.866083
accuracy: 0.700000
Epoch 782, CIFAR-10 Batch 3:  loss: 0.836263
accuracy: 0.725000
Epoch 782, CIFAR-10 Batch 4:  loss: 1.274897
accuracy: 0.525000
Epoch 782, CIFAR-10 Batch 5:  loss: 0.995479
accuracy: 0.675000
Epoch 783, CIFAR-10 Batch 1:  loss: 0.809716
accuracy: 0.725000
Epoch 783, CIFAR-10 Batch 2:  loss: 0.849410
accuracy: 0.700000
Epoch 783, CIFAR-10 Batch 3:  loss: 0.803306
accuracy: 0.775000
Epoch 783, CIFAR-10 Batch 4:  loss: 1.224833
accuracy: 0.575000
Epoch 783, CIFAR-10 Batch 5:  loss: 1.002275
accuracy: 0.675000
Epoch 784, CIFAR-10 Batch 1:  loss: 0.792534
accuracy: 0.725000
Epoch 784, CIFAR-10 Batch 2:  loss: 0.862235
accuracy: 0.725000
Epoch 784, CIFAR-10 Batch 3:  loss: 0.802178
accuracy: 0.750000
Epoch 784, CIFAR-10 Batch 4:  loss: 1.218780
accuracy: 0.500000
Epoch 784, CIFAR-10 Batch 5:  loss: 1.015654
accuracy: 0.650000
Epoch 785, CIFAR-10 Batch 1:  loss: 0.795331
accuracy: 0.725000
Epoch 785, CIFAR-10 Batch 2:  loss: 0.865304
accuracy: 0.700000
Epoch 785, CIFAR-10 Batch 3:  loss: 0.824662
accuracy: 0.825000
Epoch 785, CIFAR-10 Batch 4:  loss: 1.234430
accuracy: 0.550000
Epoch 785, CIFAR-10 Batch 5:  loss: 0.995850
accuracy: 0.650000
Epoch 786, CIFAR-10 Batch 1:  loss: 0.766119
accuracy: 0.800000
Epoch 786, CIFAR-10 Batch 2:  loss: 0.862951
accuracy: 0.750000
Epoch 786, CIFAR-10 Batch 3:  loss: 0.816394
accuracy: 0.750000
Epoch 786, CIFAR-10 Batch 4:  loss: 1.226923
accuracy: 0.550000
Epoch 786, CIFAR-10 Batch 5:  loss: 0.992381
accuracy: 0.675000
Epoch 787, CIFAR-10 Batch 1:  loss: 0.805903
accuracy: 0.750000
Epoch 787, CIFAR-10 Batch 2:  loss: 0.848817
accuracy: 0.725000
Epoch 787, CIFAR-10 Batch 3:  loss: 0.855621
accuracy: 0.750000
Epoch 787, CIFAR-10 Batch 4:  loss: 1.254288
accuracy: 0.575000
Epoch 787, CIFAR-10 Batch 5:  loss: 0.989013
accuracy: 0.650000
Epoch 788, CIFAR-10 Batch 1:  loss: 0.806907
accuracy: 0.725000
Epoch 788, CIFAR-10 Batch 2:  loss: 0.861388
accuracy: 0.700000
Epoch 788, CIFAR-10 Batch 3:  loss: 0.803628
accuracy: 0.800000
Epoch 788, CIFAR-10 Batch 4:  loss: 1.222156
accuracy: 0.500000
Epoch 788, CIFAR-10 Batch 5:  loss: 0.990086
accuracy: 0.700000
Epoch 789, CIFAR-10 Batch 1:  loss: 0.793182
accuracy: 0.750000
Epoch 789, CIFAR-10 Batch 2:  loss: 0.853008
accuracy: 0.775000
Epoch 789, CIFAR-10 Batch 3:  loss: 0.824668
accuracy: 0.800000
Epoch 789, CIFAR-10 Batch 4:  loss: 1.269510
accuracy: 0.500000
Epoch 789, CIFAR-10 Batch 5:  loss: 1.012309
accuracy: 0.675000
Epoch 790, CIFAR-10 Batch 1:  loss: 0.807544
accuracy: 0.750000
Epoch 790, CIFAR-10 Batch 2:  loss: 0.878582
accuracy: 0.750000
Epoch 790, CIFAR-10 Batch 3:  loss: 0.798497
accuracy: 0.750000
Epoch 790, CIFAR-10 Batch 4:  loss: 1.239582
accuracy: 0.575000
Epoch 790, CIFAR-10 Batch 5:  loss: 0.994032
accuracy: 0.675000
Epoch 791, CIFAR-10 Batch 1:  loss: 0.784555
accuracy: 0.700000
Epoch 791, CIFAR-10 Batch 2:  loss: 0.867096
accuracy: 0.725000
Epoch 791, CIFAR-10 Batch 3:  loss: 0.792879
accuracy: 0.800000
Epoch 791, CIFAR-10 Batch 4:  loss: 1.266786
accuracy: 0.600000
Epoch 791, CIFAR-10 Batch 5:  loss: 0.986499
accuracy: 0.700000
Epoch 792, CIFAR-10 Batch 1:  loss: 0.777401
accuracy: 0.750000
Epoch 792, CIFAR-10 Batch 2:  loss: 0.857925
accuracy: 0.775000
Epoch 792, CIFAR-10 Batch 3:  loss: 0.816918
accuracy: 0.825000
Epoch 792, CIFAR-10 Batch 4:  loss: 1.261643
accuracy: 0.525000
Epoch 792, CIFAR-10 Batch 5:  loss: 1.009645
accuracy: 0.700000
Epoch 793, CIFAR-10 Batch 1:  loss: 0.794336
accuracy: 0.775000
Epoch 793, CIFAR-10 Batch 2:  loss: 0.864237
accuracy: 0.725000
Epoch 793, CIFAR-10 Batch 3:  loss: 0.798067
accuracy: 0.775000
Epoch 793, CIFAR-10 Batch 4:  loss: 1.258453
accuracy: 0.475000
Epoch 793, CIFAR-10 Batch 5:  loss: 0.974692
accuracy: 0.675000
Epoch 794, CIFAR-10 Batch 1:  loss: 0.798942
accuracy: 0.700000
Epoch 794, CIFAR-10 Batch 2:  loss: 0.869842
accuracy: 0.725000
Epoch 794, CIFAR-10 Batch 3:  loss: 0.788218
accuracy: 0.775000
Epoch 794, CIFAR-10 Batch 4:  loss: 1.247748
accuracy: 0.550000
Epoch 794, CIFAR-10 Batch 5:  loss: 0.987859
accuracy: 0.650000
Epoch 795, CIFAR-10 Batch 1:  loss: 0.790225
accuracy: 0.725000
Epoch 795, CIFAR-10 Batch 2:  loss: 0.871724
accuracy: 0.700000
Epoch 795, CIFAR-10 Batch 3:  loss: 0.794524
accuracy: 0.825000
Epoch 795, CIFAR-10 Batch 4:  loss: 1.242253
accuracy: 0.550000
Epoch 795, CIFAR-10 Batch 5:  loss: 0.988915
accuracy: 0.700000
Epoch 796, CIFAR-10 Batch 1:  loss: 0.785276
accuracy: 0.775000
Epoch 796, CIFAR-10 Batch 2:  loss: 0.864893
accuracy: 0.700000
Epoch 796, CIFAR-10 Batch 3:  loss: 0.815231
accuracy: 0.800000
Epoch 796, CIFAR-10 Batch 4:  loss: 1.268093
accuracy: 0.500000
Epoch 796, CIFAR-10 Batch 5:  loss: 0.975959
accuracy: 0.675000
Epoch 797, CIFAR-10 Batch 1:  loss: 0.784698
accuracy: 0.775000
Epoch 797, CIFAR-10 Batch 2:  loss: 0.863184
accuracy: 0.700000
Epoch 797, CIFAR-10 Batch 3:  loss: 0.825794
accuracy: 0.800000
Epoch 797, CIFAR-10 Batch 4:  loss: 1.258747
accuracy: 0.525000
Epoch 797, CIFAR-10 Batch 5:  loss: 0.979553
accuracy: 0.675000
Epoch 798, CIFAR-10 Batch 1:  loss: 0.773082
accuracy: 0.775000
Epoch 798, CIFAR-10 Batch 2:  loss: 0.894144
accuracy: 0.650000
Epoch 798, CIFAR-10 Batch 3:  loss: 0.816779
accuracy: 0.775000
Epoch 798, CIFAR-10 Batch 4:  loss: 1.263350
accuracy: 0.500000
Epoch 798, CIFAR-10 Batch 5:  loss: 0.966808
accuracy: 0.700000
Epoch 799, CIFAR-10 Batch 1:  loss: 0.799990
accuracy: 0.775000
Epoch 799, CIFAR-10 Batch 2:  loss: 2.710472
accuracy: 0.700000
Epoch 799, CIFAR-10 Batch 3:  loss: 0.821539
accuracy: 0.750000
Epoch 799, CIFAR-10 Batch 4:  loss: 1.245617
accuracy: 0.575000
Epoch 799, CIFAR-10 Batch 5:  loss: 1.032827
accuracy: 0.700000
Epoch 800, CIFAR-10 Batch 1:  loss: 0.795987
accuracy: 0.750000
Epoch 800, CIFAR-10 Batch 2:  loss: 0.836850
accuracy: 0.725000
Epoch 800, CIFAR-10 Batch 3:  loss: 0.812883
accuracy: 0.725000
Epoch 800, CIFAR-10 Batch 4:  loss: 1.229435
accuracy: 0.550000
Epoch 800, CIFAR-10 Batch 5:  loss: 0.983277
accuracy: 0.650000
Epoch 801, CIFAR-10 Batch 1:  loss: 0.785160
accuracy: 0.775000
Epoch 801, CIFAR-10 Batch 2:  loss: 2.332744
accuracy: 0.675000
Epoch 801, CIFAR-10 Batch 3:  loss: 0.808100
accuracy: 0.750000
Epoch 801, CIFAR-10 Batch 4:  loss: 1.248674
accuracy: 0.575000
Epoch 801, CIFAR-10 Batch 5:  loss: 0.963400
accuracy: 0.700000
Epoch 802, CIFAR-10 Batch 1:  loss: 0.765351
accuracy: 0.750000
Epoch 802, CIFAR-10 Batch 2:  loss: 2.094882
accuracy: 0.700000
Epoch 802, CIFAR-10 Batch 3:  loss: 0.847694
accuracy: 0.700000
Epoch 802, CIFAR-10 Batch 4:  loss: 1.214470
accuracy: 0.575000
Epoch 802, CIFAR-10 Batch 5:  loss: 1.007223
accuracy: 0.700000
Epoch 803, CIFAR-10 Batch 1:  loss: 0.771510
accuracy: 0.775000
Epoch 803, CIFAR-10 Batch 2:  loss: 2.017561
accuracy: 0.650000
Epoch 803, CIFAR-10 Batch 3:  loss: 0.824831
accuracy: 0.775000
Epoch 803, CIFAR-10 Batch 4:  loss: 1.230503
accuracy: 0.525000
Epoch 803, CIFAR-10 Batch 5:  loss: 0.984664
accuracy: 0.700000
Epoch 804, CIFAR-10 Batch 1:  loss: 0.787349
accuracy: 0.750000
Epoch 804, CIFAR-10 Batch 2:  loss: 1.611777
accuracy: 0.700000
Epoch 804, CIFAR-10 Batch 3:  loss: 0.775174
accuracy: 0.775000
Epoch 804, CIFAR-10 Batch 4:  loss: 1.252698
accuracy: 0.575000
Epoch 804, CIFAR-10 Batch 5:  loss: 0.975583
accuracy: 0.725000
Epoch 805, CIFAR-10 Batch 1:  loss: 0.769589
accuracy: 0.800000
Epoch 805, CIFAR-10 Batch 2:  loss: 1.459139
accuracy: 0.700000
Epoch 805, CIFAR-10 Batch 3:  loss: 0.786629
accuracy: 0.800000
Epoch 805, CIFAR-10 Batch 4:  loss: 1.229107
accuracy: 0.550000
Epoch 805, CIFAR-10 Batch 5:  loss: 0.961976
accuracy: 0.725000
Epoch 806, CIFAR-10 Batch 1:  loss: 0.765169
accuracy: 0.750000
Epoch 806, CIFAR-10 Batch 2:  loss: 1.197839
accuracy: 0.675000
Epoch 806, CIFAR-10 Batch 3:  loss: 0.784152
accuracy: 0.800000
Epoch 806, CIFAR-10 Batch 4:  loss: 1.241955
accuracy: 0.550000
Epoch 806, CIFAR-10 Batch 5:  loss: 0.989715
accuracy: 0.675000
Epoch 807, CIFAR-10 Batch 1:  loss: 0.811252
accuracy: 0.725000
Epoch 807, CIFAR-10 Batch 2:  loss: 1.014841
accuracy: 0.700000
Epoch 807, CIFAR-10 Batch 3:  loss: 0.806082
accuracy: 0.800000
Epoch 807, CIFAR-10 Batch 4:  loss: 1.253971
accuracy: 0.525000
Epoch 807, CIFAR-10 Batch 5:  loss: 0.952193
accuracy: 0.725000
Epoch 808, CIFAR-10 Batch 1:  loss: 0.777233
accuracy: 0.775000
Epoch 808, CIFAR-10 Batch 2:  loss: 0.890363
accuracy: 0.675000
Epoch 808, CIFAR-10 Batch 3:  loss: 0.756803
accuracy: 0.800000
Epoch 808, CIFAR-10 Batch 4:  loss: 1.228493
accuracy: 0.550000
Epoch 808, CIFAR-10 Batch 5:  loss: 0.970286
accuracy: 0.700000
Epoch 809, CIFAR-10 Batch 1:  loss: 0.764091
accuracy: 0.775000
Epoch 809, CIFAR-10 Batch 2:  loss: 0.941835
accuracy: 0.700000
Epoch 809, CIFAR-10 Batch 3:  loss: 0.812337
accuracy: 0.750000
Epoch 809, CIFAR-10 Batch 4:  loss: 1.240327
accuracy: 0.550000
Epoch 809, CIFAR-10 Batch 5:  loss: 0.984305
accuracy: 0.675000
Epoch 810, CIFAR-10 Batch 1:  loss: 0.812702
accuracy: 0.700000
Epoch 810, CIFAR-10 Batch 2:  loss: 0.922351
accuracy: 0.650000
Epoch 810, CIFAR-10 Batch 3:  loss: 0.788921
accuracy: 0.775000
Epoch 810, CIFAR-10 Batch 4:  loss: 1.284749
accuracy: 0.550000
Epoch 810, CIFAR-10 Batch 5:  loss: 0.969068
accuracy: 0.725000
Epoch 811, CIFAR-10 Batch 1:  loss: 0.790800
accuracy: 0.700000
Epoch 811, CIFAR-10 Batch 2:  loss: 0.937260
accuracy: 0.675000
Epoch 811, CIFAR-10 Batch 3:  loss: 0.800791
accuracy: 0.750000
Epoch 811, CIFAR-10 Batch 4:  loss: 1.286087
accuracy: 0.450000
Epoch 811, CIFAR-10 Batch 5:  loss: 0.987474
accuracy: 0.650000
Epoch 812, CIFAR-10 Batch 1:  loss: 0.788927
accuracy: 0.750000
Epoch 812, CIFAR-10 Batch 2:  loss: 0.906398
accuracy: 0.700000
Epoch 812, CIFAR-10 Batch 3:  loss: 0.784348
accuracy: 0.800000
Epoch 812, CIFAR-10 Batch 4:  loss: 1.294139
accuracy: 0.525000
Epoch 812, CIFAR-10 Batch 5:  loss: 0.985320
accuracy: 0.650000
Epoch 813, CIFAR-10 Batch 1:  loss: 0.779830
accuracy: 0.725000
Epoch 813, CIFAR-10 Batch 2:  loss: 0.904093
accuracy: 0.675000
Epoch 813, CIFAR-10 Batch 3:  loss: 0.766538
accuracy: 0.775000
Epoch 813, CIFAR-10 Batch 4:  loss: 1.264432
accuracy: 0.500000
Epoch 813, CIFAR-10 Batch 5:  loss: 1.024498
accuracy: 0.625000
Epoch 814, CIFAR-10 Batch 1:  loss: 0.810821
accuracy: 0.750000
Epoch 814, CIFAR-10 Batch 2:  loss: 0.935858
accuracy: 0.675000
Epoch 814, CIFAR-10 Batch 3:  loss: 0.774923
accuracy: 0.750000
Epoch 814, CIFAR-10 Batch 4:  loss: 1.269463
accuracy: 0.525000
Epoch 814, CIFAR-10 Batch 5:  loss: 1.004075
accuracy: 0.700000
Epoch 815, CIFAR-10 Batch 1:  loss: 0.763929
accuracy: 0.775000
Epoch 815, CIFAR-10 Batch 2:  loss: 0.918362
accuracy: 0.675000
Epoch 815, CIFAR-10 Batch 3:  loss: 0.791625
accuracy: 0.775000
Epoch 815, CIFAR-10 Batch 4:  loss: 1.283690
accuracy: 0.500000
Epoch 815, CIFAR-10 Batch 5:  loss: 0.945995
accuracy: 0.725000
Epoch 816, CIFAR-10 Batch 1:  loss: 0.776177
accuracy: 0.775000
Epoch 816, CIFAR-10 Batch 2:  loss: 0.929034
accuracy: 0.675000
Epoch 816, CIFAR-10 Batch 3:  loss: 0.770765
accuracy: 0.775000
Epoch 816, CIFAR-10 Batch 4:  loss: 1.240320
accuracy: 0.600000
Epoch 816, CIFAR-10 Batch 5:  loss: 0.982975
accuracy: 0.675000
Epoch 817, CIFAR-10 Batch 1:  loss: 0.807109
accuracy: 0.700000
Epoch 817, CIFAR-10 Batch 2:  loss: 0.912030
accuracy: 0.675000
Epoch 817, CIFAR-10 Batch 3:  loss: 0.755433
accuracy: 0.775000
Epoch 817, CIFAR-10 Batch 4:  loss: 1.252609
accuracy: 0.525000
Epoch 817, CIFAR-10 Batch 5:  loss: 0.989900
accuracy: 0.675000
Epoch 818, CIFAR-10 Batch 1:  loss: 0.814996
accuracy: 0.700000
Epoch 818, CIFAR-10 Batch 2:  loss: 0.897311
accuracy: 0.675000
Epoch 818, CIFAR-10 Batch 3:  loss: 0.785901
accuracy: 0.700000
Epoch 818, CIFAR-10 Batch 4:  loss: 1.296610
accuracy: 0.550000
Epoch 818, CIFAR-10 Batch 5:  loss: 0.958896
accuracy: 0.675000
Epoch 819, CIFAR-10 Batch 1:  loss: 0.807126
accuracy: 0.750000
Epoch 819, CIFAR-10 Batch 2:  loss: 0.899234
accuracy: 0.675000
Epoch 819, CIFAR-10 Batch 3:  loss: 0.814884
accuracy: 0.700000
Epoch 819, CIFAR-10 Batch 4:  loss: 1.234841
accuracy: 0.525000
Epoch 819, CIFAR-10 Batch 5:  loss: 0.995581
accuracy: 0.700000
Epoch 820, CIFAR-10 Batch 1:  loss: 0.771490
accuracy: 0.750000
Epoch 820, CIFAR-10 Batch 2:  loss: 0.930477
accuracy: 0.675000
Epoch 820, CIFAR-10 Batch 3:  loss: 0.772390
accuracy: 0.750000
Epoch 820, CIFAR-10 Batch 4:  loss: 1.281927
accuracy: 0.550000
Epoch 820, CIFAR-10 Batch 5:  loss: 1.005586
accuracy: 0.675000
Epoch 821, CIFAR-10 Batch 1:  loss: 0.774000
accuracy: 0.725000
Epoch 821, CIFAR-10 Batch 2:  loss: 0.903148
accuracy: 0.725000
Epoch 821, CIFAR-10 Batch 3:  loss: 0.797826
accuracy: 0.750000
Epoch 821, CIFAR-10 Batch 4:  loss: 1.276450
accuracy: 0.500000
Epoch 821, CIFAR-10 Batch 5:  loss: 0.985495
accuracy: 0.700000
Epoch 822, CIFAR-10 Batch 1:  loss: 0.771371
accuracy: 0.750000
Epoch 822, CIFAR-10 Batch 2:  loss: 0.915696
accuracy: 0.650000
Epoch 822, CIFAR-10 Batch 3:  loss: 0.767832
accuracy: 0.750000
Epoch 822, CIFAR-10 Batch 4:  loss: 1.270167
accuracy: 0.525000
Epoch 822, CIFAR-10 Batch 5:  loss: 0.964662
accuracy: 0.700000
Epoch 823, CIFAR-10 Batch 1:  loss: 0.747538
accuracy: 0.775000
Epoch 823, CIFAR-10 Batch 2:  loss: 0.876040
accuracy: 0.675000
Epoch 823, CIFAR-10 Batch 3:  loss: 0.799333
accuracy: 0.800000
Epoch 823, CIFAR-10 Batch 4:  loss: 1.263985
accuracy: 0.525000
Epoch 823, CIFAR-10 Batch 5:  loss: 0.958304
accuracy: 0.700000
Epoch 824, CIFAR-10 Batch 1:  loss: 0.765384
accuracy: 0.725000
Epoch 824, CIFAR-10 Batch 2:  loss: 0.919966
accuracy: 0.700000
Epoch 824, CIFAR-10 Batch 3:  loss: 0.785722
accuracy: 0.725000
Epoch 824, CIFAR-10 Batch 4:  loss: 1.243084
accuracy: 0.525000
Epoch 824, CIFAR-10 Batch 5:  loss: 0.987597
accuracy: 0.650000
Epoch 825, CIFAR-10 Batch 1:  loss: 0.783603
accuracy: 0.700000
Epoch 825, CIFAR-10 Batch 2:  loss: 0.911868
accuracy: 0.675000
Epoch 825, CIFAR-10 Batch 3:  loss: 0.765168
accuracy: 0.725000
Epoch 825, CIFAR-10 Batch 4:  loss: 1.280563
accuracy: 0.575000
Epoch 825, CIFAR-10 Batch 5:  loss: 0.969982
accuracy: 0.725000
Epoch 826, CIFAR-10 Batch 1:  loss: 0.768187
accuracy: 0.700000
Epoch 826, CIFAR-10 Batch 2:  loss: 0.903376
accuracy: 0.675000
Epoch 826, CIFAR-10 Batch 3:  loss: 0.788706
accuracy: 0.775000
Epoch 826, CIFAR-10 Batch 4:  loss: 1.244660
accuracy: 0.550000
Epoch 826, CIFAR-10 Batch 5:  loss: 0.992281
accuracy: 0.650000
Epoch 827, CIFAR-10 Batch 1:  loss: 0.773629
accuracy: 0.725000
Epoch 827, CIFAR-10 Batch 2:  loss: 0.882967
accuracy: 0.700000
Epoch 827, CIFAR-10 Batch 3:  loss: 0.770302
accuracy: 0.750000
Epoch 827, CIFAR-10 Batch 4:  loss: 1.311730
accuracy: 0.475000
Epoch 827, CIFAR-10 Batch 5:  loss: 0.962056
accuracy: 0.675000
Epoch 828, CIFAR-10 Batch 1:  loss: 0.770160
accuracy: 0.750000
Epoch 828, CIFAR-10 Batch 2:  loss: 1.150204
accuracy: 0.675000
Epoch 828, CIFAR-10 Batch 3:  loss: 0.768298
accuracy: 0.750000
Epoch 828, CIFAR-10 Batch 4:  loss: 1.238059
accuracy: 0.575000
Epoch 828, CIFAR-10 Batch 5:  loss: 1.018087
accuracy: 0.675000
Epoch 829, CIFAR-10 Batch 1:  loss: 0.774420
accuracy: 0.750000
Epoch 829, CIFAR-10 Batch 2:  loss: 0.953807
accuracy: 0.700000
Epoch 829, CIFAR-10 Batch 3:  loss: 0.767079
accuracy: 0.750000
Epoch 829, CIFAR-10 Batch 4:  loss: 1.274647
accuracy: 0.500000
Epoch 829, CIFAR-10 Batch 5:  loss: 0.982206
accuracy: 0.700000
Epoch 830, CIFAR-10 Batch 1:  loss: 0.909660
accuracy: 0.700000
Epoch 830, CIFAR-10 Batch 2:  loss: 0.913298
accuracy: 0.650000
Epoch 830, CIFAR-10 Batch 3:  loss: 0.779837
accuracy: 0.800000
Epoch 830, CIFAR-10 Batch 4:  loss: 1.258333
accuracy: 0.525000
Epoch 830, CIFAR-10 Batch 5:  loss: 0.984210
accuracy: 0.700000
Epoch 831, CIFAR-10 Batch 1:  loss: 0.744689
accuracy: 0.775000
Epoch 831, CIFAR-10 Batch 2:  loss: 0.922980
accuracy: 0.675000
Epoch 831, CIFAR-10 Batch 3:  loss: 0.750032
accuracy: 0.750000
Epoch 831, CIFAR-10 Batch 4:  loss: 1.277470
accuracy: 0.550000
Epoch 831, CIFAR-10 Batch 5:  loss: 0.970342
accuracy: 0.650000
Epoch 832, CIFAR-10 Batch 1:  loss: 0.741004
accuracy: 0.800000
Epoch 832, CIFAR-10 Batch 2:  loss: 0.915311
accuracy: 0.675000
Epoch 832, CIFAR-10 Batch 3:  loss: 0.741412
accuracy: 0.750000
Epoch 832, CIFAR-10 Batch 4:  loss: 1.263582
accuracy: 0.575000
Epoch 832, CIFAR-10 Batch 5:  loss: 0.976161
accuracy: 0.675000
Epoch 833, CIFAR-10 Batch 1:  loss: 0.737870
accuracy: 0.750000
Epoch 833, CIFAR-10 Batch 2:  loss: 0.923347
accuracy: 0.700000
Epoch 833, CIFAR-10 Batch 3:  loss: 0.742599
accuracy: 0.825000
Epoch 833, CIFAR-10 Batch 4:  loss: 1.270898
accuracy: 0.550000
Epoch 833, CIFAR-10 Batch 5:  loss: 1.014447
accuracy: 0.675000
Epoch 834, CIFAR-10 Batch 1:  loss: 0.764129
accuracy: 0.725000
Epoch 834, CIFAR-10 Batch 2:  loss: 0.922987
accuracy: 0.650000
Epoch 834, CIFAR-10 Batch 3:  loss: 0.756608
accuracy: 0.800000
Epoch 834, CIFAR-10 Batch 4:  loss: 1.259858
accuracy: 0.500000
Epoch 834, CIFAR-10 Batch 5:  loss: 0.946336
accuracy: 0.700000
Epoch 835, CIFAR-10 Batch 1:  loss: 0.765781
accuracy: 0.750000
Epoch 835, CIFAR-10 Batch 2:  loss: 0.928224
accuracy: 0.650000
Epoch 835, CIFAR-10 Batch 3:  loss: 0.754708
accuracy: 0.825000
Epoch 835, CIFAR-10 Batch 4:  loss: 1.232470
accuracy: 0.525000
Epoch 835, CIFAR-10 Batch 5:  loss: 0.967816
accuracy: 0.675000
Epoch 836, CIFAR-10 Batch 1:  loss: 0.720850
accuracy: 0.775000
Epoch 836, CIFAR-10 Batch 2:  loss: 0.899145
accuracy: 0.650000
Epoch 836, CIFAR-10 Batch 3:  loss: 0.794479
accuracy: 0.775000
Epoch 836, CIFAR-10 Batch 4:  loss: 1.289006
accuracy: 0.550000
Epoch 836, CIFAR-10 Batch 5:  loss: 0.979788
accuracy: 0.700000
Epoch 837, CIFAR-10 Batch 1:  loss: 0.762096
accuracy: 0.775000
Epoch 837, CIFAR-10 Batch 2:  loss: 0.908615
accuracy: 0.700000
Epoch 837, CIFAR-10 Batch 3:  loss: 0.766739
accuracy: 0.800000
Epoch 837, CIFAR-10 Batch 4:  loss: 1.276138
accuracy: 0.475000
Epoch 837, CIFAR-10 Batch 5:  loss: 0.985402
accuracy: 0.750000
Epoch 838, CIFAR-10 Batch 1:  loss: 0.724153
accuracy: 0.775000
Epoch 838, CIFAR-10 Batch 2:  loss: 0.927759
accuracy: 0.675000
Epoch 838, CIFAR-10 Batch 3:  loss: 0.760060
accuracy: 0.825000
Epoch 838, CIFAR-10 Batch 4:  loss: 1.246544
accuracy: 0.575000
Epoch 838, CIFAR-10 Batch 5:  loss: 0.994198
accuracy: 0.725000
Epoch 839, CIFAR-10 Batch 1:  loss: 0.783541
accuracy: 0.775000
Epoch 839, CIFAR-10 Batch 2:  loss: 0.912600
accuracy: 0.725000
Epoch 839, CIFAR-10 Batch 3:  loss: 0.801524
accuracy: 0.800000
Epoch 839, CIFAR-10 Batch 4:  loss: 1.277478
accuracy: 0.525000
Epoch 839, CIFAR-10 Batch 5:  loss: 0.944151
accuracy: 0.725000
Epoch 840, CIFAR-10 Batch 1:  loss: 0.741359
accuracy: 0.750000
Epoch 840, CIFAR-10 Batch 2:  loss: 0.920309
accuracy: 0.650000
Epoch 840, CIFAR-10 Batch 3:  loss: 0.789085
accuracy: 0.725000
Epoch 840, CIFAR-10 Batch 4:  loss: 1.283111
accuracy: 0.550000
Epoch 840, CIFAR-10 Batch 5:  loss: 0.993327
accuracy: 0.675000
Epoch 841, CIFAR-10 Batch 1:  loss: 0.769116
accuracy: 0.725000
Epoch 841, CIFAR-10 Batch 2:  loss: 0.898276
accuracy: 0.700000
Epoch 841, CIFAR-10 Batch 3:  loss: 0.739124
accuracy: 0.775000
Epoch 841, CIFAR-10 Batch 4:  loss: 1.236881
accuracy: 0.525000
Epoch 841, CIFAR-10 Batch 5:  loss: 0.994862
accuracy: 0.700000
Epoch 842, CIFAR-10 Batch 1:  loss: 0.728266
accuracy: 0.725000
Epoch 842, CIFAR-10 Batch 2:  loss: 0.882012
accuracy: 0.650000
Epoch 842, CIFAR-10 Batch 3:  loss: 0.766726
accuracy: 0.750000
Epoch 842, CIFAR-10 Batch 4:  loss: 1.268855
accuracy: 0.525000
Epoch 842, CIFAR-10 Batch 5:  loss: 0.969977
accuracy: 0.675000
Epoch 843, CIFAR-10 Batch 1:  loss: 0.723578
accuracy: 0.750000
Epoch 843, CIFAR-10 Batch 2:  loss: 1.161999
accuracy: 0.675000
Epoch 843, CIFAR-10 Batch 3:  loss: 0.777220
accuracy: 0.725000
Epoch 843, CIFAR-10 Batch 4:  loss: 1.221590
accuracy: 0.550000
Epoch 843, CIFAR-10 Batch 5:  loss: 1.008883
accuracy: 0.700000
Epoch 844, CIFAR-10 Batch 1:  loss: 0.728184
accuracy: 0.775000
Epoch 844, CIFAR-10 Batch 2:  loss: 1.031242
accuracy: 0.650000
Epoch 844, CIFAR-10 Batch 3:  loss: 0.808292
accuracy: 0.750000
Epoch 844, CIFAR-10 Batch 4:  loss: 1.261524
accuracy: 0.500000
Epoch 844, CIFAR-10 Batch 5:  loss: 0.996381
accuracy: 0.700000
Epoch 845, CIFAR-10 Batch 1:  loss: 0.752343
accuracy: 0.725000
Epoch 845, CIFAR-10 Batch 2:  loss: 0.902491
accuracy: 0.675000
Epoch 845, CIFAR-10 Batch 3:  loss: 0.778965
accuracy: 0.775000
Epoch 845, CIFAR-10 Batch 4:  loss: 1.206248
accuracy: 0.575000
Epoch 845, CIFAR-10 Batch 5:  loss: 1.003844
accuracy: 0.650000
Epoch 846, CIFAR-10 Batch 1:  loss: 0.753099
accuracy: 0.725000
Epoch 846, CIFAR-10 Batch 2:  loss: 0.895692
accuracy: 0.675000
Epoch 846, CIFAR-10 Batch 3:  loss: 0.778810
accuracy: 0.825000
Epoch 846, CIFAR-10 Batch 4:  loss: 1.253634
accuracy: 0.500000
Epoch 846, CIFAR-10 Batch 5:  loss: 0.970916
accuracy: 0.675000
Epoch 847, CIFAR-10 Batch 1:  loss: 0.720106
accuracy: 0.750000
Epoch 847, CIFAR-10 Batch 2:  loss: 0.902349
accuracy: 0.700000
Epoch 847, CIFAR-10 Batch 3:  loss: 0.784166
accuracy: 0.750000
Epoch 847, CIFAR-10 Batch 4:  loss: 1.261409
accuracy: 0.550000
Epoch 847, CIFAR-10 Batch 5:  loss: 0.972617
accuracy: 0.675000
Epoch 848, CIFAR-10 Batch 1:  loss: 0.726669
accuracy: 0.775000
Epoch 848, CIFAR-10 Batch 2:  loss: 0.907937
accuracy: 0.700000
Epoch 848, CIFAR-10 Batch 3:  loss: 0.806335
accuracy: 0.750000
Epoch 848, CIFAR-10 Batch 4:  loss: 1.225460
accuracy: 0.575000
Epoch 848, CIFAR-10 Batch 5:  loss: 0.984738
accuracy: 0.700000
Epoch 849, CIFAR-10 Batch 1:  loss: 0.734463
accuracy: 0.725000
Epoch 849, CIFAR-10 Batch 2:  loss: 0.921195
accuracy: 0.700000
Epoch 849, CIFAR-10 Batch 3:  loss: 0.765937
accuracy: 0.800000
Epoch 849, CIFAR-10 Batch 4:  loss: 1.260443
accuracy: 0.600000
Epoch 849, CIFAR-10 Batch 5:  loss: 0.987023
accuracy: 0.700000
Epoch 850, CIFAR-10 Batch 1:  loss: 0.753525
accuracy: 0.725000
Epoch 850, CIFAR-10 Batch 2:  loss: 0.896876
accuracy: 0.700000
Epoch 850, CIFAR-10 Batch 3:  loss: 0.752099
accuracy: 0.850000
Epoch 850, CIFAR-10 Batch 4:  loss: 1.236615
accuracy: 0.550000
Epoch 850, CIFAR-10 Batch 5:  loss: 0.987388
accuracy: 0.675000
Epoch 851, CIFAR-10 Batch 1:  loss: 0.740570
accuracy: 0.750000
Epoch 851, CIFAR-10 Batch 2:  loss: 0.959053
accuracy: 0.675000
Epoch 851, CIFAR-10 Batch 3:  loss: 0.788256
accuracy: 0.800000
Epoch 851, CIFAR-10 Batch 4:  loss: 1.243703
accuracy: 0.600000
Epoch 851, CIFAR-10 Batch 5:  loss: 0.979840
accuracy: 0.725000
Epoch 852, CIFAR-10 Batch 1:  loss: 0.720597
accuracy: 0.750000
Epoch 852, CIFAR-10 Batch 2:  loss: 0.977855
accuracy: 0.650000
Epoch 852, CIFAR-10 Batch 3:  loss: 0.774066
accuracy: 0.800000
Epoch 852, CIFAR-10 Batch 4:  loss: 1.264916
accuracy: 0.600000
Epoch 852, CIFAR-10 Batch 5:  loss: 0.983816
accuracy: 0.725000
Epoch 853, CIFAR-10 Batch 1:  loss: 0.749480
accuracy: 0.775000
Epoch 853, CIFAR-10 Batch 2:  loss: 0.936559
accuracy: 0.725000
Epoch 853, CIFAR-10 Batch 3:  loss: 0.783966
accuracy: 0.800000
Epoch 853, CIFAR-10 Batch 4:  loss: 1.249055
accuracy: 0.550000
Epoch 853, CIFAR-10 Batch 5:  loss: 1.003062
accuracy: 0.700000
Epoch 854, CIFAR-10 Batch 1:  loss: 0.759482
accuracy: 0.775000
Epoch 854, CIFAR-10 Batch 2:  loss: 0.921476
accuracy: 0.675000
Epoch 854, CIFAR-10 Batch 3:  loss: 0.747735
accuracy: 0.775000
Epoch 854, CIFAR-10 Batch 4:  loss: 1.240488
accuracy: 0.600000
Epoch 854, CIFAR-10 Batch 5:  loss: 0.977060
accuracy: 0.675000
Epoch 855, CIFAR-10 Batch 1:  loss: 0.735834
accuracy: 0.725000
Epoch 855, CIFAR-10 Batch 2:  loss: 0.910974
accuracy: 0.700000
Epoch 855, CIFAR-10 Batch 3:  loss: 0.756024
accuracy: 0.850000
Epoch 855, CIFAR-10 Batch 4:  loss: 1.261557
accuracy: 0.475000
Epoch 855, CIFAR-10 Batch 5:  loss: 0.970398
accuracy: 0.700000
Epoch 856, CIFAR-10 Batch 1:  loss: 0.740933
accuracy: 0.750000
Epoch 856, CIFAR-10 Batch 2:  loss: 0.934964
accuracy: 0.725000
Epoch 856, CIFAR-10 Batch 3:  loss: 0.804859
accuracy: 0.800000
Epoch 856, CIFAR-10 Batch 4:  loss: 1.287243
accuracy: 0.500000
Epoch 856, CIFAR-10 Batch 5:  loss: 0.960847
accuracy: 0.725000
Epoch 857, CIFAR-10 Batch 1:  loss: 0.765452
accuracy: 0.700000
Epoch 857, CIFAR-10 Batch 2:  loss: 0.899790
accuracy: 0.700000
Epoch 857, CIFAR-10 Batch 3:  loss: 0.780566
accuracy: 0.775000
Epoch 857, CIFAR-10 Batch 4:  loss: 1.245015
accuracy: 0.525000
Epoch 857, CIFAR-10 Batch 5:  loss: 0.962145
accuracy: 0.700000
Epoch 858, CIFAR-10 Batch 1:  loss: 0.751266
accuracy: 0.775000
Epoch 858, CIFAR-10 Batch 2:  loss: 0.968396
accuracy: 0.725000
Epoch 858, CIFAR-10 Batch 3:  loss: 0.776453
accuracy: 0.800000
Epoch 858, CIFAR-10 Batch 4:  loss: 1.339126
accuracy: 0.500000
Epoch 858, CIFAR-10 Batch 5:  loss: 0.977244
accuracy: 0.700000
Epoch 859, CIFAR-10 Batch 1:  loss: 0.751408
accuracy: 0.750000
Epoch 859, CIFAR-10 Batch 2:  loss: 0.936012
accuracy: 0.700000
Epoch 859, CIFAR-10 Batch 3:  loss: 0.784123
accuracy: 0.825000
Epoch 859, CIFAR-10 Batch 4:  loss: 1.226843
accuracy: 0.575000
Epoch 859, CIFAR-10 Batch 5:  loss: 0.969896
accuracy: 0.725000
Epoch 860, CIFAR-10 Batch 1:  loss: 0.761224
accuracy: 0.725000
Epoch 860, CIFAR-10 Batch 2:  loss: 0.908591
accuracy: 0.700000
Epoch 860, CIFAR-10 Batch 3:  loss: 0.772442
accuracy: 0.825000
Epoch 860, CIFAR-10 Batch 4:  loss: 1.222114
accuracy: 0.550000
Epoch 860, CIFAR-10 Batch 5:  loss: 0.972539
accuracy: 0.700000
Epoch 861, CIFAR-10 Batch 1:  loss: 0.732075
accuracy: 0.750000
Epoch 861, CIFAR-10 Batch 2:  loss: 0.918822
accuracy: 0.700000
Epoch 861, CIFAR-10 Batch 3:  loss: 0.777129
accuracy: 0.800000
Epoch 861, CIFAR-10 Batch 4:  loss: 1.226681
accuracy: 0.575000
Epoch 861, CIFAR-10 Batch 5:  loss: 0.975084
accuracy: 0.700000
Epoch 862, CIFAR-10 Batch 1:  loss: 0.743413
accuracy: 0.775000
Epoch 862, CIFAR-10 Batch 2:  loss: 0.915808
accuracy: 0.700000
Epoch 862, CIFAR-10 Batch 3:  loss: 0.795644
accuracy: 0.775000
Epoch 862, CIFAR-10 Batch 4:  loss: 1.234198
accuracy: 0.550000
Epoch 862, CIFAR-10 Batch 5:  loss: 0.933062
accuracy: 0.750000
Epoch 863, CIFAR-10 Batch 1:  loss: 0.737574
accuracy: 0.750000
Epoch 863, CIFAR-10 Batch 2:  loss: 0.898677
accuracy: 0.675000
Epoch 863, CIFAR-10 Batch 3:  loss: 0.842021
accuracy: 0.775000
Epoch 863, CIFAR-10 Batch 4:  loss: 1.211331
accuracy: 0.575000
Epoch 863, CIFAR-10 Batch 5:  loss: 1.010442
accuracy: 0.725000
Epoch 864, CIFAR-10 Batch 1:  loss: 0.766744
accuracy: 0.750000
Epoch 864, CIFAR-10 Batch 2:  loss: 0.909717
accuracy: 0.700000
Epoch 864, CIFAR-10 Batch 3:  loss: 0.834943
accuracy: 0.750000
Epoch 864, CIFAR-10 Batch 4:  loss: 1.254712
accuracy: 0.575000
Epoch 864, CIFAR-10 Batch 5:  loss: 0.954715
accuracy: 0.725000
Epoch 865, CIFAR-10 Batch 1:  loss: 0.720446
accuracy: 0.775000
Epoch 865, CIFAR-10 Batch 2:  loss: 0.931192
accuracy: 0.725000
Epoch 865, CIFAR-10 Batch 3:  loss: 0.861642
accuracy: 0.750000
Epoch 865, CIFAR-10 Batch 4:  loss: 1.239447
accuracy: 0.550000
Epoch 865, CIFAR-10 Batch 5:  loss: 0.980736
accuracy: 0.725000
Epoch 866, CIFAR-10 Batch 1:  loss: 0.747939
accuracy: 0.800000
Epoch 866, CIFAR-10 Batch 2:  loss: 0.914928
accuracy: 0.725000
Epoch 866, CIFAR-10 Batch 3:  loss: 0.814148
accuracy: 0.750000
Epoch 866, CIFAR-10 Batch 4:  loss: 1.250395
accuracy: 0.500000
Epoch 866, CIFAR-10 Batch 5:  loss: 0.987646
accuracy: 0.650000
Epoch 867, CIFAR-10 Batch 1:  loss: 0.759449
accuracy: 0.750000
Epoch 867, CIFAR-10 Batch 2:  loss: 1.072354
accuracy: 0.700000
Epoch 867, CIFAR-10 Batch 3:  loss: 0.810230
accuracy: 0.725000
Epoch 867, CIFAR-10 Batch 4:  loss: 1.223902
accuracy: 0.550000
Epoch 867, CIFAR-10 Batch 5:  loss: 1.007951
accuracy: 0.700000
Epoch 868, CIFAR-10 Batch 1:  loss: 0.766649
accuracy: 0.775000
Epoch 868, CIFAR-10 Batch 2:  loss: 1.999598
accuracy: 0.675000
Epoch 868, CIFAR-10 Batch 3:  loss: 0.784954
accuracy: 0.800000
Epoch 868, CIFAR-10 Batch 4:  loss: 1.224399
accuracy: 0.550000
Epoch 868, CIFAR-10 Batch 5:  loss: 1.018023
accuracy: 0.700000
Epoch 869, CIFAR-10 Batch 1:  loss: 0.780256
accuracy: 0.750000
Epoch 869, CIFAR-10 Batch 2:  loss: 0.820596
accuracy: 0.725000
Epoch 869, CIFAR-10 Batch 3:  loss: 0.784215
accuracy: 0.800000
Epoch 869, CIFAR-10 Batch 4:  loss: 1.227495
accuracy: 0.525000
Epoch 869, CIFAR-10 Batch 5:  loss: 0.998018
accuracy: 0.625000
Epoch 870, CIFAR-10 Batch 1:  loss: 0.762662
accuracy: 0.750000
Epoch 870, CIFAR-10 Batch 2:  loss: 0.894656
accuracy: 0.700000
Epoch 870, CIFAR-10 Batch 3:  loss: 0.809829
accuracy: 0.750000
Epoch 870, CIFAR-10 Batch 4:  loss: 1.294430
accuracy: 0.550000
Epoch 870, CIFAR-10 Batch 5:  loss: 1.025155
accuracy: 0.650000
Epoch 871, CIFAR-10 Batch 1:  loss: 0.782369
accuracy: 0.725000
Epoch 871, CIFAR-10 Batch 2:  loss: 0.855717
accuracy: 0.750000
Epoch 871, CIFAR-10 Batch 3:  loss: 0.765311
accuracy: 0.800000
Epoch 871, CIFAR-10 Batch 4:  loss: 1.241952
accuracy: 0.575000
Epoch 871, CIFAR-10 Batch 5:  loss: 0.987517
accuracy: 0.700000
Epoch 872, CIFAR-10 Batch 1:  loss: 0.720917
accuracy: 0.800000
Epoch 872, CIFAR-10 Batch 2:  loss: 2.161771
accuracy: 0.675000
Epoch 872, CIFAR-10 Batch 3:  loss: 0.776782
accuracy: 0.775000
Epoch 872, CIFAR-10 Batch 4:  loss: 1.259778
accuracy: 0.550000
Epoch 872, CIFAR-10 Batch 5:  loss: 0.980340
accuracy: 0.675000
Epoch 873, CIFAR-10 Batch 1:  loss: 0.751216
accuracy: 0.775000
Epoch 873, CIFAR-10 Batch 2:  loss: 1.070736
accuracy: 0.700000
Epoch 873, CIFAR-10 Batch 3:  loss: 0.787212
accuracy: 0.775000
Epoch 873, CIFAR-10 Batch 4:  loss: 1.240016
accuracy: 0.500000
Epoch 873, CIFAR-10 Batch 5:  loss: 1.002705
accuracy: 0.725000
Epoch 874, CIFAR-10 Batch 1:  loss: 0.747345
accuracy: 0.775000
Epoch 874, CIFAR-10 Batch 2:  loss: 0.872159
accuracy: 0.675000
Epoch 874, CIFAR-10 Batch 3:  loss: 0.754176
accuracy: 0.825000
Epoch 874, CIFAR-10 Batch 4:  loss: 1.261395
accuracy: 0.500000
Epoch 874, CIFAR-10 Batch 5:  loss: 0.971837
accuracy: 0.625000
Epoch 875, CIFAR-10 Batch 1:  loss: 0.764456
accuracy: 0.750000
Epoch 875, CIFAR-10 Batch 2:  loss: 0.859861
accuracy: 0.700000
Epoch 875, CIFAR-10 Batch 3:  loss: 0.793844
accuracy: 0.775000
Epoch 875, CIFAR-10 Batch 4:  loss: 1.249158
accuracy: 0.500000
Epoch 875, CIFAR-10 Batch 5:  loss: 0.980081
accuracy: 0.725000
Epoch 876, CIFAR-10 Batch 1:  loss: 0.758336
accuracy: 0.775000
Epoch 876, CIFAR-10 Batch 2:  loss: 0.858544
accuracy: 0.725000
Epoch 876, CIFAR-10 Batch 3:  loss: 0.820311
accuracy: 0.775000
Epoch 876, CIFAR-10 Batch 4:  loss: 1.231884
accuracy: 0.475000
Epoch 876, CIFAR-10 Batch 5:  loss: 0.949222
accuracy: 0.725000
Epoch 877, CIFAR-10 Batch 1:  loss: 0.774998
accuracy: 0.775000
Epoch 877, CIFAR-10 Batch 2:  loss: 0.825109
accuracy: 0.725000
Epoch 877, CIFAR-10 Batch 3:  loss: 0.854694
accuracy: 0.750000
Epoch 877, CIFAR-10 Batch 4:  loss: 1.250433
accuracy: 0.550000
Epoch 877, CIFAR-10 Batch 5:  loss: 1.014050
accuracy: 0.675000
Epoch 878, CIFAR-10 Batch 1:  loss: 0.775940
accuracy: 0.750000
Epoch 878, CIFAR-10 Batch 2:  loss: 0.814908
accuracy: 0.725000
Epoch 878, CIFAR-10 Batch 3:  loss: 0.792470
accuracy: 0.800000
Epoch 878, CIFAR-10 Batch 4:  loss: 1.211629
accuracy: 0.600000
Epoch 878, CIFAR-10 Batch 5:  loss: 1.012819
accuracy: 0.650000
Epoch 879, CIFAR-10 Batch 1:  loss: 0.764864
accuracy: 0.750000
Epoch 879, CIFAR-10 Batch 2:  loss: 0.817699
accuracy: 0.750000
Epoch 879, CIFAR-10 Batch 3:  loss: 0.807599
accuracy: 0.825000
Epoch 879, CIFAR-10 Batch 4:  loss: 1.249344
accuracy: 0.550000
Epoch 879, CIFAR-10 Batch 5:  loss: 1.008682
accuracy: 0.625000
Epoch 880, CIFAR-10 Batch 1:  loss: 0.751955
accuracy: 0.775000
Epoch 880, CIFAR-10 Batch 2:  loss: 0.838537
accuracy: 0.700000
Epoch 880, CIFAR-10 Batch 3:  loss: 0.781846
accuracy: 0.825000
Epoch 880, CIFAR-10 Batch 4:  loss: 1.237309
accuracy: 0.550000
Epoch 880, CIFAR-10 Batch 5:  loss: 0.990110
accuracy: 0.725000
Epoch 881, CIFAR-10 Batch 1:  loss: 0.755448
accuracy: 0.775000
Epoch 881, CIFAR-10 Batch 2:  loss: 0.822562
accuracy: 0.725000
Epoch 881, CIFAR-10 Batch 3:  loss: 0.788653
accuracy: 0.800000
Epoch 881, CIFAR-10 Batch 4:  loss: 1.242962
accuracy: 0.525000
Epoch 881, CIFAR-10 Batch 5:  loss: 0.992971
accuracy: 0.750000
Epoch 882, CIFAR-10 Batch 1:  loss: 0.791708
accuracy: 0.725000
Epoch 882, CIFAR-10 Batch 2:  loss: 0.823069
accuracy: 0.700000
Epoch 882, CIFAR-10 Batch 3:  loss: 0.783267
accuracy: 0.800000
Epoch 882, CIFAR-10 Batch 4:  loss: 1.237651
accuracy: 0.550000
Epoch 882, CIFAR-10 Batch 5:  loss: 0.994433
accuracy: 0.675000
Epoch 883, CIFAR-10 Batch 1:  loss: 0.765584
accuracy: 0.750000
Epoch 883, CIFAR-10 Batch 2:  loss: 0.850795
accuracy: 0.700000
Epoch 883, CIFAR-10 Batch 3:  loss: 0.824927
accuracy: 0.750000
Epoch 883, CIFAR-10 Batch 4:  loss: 1.236605
accuracy: 0.525000
Epoch 883, CIFAR-10 Batch 5:  loss: 1.016230
accuracy: 0.725000
Epoch 884, CIFAR-10 Batch 1:  loss: 0.774397
accuracy: 0.750000
Epoch 884, CIFAR-10 Batch 2:  loss: 0.833628
accuracy: 0.725000
Epoch 884, CIFAR-10 Batch 3:  loss: 0.844473
accuracy: 0.750000
Epoch 884, CIFAR-10 Batch 4:  loss: 1.239333
accuracy: 0.550000
Epoch 884, CIFAR-10 Batch 5:  loss: 0.988745
accuracy: 0.650000
Epoch 885, CIFAR-10 Batch 1:  loss: 0.736002
accuracy: 0.750000
Epoch 885, CIFAR-10 Batch 2:  loss: 0.835899
accuracy: 0.725000
Epoch 885, CIFAR-10 Batch 3:  loss: 0.797050
accuracy: 0.775000
Epoch 885, CIFAR-10 Batch 4:  loss: 1.228577
accuracy: 0.525000
Epoch 885, CIFAR-10 Batch 5:  loss: 0.984013
accuracy: 0.725000
Epoch 886, CIFAR-10 Batch 1:  loss: 0.790950
accuracy: 0.725000
Epoch 886, CIFAR-10 Batch 2:  loss: 0.821657
accuracy: 0.725000
Epoch 886, CIFAR-10 Batch 3:  loss: 0.811479
accuracy: 0.775000
Epoch 886, CIFAR-10 Batch 4:  loss: 1.204263
accuracy: 0.575000
Epoch 886, CIFAR-10 Batch 5:  loss: 1.005629
accuracy: 0.650000
Epoch 887, CIFAR-10 Batch 1:  loss: 0.733214
accuracy: 0.800000
Epoch 887, CIFAR-10 Batch 2:  loss: 0.822522
accuracy: 0.700000
Epoch 887, CIFAR-10 Batch 3:  loss: 0.834463
accuracy: 0.750000
Epoch 887, CIFAR-10 Batch 4:  loss: 1.224570
accuracy: 0.625000
Epoch 887, CIFAR-10 Batch 5:  loss: 1.009812
accuracy: 0.675000
Epoch 888, CIFAR-10 Batch 1:  loss: 0.758128
accuracy: 0.725000
Epoch 888, CIFAR-10 Batch 2:  loss: 0.838539
accuracy: 0.750000
Epoch 888, CIFAR-10 Batch 3:  loss: 0.859342
accuracy: 0.750000
Epoch 888, CIFAR-10 Batch 4:  loss: 1.258772
accuracy: 0.500000
Epoch 888, CIFAR-10 Batch 5:  loss: 0.992829
accuracy: 0.700000
Epoch 889, CIFAR-10 Batch 1:  loss: 0.780543
accuracy: 0.775000
Epoch 889, CIFAR-10 Batch 2:  loss: 0.871890
accuracy: 0.700000
Epoch 889, CIFAR-10 Batch 3:  loss: 0.849331
accuracy: 0.725000
Epoch 889, CIFAR-10 Batch 4:  loss: 1.227231
accuracy: 0.550000
Epoch 889, CIFAR-10 Batch 5:  loss: 0.994162
accuracy: 0.675000
Epoch 890, CIFAR-10 Batch 1:  loss: 0.746631
accuracy: 0.750000
Epoch 890, CIFAR-10 Batch 2:  loss: 0.842371
accuracy: 0.750000
Epoch 890, CIFAR-10 Batch 3:  loss: 0.864894
accuracy: 0.750000
Epoch 890, CIFAR-10 Batch 4:  loss: 1.252562
accuracy: 0.575000
Epoch 890, CIFAR-10 Batch 5:  loss: 1.011895
accuracy: 0.675000
Epoch 891, CIFAR-10 Batch 1:  loss: 0.738882
accuracy: 0.750000
Epoch 891, CIFAR-10 Batch 2:  loss: 0.842648
accuracy: 0.675000
Epoch 891, CIFAR-10 Batch 3:  loss: 0.827624
accuracy: 0.775000
Epoch 891, CIFAR-10 Batch 4:  loss: 1.283904
accuracy: 0.500000
Epoch 891, CIFAR-10 Batch 5:  loss: 1.017655
accuracy: 0.700000
Epoch 892, CIFAR-10 Batch 1:  loss: 0.756669
accuracy: 0.775000
Epoch 892, CIFAR-10 Batch 2:  loss: 2.141531
accuracy: 0.650000
Epoch 892, CIFAR-10 Batch 3:  loss: 0.795180
accuracy: 0.750000
Epoch 892, CIFAR-10 Batch 4:  loss: 1.260962
accuracy: 0.525000
Epoch 892, CIFAR-10 Batch 5:  loss: 0.989828
accuracy: 0.675000
Epoch 893, CIFAR-10 Batch 1:  loss: 0.722893
accuracy: 0.750000
Epoch 893, CIFAR-10 Batch 2:  loss: 0.823847
accuracy: 0.725000
Epoch 893, CIFAR-10 Batch 3:  loss: 0.823533
accuracy: 0.800000
Epoch 893, CIFAR-10 Batch 4:  loss: 2.478782
accuracy: 0.500000
Epoch 893, CIFAR-10 Batch 5:  loss: 1.005627
accuracy: 0.650000
Epoch 894, CIFAR-10 Batch 1:  loss: 0.727200
accuracy: 0.750000
Epoch 894, CIFAR-10 Batch 2:  loss: 0.838531
accuracy: 0.700000
Epoch 894, CIFAR-10 Batch 3:  loss: 0.847790
accuracy: 0.750000
Epoch 894, CIFAR-10 Batch 4:  loss: 1.262536
accuracy: 0.550000
Epoch 894, CIFAR-10 Batch 5:  loss: 0.969551
accuracy: 0.725000
Epoch 895, CIFAR-10 Batch 1:  loss: 0.742398
accuracy: 0.750000
Epoch 895, CIFAR-10 Batch 2:  loss: 0.829555
accuracy: 0.725000
Epoch 895, CIFAR-10 Batch 3:  loss: 0.805478
accuracy: 0.775000
Epoch 895, CIFAR-10 Batch 4:  loss: 1.234370
accuracy: 0.575000
Epoch 895, CIFAR-10 Batch 5:  loss: 0.991505
accuracy: 0.725000
Epoch 896, CIFAR-10 Batch 1:  loss: 0.729285
accuracy: 0.800000
Epoch 896, CIFAR-10 Batch 2:  loss: 0.840895
accuracy: 0.700000
Epoch 896, CIFAR-10 Batch 3:  loss: 0.786742
accuracy: 0.825000
Epoch 896, CIFAR-10 Batch 4:  loss: 1.236282
accuracy: 0.500000
Epoch 896, CIFAR-10 Batch 5:  loss: 0.982729
accuracy: 0.650000
Epoch 897, CIFAR-10 Batch 1:  loss: 0.701748
accuracy: 0.750000
Epoch 897, CIFAR-10 Batch 2:  loss: 0.886851
accuracy: 0.675000
Epoch 897, CIFAR-10 Batch 3:  loss: 0.803965
accuracy: 0.775000
Epoch 897, CIFAR-10 Batch 4:  loss: 1.265051
accuracy: 0.500000
Epoch 897, CIFAR-10 Batch 5:  loss: 0.989285
accuracy: 0.700000
Epoch 898, CIFAR-10 Batch 1:  loss: 0.701934
accuracy: 0.750000
Epoch 898, CIFAR-10 Batch 2:  loss: 0.848249
accuracy: 0.700000
Epoch 898, CIFAR-10 Batch 3:  loss: 0.805509
accuracy: 0.800000
Epoch 898, CIFAR-10 Batch 4:  loss: 1.259390
accuracy: 0.500000
Epoch 898, CIFAR-10 Batch 5:  loss: 0.963086
accuracy: 0.650000
Epoch 899, CIFAR-10 Batch 1:  loss: 0.726625
accuracy: 0.775000
Epoch 899, CIFAR-10 Batch 2:  loss: 0.842379
accuracy: 0.725000
Epoch 899, CIFAR-10 Batch 3:  loss: 0.787198
accuracy: 0.750000
Epoch 899, CIFAR-10 Batch 4:  loss: 1.261498
accuracy: 0.475000
Epoch 899, CIFAR-10 Batch 5:  loss: 0.999923
accuracy: 0.675000
Epoch 900, CIFAR-10 Batch 1:  loss: 0.704206
accuracy: 0.775000
Epoch 900, CIFAR-10 Batch 2:  loss: 0.879277
accuracy: 0.700000
Epoch 900, CIFAR-10 Batch 3:  loss: 0.837874
accuracy: 0.775000
Epoch 900, CIFAR-10 Batch 4:  loss: 1.255425
accuracy: 0.500000
Epoch 900, CIFAR-10 Batch 5:  loss: 1.001931
accuracy: 0.725000
Epoch 901, CIFAR-10 Batch 1:  loss: 0.737412
accuracy: 0.750000
Epoch 901, CIFAR-10 Batch 2:  loss: 0.845783
accuracy: 0.725000
Epoch 901, CIFAR-10 Batch 3:  loss: 0.836129
accuracy: 0.775000
Epoch 901, CIFAR-10 Batch 4:  loss: 1.223289
accuracy: 0.525000
Epoch 901, CIFAR-10 Batch 5:  loss: 1.010723
accuracy: 0.675000
Epoch 902, CIFAR-10 Batch 1:  loss: 0.757482
accuracy: 0.750000
Epoch 902, CIFAR-10 Batch 2:  loss: 0.879648
accuracy: 0.675000
Epoch 902, CIFAR-10 Batch 3:  loss: 0.870550
accuracy: 0.775000
Epoch 902, CIFAR-10 Batch 4:  loss: 1.245985
accuracy: 0.525000
Epoch 902, CIFAR-10 Batch 5:  loss: 1.009946
accuracy: 0.650000
Epoch 903, CIFAR-10 Batch 1:  loss: 0.736270
accuracy: 0.750000
Epoch 903, CIFAR-10 Batch 2:  loss: 0.849643
accuracy: 0.700000
Epoch 903, CIFAR-10 Batch 3:  loss: 0.807217
accuracy: 0.800000
Epoch 903, CIFAR-10 Batch 4:  loss: 1.241428
accuracy: 0.525000
Epoch 903, CIFAR-10 Batch 5:  loss: 0.983775
accuracy: 0.700000
Epoch 904, CIFAR-10 Batch 1:  loss: 0.712676
accuracy: 0.775000
Epoch 904, CIFAR-10 Batch 2:  loss: 0.836744
accuracy: 0.700000
Epoch 904, CIFAR-10 Batch 3:  loss: 0.793507
accuracy: 0.800000
Epoch 904, CIFAR-10 Batch 4:  loss: 1.215181
accuracy: 0.575000
Epoch 904, CIFAR-10 Batch 5:  loss: 0.997465
accuracy: 0.675000
Epoch 905, CIFAR-10 Batch 1:  loss: 0.720160
accuracy: 0.775000
Epoch 905, CIFAR-10 Batch 2:  loss: 0.823600
accuracy: 0.700000
Epoch 905, CIFAR-10 Batch 3:  loss: 0.837455
accuracy: 0.775000
Epoch 905, CIFAR-10 Batch 4:  loss: 1.226739
accuracy: 0.550000
Epoch 905, CIFAR-10 Batch 5:  loss: 0.984665
accuracy: 0.650000
Epoch 906, CIFAR-10 Batch 1:  loss: 0.790774
accuracy: 0.750000
Epoch 906, CIFAR-10 Batch 2:  loss: 0.837411
accuracy: 0.725000
Epoch 906, CIFAR-10 Batch 3:  loss: 0.815950
accuracy: 0.750000
Epoch 906, CIFAR-10 Batch 4:  loss: 1.240902
accuracy: 0.575000
Epoch 906, CIFAR-10 Batch 5:  loss: 1.020601
accuracy: 0.625000
Epoch 907, CIFAR-10 Batch 1:  loss: 0.774159
accuracy: 0.725000
Epoch 907, CIFAR-10 Batch 2:  loss: 0.817463
accuracy: 0.725000
Epoch 907, CIFAR-10 Batch 3:  loss: 0.810772
accuracy: 0.775000
Epoch 907, CIFAR-10 Batch 4:  loss: 1.198735
accuracy: 0.600000
Epoch 907, CIFAR-10 Batch 5:  loss: 0.991375
accuracy: 0.650000
Epoch 908, CIFAR-10 Batch 1:  loss: 0.769379
accuracy: 0.750000
Epoch 908, CIFAR-10 Batch 2:  loss: 0.832467
accuracy: 0.675000
Epoch 908, CIFAR-10 Batch 3:  loss: 0.798893
accuracy: 0.775000
Epoch 908, CIFAR-10 Batch 4:  loss: 1.237201
accuracy: 0.525000
Epoch 908, CIFAR-10 Batch 5:  loss: 0.966863
accuracy: 0.625000
Epoch 909, CIFAR-10 Batch 1:  loss: 0.700273
accuracy: 0.775000
Epoch 909, CIFAR-10 Batch 2:  loss: 0.849854
accuracy: 0.725000
Epoch 909, CIFAR-10 Batch 3:  loss: 0.812935
accuracy: 0.800000
Epoch 909, CIFAR-10 Batch 4:  loss: 1.276859
accuracy: 0.575000
Epoch 909, CIFAR-10 Batch 5:  loss: 1.011333
accuracy: 0.650000
Epoch 910, CIFAR-10 Batch 1:  loss: 0.733776
accuracy: 0.750000
Epoch 910, CIFAR-10 Batch 2:  loss: 0.832398
accuracy: 0.725000
Epoch 910, CIFAR-10 Batch 3:  loss: 0.824160
accuracy: 0.775000
Epoch 910, CIFAR-10 Batch 4:  loss: 1.205099
accuracy: 0.575000
Epoch 910, CIFAR-10 Batch 5:  loss: 0.967498
accuracy: 0.675000
Epoch 911, CIFAR-10 Batch 1:  loss: 0.719285
accuracy: 0.750000
Epoch 911, CIFAR-10 Batch 2:  loss: 0.838840
accuracy: 0.725000
Epoch 911, CIFAR-10 Batch 3:  loss: 0.818306
accuracy: 0.800000
Epoch 911, CIFAR-10 Batch 4:  loss: 1.227654
accuracy: 0.550000
Epoch 911, CIFAR-10 Batch 5:  loss: 0.994699
accuracy: 0.650000
Epoch 912, CIFAR-10 Batch 1:  loss: 0.738187
accuracy: 0.750000
Epoch 912, CIFAR-10 Batch 2:  loss: 0.882848
accuracy: 0.675000
Epoch 912, CIFAR-10 Batch 3:  loss: 0.830670
accuracy: 0.800000
Epoch 912, CIFAR-10 Batch 4:  loss: 1.248215
accuracy: 0.575000
Epoch 912, CIFAR-10 Batch 5:  loss: 0.959434
accuracy: 0.675000
Epoch 913, CIFAR-10 Batch 1:  loss: 0.716581
accuracy: 0.800000
Epoch 913, CIFAR-10 Batch 2:  loss: 0.850988
accuracy: 0.725000
Epoch 913, CIFAR-10 Batch 3:  loss: 0.778863
accuracy: 0.825000
Epoch 913, CIFAR-10 Batch 4:  loss: 1.283333
accuracy: 0.525000
Epoch 913, CIFAR-10 Batch 5:  loss: 0.978616
accuracy: 0.675000
Epoch 914, CIFAR-10 Batch 1:  loss: 0.718817
accuracy: 0.750000
Epoch 914, CIFAR-10 Batch 2:  loss: 0.873465
accuracy: 0.700000
Epoch 914, CIFAR-10 Batch 3:  loss: 0.770341
accuracy: 0.800000
Epoch 914, CIFAR-10 Batch 4:  loss: 1.245275
accuracy: 0.575000
Epoch 914, CIFAR-10 Batch 5:  loss: 0.967641
accuracy: 0.650000
Epoch 915, CIFAR-10 Batch 1:  loss: 0.713518
accuracy: 0.775000
Epoch 915, CIFAR-10 Batch 2:  loss: 0.826647
accuracy: 0.700000
Epoch 915, CIFAR-10 Batch 3:  loss: 0.784354
accuracy: 0.800000
Epoch 915, CIFAR-10 Batch 4:  loss: 1.254797
accuracy: 0.525000
Epoch 915, CIFAR-10 Batch 5:  loss: 0.986272
accuracy: 0.675000
Epoch 916, CIFAR-10 Batch 1:  loss: 0.731201
accuracy: 0.750000
Epoch 916, CIFAR-10 Batch 2:  loss: 0.860772
accuracy: 0.700000
Epoch 916, CIFAR-10 Batch 3:  loss: 0.783188
accuracy: 0.825000
Epoch 916, CIFAR-10 Batch 4:  loss: 1.919528
accuracy: 0.500000
Epoch 916, CIFAR-10 Batch 5:  loss: 0.996959
accuracy: 0.650000
Epoch 917, CIFAR-10 Batch 1:  loss: 0.722884
accuracy: 0.775000
Epoch 917, CIFAR-10 Batch 2:  loss: 0.825388
accuracy: 0.700000
Epoch 917, CIFAR-10 Batch 3:  loss: 0.813080
accuracy: 0.800000
Epoch 917, CIFAR-10 Batch 4:  loss: 1.224782
accuracy: 0.550000
Epoch 917, CIFAR-10 Batch 5:  loss: 0.990843
accuracy: 0.625000
Epoch 918, CIFAR-10 Batch 1:  loss: 0.735492
accuracy: 0.750000
Epoch 918, CIFAR-10 Batch 2:  loss: 0.846450
accuracy: 0.700000
Epoch 918, CIFAR-10 Batch 3:  loss: 0.738354
accuracy: 0.800000
Epoch 918, CIFAR-10 Batch 4:  loss: 1.273893
accuracy: 0.475000
Epoch 918, CIFAR-10 Batch 5:  loss: 0.945914
accuracy: 0.700000
Epoch 919, CIFAR-10 Batch 1:  loss: 0.732642
accuracy: 0.725000
Epoch 919, CIFAR-10 Batch 2:  loss: 0.846296
accuracy: 0.675000
Epoch 919, CIFAR-10 Batch 3:  loss: 0.783404
accuracy: 0.800000
Epoch 919, CIFAR-10 Batch 4:  loss: 1.206563
accuracy: 0.575000
Epoch 919, CIFAR-10 Batch 5:  loss: 0.954470
accuracy: 0.675000
Epoch 920, CIFAR-10 Batch 1:  loss: 0.739014
accuracy: 0.725000
Epoch 920, CIFAR-10 Batch 2:  loss: 0.835250
accuracy: 0.750000
Epoch 920, CIFAR-10 Batch 3:  loss: 0.772765
accuracy: 0.825000
Epoch 920, CIFAR-10 Batch 4:  loss: 1.237135
accuracy: 0.550000
Epoch 920, CIFAR-10 Batch 5:  loss: 0.990637
accuracy: 0.625000
Epoch 921, CIFAR-10 Batch 1:  loss: 0.728747
accuracy: 0.750000
Epoch 921, CIFAR-10 Batch 2:  loss: 0.815814
accuracy: 0.700000
Epoch 921, CIFAR-10 Batch 3:  loss: 0.794203
accuracy: 0.800000
Epoch 921, CIFAR-10 Batch 4:  loss: 1.260179
accuracy: 0.500000
Epoch 921, CIFAR-10 Batch 5:  loss: 1.014601
accuracy: 0.650000
Epoch 922, CIFAR-10 Batch 1:  loss: 0.720458
accuracy: 0.750000
Epoch 922, CIFAR-10 Batch 2:  loss: 0.830985
accuracy: 0.750000
Epoch 922, CIFAR-10 Batch 3:  loss: 0.788949
accuracy: 0.800000
Epoch 922, CIFAR-10 Batch 4:  loss: 1.243413
accuracy: 0.500000
Epoch 922, CIFAR-10 Batch 5:  loss: 0.982497
accuracy: 0.700000
Epoch 923, CIFAR-10 Batch 1:  loss: 0.735515
accuracy: 0.750000
Epoch 923, CIFAR-10 Batch 2:  loss: 0.841227
accuracy: 0.725000
Epoch 923, CIFAR-10 Batch 3:  loss: 0.804476
accuracy: 0.800000
Epoch 923, CIFAR-10 Batch 4:  loss: 1.251271
accuracy: 0.525000
Epoch 923, CIFAR-10 Batch 5:  loss: 1.005129
accuracy: 0.625000
Epoch 924, CIFAR-10 Batch 1:  loss: 0.729362
accuracy: 0.775000
Epoch 924, CIFAR-10 Batch 2:  loss: 0.836094
accuracy: 0.725000
Epoch 924, CIFAR-10 Batch 3:  loss: 0.818244
accuracy: 0.800000
Epoch 924, CIFAR-10 Batch 4:  loss: 1.273565
accuracy: 0.475000
Epoch 924, CIFAR-10 Batch 5:  loss: 1.004381
accuracy: 0.675000
Epoch 925, CIFAR-10 Batch 1:  loss: 0.753694
accuracy: 0.750000
Epoch 925, CIFAR-10 Batch 2:  loss: 0.857123
accuracy: 0.700000
Epoch 925, CIFAR-10 Batch 3:  loss: 0.807444
accuracy: 0.800000
Epoch 925, CIFAR-10 Batch 4:  loss: 1.249617
accuracy: 0.525000
Epoch 925, CIFAR-10 Batch 5:  loss: 0.982863
accuracy: 0.650000
Epoch 926, CIFAR-10 Batch 1:  loss: 0.720479
accuracy: 0.775000
Epoch 926, CIFAR-10 Batch 2:  loss: 0.842195
accuracy: 0.750000
Epoch 926, CIFAR-10 Batch 3:  loss: 0.840602
accuracy: 0.800000
Epoch 926, CIFAR-10 Batch 4:  loss: 1.278555
accuracy: 0.500000
Epoch 926, CIFAR-10 Batch 5:  loss: 1.052689
accuracy: 0.625000
Epoch 927, CIFAR-10 Batch 1:  loss: 0.742923
accuracy: 0.750000
Epoch 927, CIFAR-10 Batch 2:  loss: 0.833742
accuracy: 0.750000
Epoch 927, CIFAR-10 Batch 3:  loss: 0.773961
accuracy: 0.800000
Epoch 927, CIFAR-10 Batch 4:  loss: 1.272765
accuracy: 0.500000
Epoch 927, CIFAR-10 Batch 5:  loss: 0.978492
accuracy: 0.725000
Epoch 928, CIFAR-10 Batch 1:  loss: 0.776590
accuracy: 0.725000
Epoch 928, CIFAR-10 Batch 2:  loss: 0.852115
accuracy: 0.675000
Epoch 928, CIFAR-10 Batch 3:  loss: 0.768705
accuracy: 0.825000
Epoch 928, CIFAR-10 Batch 4:  loss: 1.256693
accuracy: 0.550000
Epoch 928, CIFAR-10 Batch 5:  loss: 0.967086
accuracy: 0.675000
Epoch 929, CIFAR-10 Batch 1:  loss: 0.717444
accuracy: 0.750000
Epoch 929, CIFAR-10 Batch 2:  loss: 0.842853
accuracy: 0.750000
Epoch 929, CIFAR-10 Batch 3:  loss: 0.772610
accuracy: 0.775000
Epoch 929, CIFAR-10 Batch 4:  loss: 1.247924
accuracy: 0.525000
Epoch 929, CIFAR-10 Batch 5:  loss: 0.956679
accuracy: 0.675000
Epoch 930, CIFAR-10 Batch 1:  loss: 0.734725
accuracy: 0.750000
Epoch 930, CIFAR-10 Batch 2:  loss: 0.858557
accuracy: 0.750000
Epoch 930, CIFAR-10 Batch 3:  loss: 0.752303
accuracy: 0.800000
Epoch 930, CIFAR-10 Batch 4:  loss: 1.234606
accuracy: 0.575000
Epoch 930, CIFAR-10 Batch 5:  loss: 0.973843
accuracy: 0.700000
Epoch 931, CIFAR-10 Batch 1:  loss: 0.723506
accuracy: 0.750000
Epoch 931, CIFAR-10 Batch 2:  loss: 0.825500
accuracy: 0.750000
Epoch 931, CIFAR-10 Batch 3:  loss: 0.794520
accuracy: 0.775000
Epoch 931, CIFAR-10 Batch 4:  loss: 1.249516
accuracy: 0.550000
Epoch 931, CIFAR-10 Batch 5:  loss: 0.939758
accuracy: 0.700000
Epoch 932, CIFAR-10 Batch 1:  loss: 0.732165
accuracy: 0.750000
Epoch 932, CIFAR-10 Batch 2:  loss: 0.811933
accuracy: 0.750000
Epoch 932, CIFAR-10 Batch 3:  loss: 0.782364
accuracy: 0.775000
Epoch 932, CIFAR-10 Batch 4:  loss: 1.223627
accuracy: 0.575000
Epoch 932, CIFAR-10 Batch 5:  loss: 1.011454
accuracy: 0.675000
Epoch 933, CIFAR-10 Batch 1:  loss: 0.759443
accuracy: 0.725000
Epoch 933, CIFAR-10 Batch 2:  loss: 0.835477
accuracy: 0.675000
Epoch 933, CIFAR-10 Batch 3:  loss: 0.790608
accuracy: 0.775000
Epoch 933, CIFAR-10 Batch 4:  loss: 1.228817
accuracy: 0.550000
Epoch 933, CIFAR-10 Batch 5:  loss: 0.993442
accuracy: 0.675000
Epoch 934, CIFAR-10 Batch 1:  loss: 0.725196
accuracy: 0.750000
Epoch 934, CIFAR-10 Batch 2:  loss: 0.819672
accuracy: 0.750000
Epoch 934, CIFAR-10 Batch 3:  loss: 0.802540
accuracy: 0.800000
Epoch 934, CIFAR-10 Batch 4:  loss: 1.216647
accuracy: 0.575000
Epoch 934, CIFAR-10 Batch 5:  loss: 1.007993
accuracy: 0.650000
Epoch 935, CIFAR-10 Batch 1:  loss: 0.760558
accuracy: 0.750000
Epoch 935, CIFAR-10 Batch 2:  loss: 0.814435
accuracy: 0.725000
Epoch 935, CIFAR-10 Batch 3:  loss: 0.789505
accuracy: 0.750000
Epoch 935, CIFAR-10 Batch 4:  loss: 1.256795
accuracy: 0.500000
Epoch 935, CIFAR-10 Batch 5:  loss: 1.014858
accuracy: 0.675000
Epoch 936, CIFAR-10 Batch 1:  loss: 0.742149
accuracy: 0.725000
Epoch 936, CIFAR-10 Batch 2:  loss: 0.956284
accuracy: 0.725000
Epoch 936, CIFAR-10 Batch 3:  loss: 0.798139
accuracy: 0.775000
Epoch 936, CIFAR-10 Batch 4:  loss: 1.303644
accuracy: 0.475000
Epoch 936, CIFAR-10 Batch 5:  loss: 1.019215
accuracy: 0.650000
Epoch 937, CIFAR-10 Batch 1:  loss: 0.717312
accuracy: 0.800000
Epoch 937, CIFAR-10 Batch 2:  loss: 0.836760
accuracy: 0.725000
Epoch 937, CIFAR-10 Batch 3:  loss: 0.745467
accuracy: 0.775000
Epoch 937, CIFAR-10 Batch 4:  loss: 1.275475
accuracy: 0.500000
Epoch 937, CIFAR-10 Batch 5:  loss: 0.976411
accuracy: 0.650000
Epoch 938, CIFAR-10 Batch 1:  loss: 0.716389
accuracy: 0.750000
Epoch 938, CIFAR-10 Batch 2:  loss: 0.818224
accuracy: 0.750000
Epoch 938, CIFAR-10 Batch 3:  loss: 0.788445
accuracy: 0.775000
Epoch 938, CIFAR-10 Batch 4:  loss: 1.233661
accuracy: 0.525000
Epoch 938, CIFAR-10 Batch 5:  loss: 1.011368
accuracy: 0.675000
Epoch 939, CIFAR-10 Batch 1:  loss: 0.719345
accuracy: 0.750000
Epoch 939, CIFAR-10 Batch 2:  loss: 0.822841
accuracy: 0.775000
Epoch 939, CIFAR-10 Batch 3:  loss: 0.786967
accuracy: 0.825000
Epoch 939, CIFAR-10 Batch 4:  loss: 1.288039
accuracy: 0.525000
Epoch 939, CIFAR-10 Batch 5:  loss: 0.977824
accuracy: 0.700000
Epoch 940, CIFAR-10 Batch 1:  loss: 0.702244
accuracy: 0.775000
Epoch 940, CIFAR-10 Batch 2:  loss: 0.851571
accuracy: 0.725000
Epoch 940, CIFAR-10 Batch 3:  loss: 0.804048
accuracy: 0.800000
Epoch 940, CIFAR-10 Batch 4:  loss: 1.251741
accuracy: 0.550000
Epoch 940, CIFAR-10 Batch 5:  loss: 0.986961
accuracy: 0.675000
Epoch 941, CIFAR-10 Batch 1:  loss: 0.713997
accuracy: 0.800000
Epoch 941, CIFAR-10 Batch 2:  loss: 0.839900
accuracy: 0.725000
Epoch 941, CIFAR-10 Batch 3:  loss: 0.776727
accuracy: 0.800000
Epoch 941, CIFAR-10 Batch 4:  loss: 1.265170
accuracy: 0.550000
Epoch 941, CIFAR-10 Batch 5:  loss: 1.002185
accuracy: 0.700000
Epoch 942, CIFAR-10 Batch 1:  loss: 0.722044
accuracy: 0.750000
Epoch 942, CIFAR-10 Batch 2:  loss: 0.821157
accuracy: 0.750000
Epoch 942, CIFAR-10 Batch 3:  loss: 0.778473
accuracy: 0.800000
Epoch 942, CIFAR-10 Batch 4:  loss: 1.242195
accuracy: 0.550000
Epoch 942, CIFAR-10 Batch 5:  loss: 1.034857
accuracy: 0.675000
Epoch 943, CIFAR-10 Batch 1:  loss: 0.718051
accuracy: 0.750000
Epoch 943, CIFAR-10 Batch 2:  loss: 0.807110
accuracy: 0.750000
Epoch 943, CIFAR-10 Batch 3:  loss: 0.808675
accuracy: 0.800000
Epoch 943, CIFAR-10 Batch 4:  loss: 1.274762
accuracy: 0.550000
Epoch 943, CIFAR-10 Batch 5:  loss: 0.972381
accuracy: 0.675000
Epoch 944, CIFAR-10 Batch 1:  loss: 0.714472
accuracy: 0.800000
Epoch 944, CIFAR-10 Batch 2:  loss: 0.822084
accuracy: 0.725000
Epoch 944, CIFAR-10 Batch 3:  loss: 0.823430
accuracy: 0.800000
Epoch 944, CIFAR-10 Batch 4:  loss: 1.298755
accuracy: 0.550000
Epoch 944, CIFAR-10 Batch 5:  loss: 0.982274
accuracy: 0.700000
Epoch 945, CIFAR-10 Batch 1:  loss: 0.725792
accuracy: 0.775000
Epoch 945, CIFAR-10 Batch 2:  loss: 0.819741
accuracy: 0.725000
Epoch 945, CIFAR-10 Batch 3:  loss: 0.777077
accuracy: 0.850000
Epoch 945, CIFAR-10 Batch 4:  loss: 1.288683
accuracy: 0.425000
Epoch 945, CIFAR-10 Batch 5:  loss: 0.942228
accuracy: 0.700000
Epoch 946, CIFAR-10 Batch 1:  loss: 0.729680
accuracy: 0.750000
Epoch 946, CIFAR-10 Batch 2:  loss: 0.828617
accuracy: 0.750000
Epoch 946, CIFAR-10 Batch 3:  loss: 0.792155
accuracy: 0.800000
Epoch 946, CIFAR-10 Batch 4:  loss: 1.283769
accuracy: 0.525000
Epoch 946, CIFAR-10 Batch 5:  loss: 0.987295
accuracy: 0.650000
Epoch 947, CIFAR-10 Batch 1:  loss: 0.724591
accuracy: 0.750000
Epoch 947, CIFAR-10 Batch 2:  loss: 0.837910
accuracy: 0.750000
Epoch 947, CIFAR-10 Batch 3:  loss: 0.764718
accuracy: 0.825000
Epoch 947, CIFAR-10 Batch 4:  loss: 1.270861
accuracy: 0.525000
Epoch 947, CIFAR-10 Batch 5:  loss: 1.016139
accuracy: 0.675000
Epoch 948, CIFAR-10 Batch 1:  loss: 0.740837
accuracy: 0.700000
Epoch 948, CIFAR-10 Batch 2:  loss: 0.824409
accuracy: 0.775000
Epoch 948, CIFAR-10 Batch 3:  loss: 0.765564
accuracy: 0.850000
Epoch 948, CIFAR-10 Batch 4:  loss: 1.253857
accuracy: 0.525000
Epoch 948, CIFAR-10 Batch 5:  loss: 0.967134
accuracy: 0.650000
Epoch 949, CIFAR-10 Batch 1:  loss: 0.707562
accuracy: 0.750000
Epoch 949, CIFAR-10 Batch 2:  loss: 0.861464
accuracy: 0.750000
Epoch 949, CIFAR-10 Batch 3:  loss: 0.786075
accuracy: 0.775000
Epoch 949, CIFAR-10 Batch 4:  loss: 1.292063
accuracy: 0.525000
Epoch 949, CIFAR-10 Batch 5:  loss: 0.987260
accuracy: 0.650000
Epoch 950, CIFAR-10 Batch 1:  loss: 0.714276
accuracy: 0.750000
Epoch 950, CIFAR-10 Batch 2:  loss: 0.806271
accuracy: 0.750000
Epoch 950, CIFAR-10 Batch 3:  loss: 0.741152
accuracy: 0.775000
Epoch 950, CIFAR-10 Batch 4:  loss: 1.273371
accuracy: 0.525000
Epoch 950, CIFAR-10 Batch 5:  loss: 0.972546
accuracy: 0.725000
Epoch 951, CIFAR-10 Batch 1:  loss: 0.719119
accuracy: 0.775000
Epoch 951, CIFAR-10 Batch 2:  loss: 0.837522
accuracy: 0.750000
Epoch 951, CIFAR-10 Batch 3:  loss: 0.802321
accuracy: 0.775000
Epoch 951, CIFAR-10 Batch 4:  loss: 1.312374
accuracy: 0.525000
Epoch 951, CIFAR-10 Batch 5:  loss: 1.013726
accuracy: 0.675000
Epoch 952, CIFAR-10 Batch 1:  loss: 0.706295
accuracy: 0.750000
Epoch 952, CIFAR-10 Batch 2:  loss: 0.853192
accuracy: 0.725000
Epoch 952, CIFAR-10 Batch 3:  loss: 0.791401
accuracy: 0.750000
Epoch 952, CIFAR-10 Batch 4:  loss: 1.280799
accuracy: 0.525000
Epoch 952, CIFAR-10 Batch 5:  loss: 0.982216
accuracy: 0.700000
Epoch 953, CIFAR-10 Batch 1:  loss: 0.695257
accuracy: 0.775000
Epoch 953, CIFAR-10 Batch 2:  loss: 0.845640
accuracy: 0.750000
Epoch 953, CIFAR-10 Batch 3:  loss: 0.790660
accuracy: 0.775000
Epoch 953, CIFAR-10 Batch 4:  loss: 1.348221
accuracy: 0.450000
Epoch 953, CIFAR-10 Batch 5:  loss: 1.022595
accuracy: 0.700000
Epoch 954, CIFAR-10 Batch 1:  loss: 0.705984
accuracy: 0.775000
Epoch 954, CIFAR-10 Batch 2:  loss: 0.863861
accuracy: 0.750000
Epoch 954, CIFAR-10 Batch 3:  loss: 0.744518
accuracy: 0.775000
Epoch 954, CIFAR-10 Batch 4:  loss: 1.250874
accuracy: 0.550000
Epoch 954, CIFAR-10 Batch 5:  loss: 0.996697
accuracy: 0.625000
Epoch 955, CIFAR-10 Batch 1:  loss: 0.728024
accuracy: 0.750000
Epoch 955, CIFAR-10 Batch 2:  loss: 0.857969
accuracy: 0.725000
Epoch 955, CIFAR-10 Batch 3:  loss: 0.770553
accuracy: 0.825000
Epoch 955, CIFAR-10 Batch 4:  loss: 1.266469
accuracy: 0.525000
Epoch 955, CIFAR-10 Batch 5:  loss: 0.982639
accuracy: 0.675000
Epoch 956, CIFAR-10 Batch 1:  loss: 0.714388
accuracy: 0.750000
Epoch 956, CIFAR-10 Batch 2:  loss: 0.895958
accuracy: 0.700000
Epoch 956, CIFAR-10 Batch 3:  loss: 0.780057
accuracy: 0.800000
Epoch 956, CIFAR-10 Batch 4:  loss: 1.237634
accuracy: 0.575000
Epoch 956, CIFAR-10 Batch 5:  loss: 0.986829
accuracy: 0.675000
Epoch 957, CIFAR-10 Batch 1:  loss: 0.699468
accuracy: 0.750000
Epoch 957, CIFAR-10 Batch 2:  loss: 0.859168
accuracy: 0.725000
Epoch 957, CIFAR-10 Batch 3:  loss: 0.822802
accuracy: 0.775000
Epoch 957, CIFAR-10 Batch 4:  loss: 1.237432
accuracy: 0.550000
Epoch 957, CIFAR-10 Batch 5:  loss: 0.999684
accuracy: 0.675000
Epoch 958, CIFAR-10 Batch 1:  loss: 0.697405
accuracy: 0.750000
Epoch 958, CIFAR-10 Batch 2:  loss: 0.843491
accuracy: 0.750000
Epoch 958, CIFAR-10 Batch 3:  loss: 0.796925
accuracy: 0.800000
Epoch 958, CIFAR-10 Batch 4:  loss: 1.269096
accuracy: 0.525000
Epoch 958, CIFAR-10 Batch 5:  loss: 1.000537
accuracy: 0.675000
Epoch 959, CIFAR-10 Batch 1:  loss: 0.676804
accuracy: 0.775000
Epoch 959, CIFAR-10 Batch 2:  loss: 0.876620
accuracy: 0.750000
Epoch 959, CIFAR-10 Batch 3:  loss: 0.773336
accuracy: 0.825000
Epoch 959, CIFAR-10 Batch 4:  loss: 1.285654
accuracy: 0.500000
Epoch 959, CIFAR-10 Batch 5:  loss: 0.981757
accuracy: 0.675000
Epoch 960, CIFAR-10 Batch 1:  loss: 0.681877
accuracy: 0.725000
Epoch 960, CIFAR-10 Batch 2:  loss: 0.855143
accuracy: 0.750000
Epoch 960, CIFAR-10 Batch 3:  loss: 0.788421
accuracy: 0.800000
Epoch 960, CIFAR-10 Batch 4:  loss: 1.261654
accuracy: 0.550000
Epoch 960, CIFAR-10 Batch 5:  loss: 0.998091
accuracy: 0.675000
Epoch 961, CIFAR-10 Batch 1:  loss: 0.712450
accuracy: 0.775000
Epoch 961, CIFAR-10 Batch 2:  loss: 0.839934
accuracy: 0.750000
Epoch 961, CIFAR-10 Batch 3:  loss: 0.774972
accuracy: 0.800000
Epoch 961, CIFAR-10 Batch 4:  loss: 1.275117
accuracy: 0.500000
Epoch 961, CIFAR-10 Batch 5:  loss: 0.964110
accuracy: 0.675000
Epoch 962, CIFAR-10 Batch 1:  loss: 0.697471
accuracy: 0.750000
Epoch 962, CIFAR-10 Batch 2:  loss: 0.857386
accuracy: 0.700000
Epoch 962, CIFAR-10 Batch 3:  loss: 0.801480
accuracy: 0.800000
Epoch 962, CIFAR-10 Batch 4:  loss: 1.274270
accuracy: 0.450000
Epoch 962, CIFAR-10 Batch 5:  loss: 1.008329
accuracy: 0.650000
Epoch 963, CIFAR-10 Batch 1:  loss: 0.705627
accuracy: 0.750000
Epoch 963, CIFAR-10 Batch 2:  loss: 0.835287
accuracy: 0.725000
Epoch 963, CIFAR-10 Batch 3:  loss: 0.839359
accuracy: 0.825000
Epoch 963, CIFAR-10 Batch 4:  loss: 1.283805
accuracy: 0.450000
Epoch 963, CIFAR-10 Batch 5:  loss: 0.994940
accuracy: 0.675000
Epoch 964, CIFAR-10 Batch 1:  loss: 0.687855
accuracy: 0.750000
Epoch 964, CIFAR-10 Batch 2:  loss: 0.855820
accuracy: 0.675000
Epoch 964, CIFAR-10 Batch 3:  loss: 0.807022
accuracy: 0.800000
Epoch 964, CIFAR-10 Batch 4:  loss: 1.259845
accuracy: 0.550000
Epoch 964, CIFAR-10 Batch 5:  loss: 1.017603
accuracy: 0.675000
Epoch 965, CIFAR-10 Batch 1:  loss: 0.689036
accuracy: 0.750000
Epoch 965, CIFAR-10 Batch 2:  loss: 0.858427
accuracy: 0.725000
Epoch 965, CIFAR-10 Batch 3:  loss: 0.805721
accuracy: 0.800000
Epoch 965, CIFAR-10 Batch 4:  loss: 1.247284
accuracy: 0.500000
Epoch 965, CIFAR-10 Batch 5:  loss: 0.989403
accuracy: 0.675000
Epoch 966, CIFAR-10 Batch 1:  loss: 0.690233
accuracy: 0.750000
Epoch 966, CIFAR-10 Batch 2:  loss: 0.851870
accuracy: 0.750000
Epoch 966, CIFAR-10 Batch 3:  loss: 0.794300
accuracy: 0.800000
Epoch 966, CIFAR-10 Batch 4:  loss: 1.264423
accuracy: 0.550000
Epoch 966, CIFAR-10 Batch 5:  loss: 0.985328
accuracy: 0.700000
Epoch 967, CIFAR-10 Batch 1:  loss: 0.708415
accuracy: 0.750000
Epoch 967, CIFAR-10 Batch 2:  loss: 0.842319
accuracy: 0.750000
Epoch 967, CIFAR-10 Batch 3:  loss: 0.793820
accuracy: 0.800000
Epoch 967, CIFAR-10 Batch 4:  loss: 1.246492
accuracy: 0.525000
Epoch 967, CIFAR-10 Batch 5:  loss: 1.004616
accuracy: 0.750000
Epoch 968, CIFAR-10 Batch 1:  loss: 0.689288
accuracy: 0.725000
Epoch 968, CIFAR-10 Batch 2:  loss: 0.832030
accuracy: 0.775000
Epoch 968, CIFAR-10 Batch 3:  loss: 0.756252
accuracy: 0.800000
Epoch 968, CIFAR-10 Batch 4:  loss: 1.265358
accuracy: 0.525000
Epoch 968, CIFAR-10 Batch 5:  loss: 0.996319
accuracy: 0.675000
Epoch 969, CIFAR-10 Batch 1:  loss: 0.700625
accuracy: 0.775000
Epoch 969, CIFAR-10 Batch 2:  loss: 0.841814
accuracy: 0.725000
Epoch 969, CIFAR-10 Batch 3:  loss: 0.818523
accuracy: 0.725000
Epoch 969, CIFAR-10 Batch 4:  loss: 1.251306
accuracy: 0.500000
Epoch 969, CIFAR-10 Batch 5:  loss: 1.008156
accuracy: 0.675000
Epoch 970, CIFAR-10 Batch 1:  loss: 0.678292
accuracy: 0.800000
Epoch 970, CIFAR-10 Batch 2:  loss: 0.866426
accuracy: 0.750000
Epoch 970, CIFAR-10 Batch 3:  loss: 0.801972
accuracy: 0.775000
Epoch 970, CIFAR-10 Batch 4:  loss: 1.267839
accuracy: 0.525000
Epoch 970, CIFAR-10 Batch 5:  loss: 0.987920
accuracy: 0.675000
Epoch 971, CIFAR-10 Batch 1:  loss: 0.681450
accuracy: 0.750000
Epoch 971, CIFAR-10 Batch 2:  loss: 0.864474
accuracy: 0.750000
Epoch 971, CIFAR-10 Batch 3:  loss: 0.827657
accuracy: 0.750000
Epoch 971, CIFAR-10 Batch 4:  loss: 1.331838
accuracy: 0.525000
Epoch 971, CIFAR-10 Batch 5:  loss: 1.006625
accuracy: 0.675000
Epoch 972, CIFAR-10 Batch 1:  loss: 0.719440
accuracy: 0.800000
Epoch 972, CIFAR-10 Batch 2:  loss: 0.864681
accuracy: 0.750000
Epoch 972, CIFAR-10 Batch 3:  loss: 0.832187
accuracy: 0.775000
Epoch 972, CIFAR-10 Batch 4:  loss: 1.244780
accuracy: 0.575000
Epoch 972, CIFAR-10 Batch 5:  loss: 0.986345
accuracy: 0.700000
Epoch 973, CIFAR-10 Batch 1:  loss: 0.709808
accuracy: 0.750000
Epoch 973, CIFAR-10 Batch 2:  loss: 0.828386
accuracy: 0.750000
Epoch 973, CIFAR-10 Batch 3:  loss: 0.811583
accuracy: 0.775000
Epoch 973, CIFAR-10 Batch 4:  loss: 1.275892
accuracy: 0.525000
Epoch 973, CIFAR-10 Batch 5:  loss: 0.985448
accuracy: 0.725000
Epoch 974, CIFAR-10 Batch 1:  loss: 0.699676
accuracy: 0.750000
Epoch 974, CIFAR-10 Batch 2:  loss: 0.841056
accuracy: 0.750000
Epoch 974, CIFAR-10 Batch 3:  loss: 0.804408
accuracy: 0.775000
Epoch 974, CIFAR-10 Batch 4:  loss: 1.262468
accuracy: 0.550000
Epoch 974, CIFAR-10 Batch 5:  loss: 1.019587
accuracy: 0.700000
Epoch 975, CIFAR-10 Batch 1:  loss: 0.706083
accuracy: 0.775000
Epoch 975, CIFAR-10 Batch 2:  loss: 0.860435
accuracy: 0.750000
Epoch 975, CIFAR-10 Batch 3:  loss: 0.780644
accuracy: 0.775000
Epoch 975, CIFAR-10 Batch 4:  loss: 1.258750
accuracy: 0.450000
Epoch 975, CIFAR-10 Batch 5:  loss: 0.971228
accuracy: 0.700000
Epoch 976, CIFAR-10 Batch 1:  loss: 1.988405
accuracy: 0.725000
Epoch 976, CIFAR-10 Batch 2:  loss: 0.821451
accuracy: 0.750000
Epoch 976, CIFAR-10 Batch 3:  loss: 0.782062
accuracy: 0.750000
Epoch 976, CIFAR-10 Batch 4:  loss: 1.263362
accuracy: 0.575000
Epoch 976, CIFAR-10 Batch 5:  loss: 1.002929
accuracy: 0.675000
Epoch 977, CIFAR-10 Batch 1:  loss: 0.832293
accuracy: 0.775000
Epoch 977, CIFAR-10 Batch 2:  loss: 0.826248
accuracy: 0.775000
Epoch 977, CIFAR-10 Batch 3:  loss: 0.765573
accuracy: 0.825000
Epoch 977, CIFAR-10 Batch 4:  loss: 1.308592
accuracy: 0.525000
Epoch 977, CIFAR-10 Batch 5:  loss: 0.981435
accuracy: 0.700000
Epoch 978, CIFAR-10 Batch 1:  loss: 0.664219
accuracy: 0.775000
Epoch 978, CIFAR-10 Batch 2:  loss: 0.846477
accuracy: 0.750000
Epoch 978, CIFAR-10 Batch 3:  loss: 0.800373
accuracy: 0.775000
Epoch 978, CIFAR-10 Batch 4:  loss: 1.235198
accuracy: 0.600000
Epoch 978, CIFAR-10 Batch 5:  loss: 0.994764
accuracy: 0.675000
Epoch 979, CIFAR-10 Batch 1:  loss: 0.717197
accuracy: 0.750000
Epoch 979, CIFAR-10 Batch 2:  loss: 0.840882
accuracy: 0.750000
Epoch 979, CIFAR-10 Batch 3:  loss: 0.785502
accuracy: 0.775000
Epoch 979, CIFAR-10 Batch 4:  loss: 1.240648
accuracy: 0.575000
Epoch 979, CIFAR-10 Batch 5:  loss: 0.982588
accuracy: 0.700000
Epoch 980, CIFAR-10 Batch 1:  loss: 0.691390
accuracy: 0.750000
Epoch 980, CIFAR-10 Batch 2:  loss: 0.839086
accuracy: 0.750000
Epoch 980, CIFAR-10 Batch 3:  loss: 0.841376
accuracy: 0.750000
Epoch 980, CIFAR-10 Batch 4:  loss: 1.259500
accuracy: 0.550000
Epoch 980, CIFAR-10 Batch 5:  loss: 0.983375
accuracy: 0.700000
Epoch 981, CIFAR-10 Batch 1:  loss: 0.679281
accuracy: 0.775000
Epoch 981, CIFAR-10 Batch 2:  loss: 0.825966
accuracy: 0.725000
Epoch 981, CIFAR-10 Batch 3:  loss: 0.780306
accuracy: 0.775000
Epoch 981, CIFAR-10 Batch 4:  loss: 1.229435
accuracy: 0.550000
Epoch 981, CIFAR-10 Batch 5:  loss: 0.996650
accuracy: 0.700000
Epoch 982, CIFAR-10 Batch 1:  loss: 0.699829
accuracy: 0.750000
Epoch 982, CIFAR-10 Batch 2:  loss: 0.808404
accuracy: 0.775000
Epoch 982, CIFAR-10 Batch 3:  loss: 0.770993
accuracy: 0.800000
Epoch 982, CIFAR-10 Batch 4:  loss: 1.226438
accuracy: 0.525000
Epoch 982, CIFAR-10 Batch 5:  loss: 0.992326
accuracy: 0.675000
Epoch 983, CIFAR-10 Batch 1:  loss: 0.712490
accuracy: 0.725000
Epoch 983, CIFAR-10 Batch 2:  loss: 0.812127
accuracy: 0.775000
Epoch 983, CIFAR-10 Batch 3:  loss: 0.769485
accuracy: 0.800000
Epoch 983, CIFAR-10 Batch 4:  loss: 1.247177
accuracy: 0.500000
Epoch 983, CIFAR-10 Batch 5:  loss: 0.989886
accuracy: 0.675000
Epoch 984, CIFAR-10 Batch 1:  loss: 0.704351
accuracy: 0.775000
Epoch 984, CIFAR-10 Batch 2:  loss: 0.820640
accuracy: 0.750000
Epoch 984, CIFAR-10 Batch 3:  loss: 0.793038
accuracy: 0.800000
Epoch 984, CIFAR-10 Batch 4:  loss: 1.205589
accuracy: 0.575000
Epoch 984, CIFAR-10 Batch 5:  loss: 1.030124
accuracy: 0.700000
Epoch 985, CIFAR-10 Batch 1:  loss: 0.705004
accuracy: 0.800000
Epoch 985, CIFAR-10 Batch 2:  loss: 0.840270
accuracy: 0.675000
Epoch 985, CIFAR-10 Batch 3:  loss: 0.804293
accuracy: 0.750000
Epoch 985, CIFAR-10 Batch 4:  loss: 1.236969
accuracy: 0.525000
Epoch 985, CIFAR-10 Batch 5:  loss: 1.001133
accuracy: 0.625000
Epoch 986, CIFAR-10 Batch 1:  loss: 0.686641
accuracy: 0.800000
Epoch 986, CIFAR-10 Batch 2:  loss: 0.852711
accuracy: 0.650000
Epoch 986, CIFAR-10 Batch 3:  loss: 0.836450
accuracy: 0.775000
Epoch 986, CIFAR-10 Batch 4:  loss: 1.215215
accuracy: 0.575000
Epoch 986, CIFAR-10 Batch 5:  loss: 0.996643
accuracy: 0.700000
Epoch 987, CIFAR-10 Batch 1:  loss: 0.661807
accuracy: 0.800000
Epoch 987, CIFAR-10 Batch 2:  loss: 0.835207
accuracy: 0.775000
Epoch 987, CIFAR-10 Batch 3:  loss: 0.834980
accuracy: 0.750000
Epoch 987, CIFAR-10 Batch 4:  loss: 1.228987
accuracy: 0.575000
Epoch 987, CIFAR-10 Batch 5:  loss: 0.990524
accuracy: 0.675000
Epoch 988, CIFAR-10 Batch 1:  loss: 0.679999
accuracy: 0.775000
Epoch 988, CIFAR-10 Batch 2:  loss: 0.825080
accuracy: 0.750000
Epoch 988, CIFAR-10 Batch 3:  loss: 0.785372
accuracy: 0.775000
Epoch 988, CIFAR-10 Batch 4:  loss: 1.258353
accuracy: 0.525000
Epoch 988, CIFAR-10 Batch 5:  loss: 0.976498
accuracy: 0.700000
Epoch 989, CIFAR-10 Batch 1:  loss: 0.689713
accuracy: 0.750000
Epoch 989, CIFAR-10 Batch 2:  loss: 0.833772
accuracy: 0.775000
Epoch 989, CIFAR-10 Batch 3:  loss: 0.805126
accuracy: 0.775000
Epoch 989, CIFAR-10 Batch 4:  loss: 1.245916
accuracy: 0.500000
Epoch 989, CIFAR-10 Batch 5:  loss: 1.024615
accuracy: 0.700000
Epoch 990, CIFAR-10 Batch 1:  loss: 0.680785
accuracy: 0.750000
Epoch 990, CIFAR-10 Batch 2:  loss: 0.842442
accuracy: 0.725000
Epoch 990, CIFAR-10 Batch 3:  loss: 0.819517
accuracy: 0.775000
Epoch 990, CIFAR-10 Batch 4:  loss: 1.242263
accuracy: 0.575000
Epoch 990, CIFAR-10 Batch 5:  loss: 1.017944
accuracy: 0.650000
Epoch 991, CIFAR-10 Batch 1:  loss: 0.696771
accuracy: 0.775000
Epoch 991, CIFAR-10 Batch 2:  loss: 0.819624
accuracy: 0.775000
Epoch 991, CIFAR-10 Batch 3:  loss: 0.792767
accuracy: 0.800000
Epoch 991, CIFAR-10 Batch 4:  loss: 1.257178
accuracy: 0.550000
Epoch 991, CIFAR-10 Batch 5:  loss: 1.006295
accuracy: 0.675000
Epoch 992, CIFAR-10 Batch 1:  loss: 0.734618
accuracy: 0.750000
Epoch 992, CIFAR-10 Batch 2:  loss: 0.814688
accuracy: 0.725000
Epoch 992, CIFAR-10 Batch 3:  loss: 0.848110
accuracy: 0.775000
Epoch 992, CIFAR-10 Batch 4:  loss: 1.256262
accuracy: 0.525000
Epoch 992, CIFAR-10 Batch 5:  loss: 0.980640
accuracy: 0.700000
Epoch 993, CIFAR-10 Batch 1:  loss: 0.741620
accuracy: 0.750000
Epoch 993, CIFAR-10 Batch 2:  loss: 0.799639
accuracy: 0.750000
Epoch 993, CIFAR-10 Batch 3:  loss: 0.795282
accuracy: 0.775000
Epoch 993, CIFAR-10 Batch 4:  loss: 1.244645
accuracy: 0.550000
Epoch 993, CIFAR-10 Batch 5:  loss: 1.024148
accuracy: 0.675000
Epoch 994, CIFAR-10 Batch 1:  loss: 0.705561
accuracy: 0.800000
Epoch 994, CIFAR-10 Batch 2:  loss: 0.814738
accuracy: 0.725000
Epoch 994, CIFAR-10 Batch 3:  loss: 0.790369
accuracy: 0.800000
Epoch 994, CIFAR-10 Batch 4:  loss: 1.257394
accuracy: 0.525000
Epoch 994, CIFAR-10 Batch 5:  loss: 1.026192
accuracy: 0.650000
Epoch 995, CIFAR-10 Batch 1:  loss: 0.713651
accuracy: 0.800000
Epoch 995, CIFAR-10 Batch 2:  loss: 0.811088
accuracy: 0.750000
Epoch 995, CIFAR-10 Batch 3:  loss: 0.801471
accuracy: 0.775000
Epoch 995, CIFAR-10 Batch 4:  loss: 1.240869
accuracy: 0.550000
Epoch 995, CIFAR-10 Batch 5:  loss: 1.074166
accuracy: 0.625000
Epoch 996, CIFAR-10 Batch 1:  loss: 0.672279
accuracy: 0.800000
Epoch 996, CIFAR-10 Batch 2:  loss: 0.829814
accuracy: 0.700000
Epoch 996, CIFAR-10 Batch 3:  loss: 0.783194
accuracy: 0.775000
Epoch 996, CIFAR-10 Batch 4:  loss: 1.215706
accuracy: 0.575000
Epoch 996, CIFAR-10 Batch 5:  loss: 1.018003
accuracy: 0.650000
Epoch 997, CIFAR-10 Batch 1:  loss: 0.714849
accuracy: 0.775000
Epoch 997, CIFAR-10 Batch 2:  loss: 0.790800
accuracy: 0.725000
Epoch 997, CIFAR-10 Batch 3:  loss: 0.852888
accuracy: 0.775000
Epoch 997, CIFAR-10 Batch 4:  loss: 1.216633
accuracy: 0.600000
Epoch 997, CIFAR-10 Batch 5:  loss: 1.045278
accuracy: 0.675000
Epoch 998, CIFAR-10 Batch 1:  loss: 0.737840
accuracy: 0.775000
Epoch 998, CIFAR-10 Batch 2:  loss: 0.796403
accuracy: 0.725000
Epoch 998, CIFAR-10 Batch 3:  loss: 0.793005
accuracy: 0.750000
Epoch 998, CIFAR-10 Batch 4:  loss: 1.210238
accuracy: 0.575000
Epoch 998, CIFAR-10 Batch 5:  loss: 1.011536
accuracy: 0.650000
Epoch 999, CIFAR-10 Batch 1:  loss: 0.684871
accuracy: 0.775000
Epoch 999, CIFAR-10 Batch 2:  loss: 0.817162
accuracy: 0.750000
Epoch 999, CIFAR-10 Batch 3:  loss: 0.819288
accuracy: 0.775000
Epoch 999, CIFAR-10 Batch 4:  loss: 1.222162
accuracy: 0.550000
Epoch 999, CIFAR-10 Batch 5:  loss: 1.003762
accuracy: 0.675000
Epoch 1000, CIFAR-10 Batch 1:  loss: 0.741551
accuracy: 0.775000
Epoch 1000, CIFAR-10 Batch 2:  loss: 0.824065
accuracy: 0.750000
Epoch 1000, CIFAR-10 Batch 3:  loss: 0.816979
accuracy: 0.725000
Epoch 1000, CIFAR-10 Batch 4:  loss: 1.218115
accuracy: 0.550000
Epoch 1000, CIFAR-10 Batch 5:  loss: 0.995134
accuracy: 0.675000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1><p>The model has been saved to disk.</p>
<h2 id="Test-Model">Test Model<a class="anchor-link" href="#Test-Model">&#182;</a></h2><p>Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#26816;&#26597;&#28857;">&#26816;&#26597;&#28857;<a class="anchor-link" href="#&#26816;&#26597;&#28857;">&#182;</a></h1><p>该模型已经被存储到你的硬盘中。</p>
<h2 id="&#27979;&#35797;&#27169;&#22411;">&#27979;&#35797;&#27169;&#22411;<a class="anchor-link" href="#&#27979;&#35797;&#27169;&#22411;">&#182;</a></h2><p>这部分将在测试数据集上测试你的模型。这边得到的准确率将作为你的最终准确率。你应该得到一个高于 50% 准确率。如果它没有超过 50%，那么你需要继续调整模型架构及参数。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Set batch size if not already set</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">pass</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">top_n_predictions</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">test_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the saved model against the test dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_training.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
    <span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Load model</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_model_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>

        <span class="c1"># Get Tensors from loaded model</span>
        <span class="n">loaded_x</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;x:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_y</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;y:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_acc</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;accuracy:0&#39;</span><span class="p">)</span>
        
        <span class="c1"># Get accuracy in batches for memory limitations</span>
        <span class="n">test_batch_acc_total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">test_batch_count</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">train_feature_batch</span><span class="p">,</span> <span class="n">train_label_batch</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">batch_features_labels</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">test_batch_acc_total</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">loaded_acc</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">train_feature_batch</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">train_label_batch</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">test_batch_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Accuracy: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_batch_acc_total</span><span class="o">/</span><span class="n">test_batch_count</span><span class="p">))</span>

        <span class="c1"># Print Random Samples</span>
        <span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)),</span> <span class="n">n_samples</span><span class="p">)))</span>
        <span class="n">random_test_predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">loaded_logits</span><span class="p">),</span> <span class="n">top_n_predictions</span><span class="p">),</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">random_test_features</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
        <span class="n">helper</span><span class="o">.</span><span class="n">display_image_predictions</span><span class="p">(</span><span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">random_test_predictions</span><span class="p">)</span>


<span class="n">test_model</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from ./image_classification
Testing Accuracy: 0.16772151898734178

</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=355
height=319
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-50-80%-Accuracy?">Why 50-80% Accuracy?<a class="anchor-link" href="#Why-50-80%-Accuracy?">&#182;</a></h2><p>You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. That's because there are many more techniques that can be applied to your model and we recemmond that once you are done with this project, you explore!</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as "image_classification.ipynb" and save it as a HTML file under "File" -&gt; "Download as".  Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#20026;&#20160;&#20040;&#20165;&#26377;-50%~-80%-&#30340;&#20934;&#30830;&#29575;&#65311;">&#20026;&#20160;&#20040;&#20165;&#26377; 50%~ 80% &#30340;&#20934;&#30830;&#29575;&#65311;<a class="anchor-link" href="#&#20026;&#20160;&#20040;&#20165;&#26377;-50%~-80%-&#30340;&#20934;&#30830;&#29575;&#65311;">&#182;</a></h2><p>你也许会觉得奇怪，为什么你的准确率总是提高不上去。对于简单的 CNN 网络而言，50% 并非是很差的表现。纯粹的猜测只会得到 10% 的准确率（因为一共有 10 类）。这是因为还有许多许多能够应用到你模型的技巧。在你做完了该项目之后，你可以探索探索我们给你推荐的一些方法。</p>
<h2 id="&#25552;&#20132;&#35813;&#39033;&#30446;">&#25552;&#20132;&#35813;&#39033;&#30446;<a class="anchor-link" href="#&#25552;&#20132;&#35813;&#39033;&#30446;">&#182;</a></h2><p>在提交项目前，请确保你在运行了所有的 cell 之后保存了项目。将项目储存为 "image_classification.ipynb" 并导出为一个 HTML 文件。你可以再菜单栏中选择 File -&gt; Download as 进行导出。请将 "helper.py" 及  "problem_unittests.py" 文件也放在你的提交文件中。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>
</html>
